{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d831d2d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation\n",
    "from tensorflow import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eaab91e",
   "metadata": {},
   "source": [
    "## Exercise 3.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "48ea85bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num examples in dataset =  10000\n",
      "Number of Features for each example =  10\n",
      "Number of possible output class =  [0 1]\n"
     ]
    }
   ],
   "source": [
    "X = pd.read_csv('https://raw.githubusercontent.com/PacktWorkshops/The-Deep-Learning-with-Keras-Workshop/master/Chapter03/data/tree_class_feats.csv')\n",
    "y = pd.read_csv('https://raw.githubusercontent.com/PacktWorkshops/The-Deep-Learning-with-Keras-Workshop/master/Chapter03/data/tree_class_target.csv')\n",
    "\n",
    "print(\"Num examples in dataset = \",X.shape[0])\n",
    "print(\"Number of Features for each example = \", X.shape[1])\n",
    "print(\"Number of possible output class = \", np.unique(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "85883798",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature 1</th>\n",
       "      <th>feature 2</th>\n",
       "      <th>feature 3</th>\n",
       "      <th>feature 4</th>\n",
       "      <th>feature 5</th>\n",
       "      <th>feature 6</th>\n",
       "      <th>feature 7</th>\n",
       "      <th>feature 8</th>\n",
       "      <th>feature 9</th>\n",
       "      <th>feature 10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.722029</td>\n",
       "      <td>-4.689223</td>\n",
       "      <td>-0.207066</td>\n",
       "      <td>2.498555</td>\n",
       "      <td>2.883010</td>\n",
       "      <td>1.579690</td>\n",
       "      <td>-2.720014</td>\n",
       "      <td>-1.246192</td>\n",
       "      <td>1.168185</td>\n",
       "      <td>1.400007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.236202</td>\n",
       "      <td>-2.412059</td>\n",
       "      <td>-2.977042</td>\n",
       "      <td>2.837931</td>\n",
       "      <td>4.201749</td>\n",
       "      <td>0.536090</td>\n",
       "      <td>0.266874</td>\n",
       "      <td>-1.308043</td>\n",
       "      <td>3.728172</td>\n",
       "      <td>-1.198629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.592300</td>\n",
       "      <td>-3.678390</td>\n",
       "      <td>-0.282953</td>\n",
       "      <td>0.912839</td>\n",
       "      <td>1.055228</td>\n",
       "      <td>1.235441</td>\n",
       "      <td>-3.378884</td>\n",
       "      <td>-1.117221</td>\n",
       "      <td>-0.274793</td>\n",
       "      <td>0.098392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.579346</td>\n",
       "      <td>-1.135482</td>\n",
       "      <td>0.734795</td>\n",
       "      <td>-3.840698</td>\n",
       "      <td>-0.362227</td>\n",
       "      <td>2.641352</td>\n",
       "      <td>-3.080336</td>\n",
       "      <td>-1.728918</td>\n",
       "      <td>-2.738785</td>\n",
       "      <td>-1.061155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-2.962439</td>\n",
       "      <td>1.754583</td>\n",
       "      <td>-1.145055</td>\n",
       "      <td>1.857364</td>\n",
       "      <td>0.989132</td>\n",
       "      <td>2.567482</td>\n",
       "      <td>2.058646</td>\n",
       "      <td>-7.009674</td>\n",
       "      <td>-2.108419</td>\n",
       "      <td>1.437935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>1.022289</td>\n",
       "      <td>-3.230883</td>\n",
       "      <td>-2.495737</td>\n",
       "      <td>0.390261</td>\n",
       "      <td>-0.147182</td>\n",
       "      <td>0.064142</td>\n",
       "      <td>-0.390135</td>\n",
       "      <td>2.211020</td>\n",
       "      <td>2.311376</td>\n",
       "      <td>-0.125661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>1.015045</td>\n",
       "      <td>-1.849473</td>\n",
       "      <td>0.336990</td>\n",
       "      <td>3.014374</td>\n",
       "      <td>2.465954</td>\n",
       "      <td>2.384255</td>\n",
       "      <td>2.417506</td>\n",
       "      <td>-2.121998</td>\n",
       "      <td>1.909964</td>\n",
       "      <td>0.300671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>0.872219</td>\n",
       "      <td>-1.853566</td>\n",
       "      <td>-2.775822</td>\n",
       "      <td>-0.093883</td>\n",
       "      <td>0.846248</td>\n",
       "      <td>-0.126794</td>\n",
       "      <td>-0.486381</td>\n",
       "      <td>1.003340</td>\n",
       "      <td>1.796131</td>\n",
       "      <td>0.352305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>3.887696</td>\n",
       "      <td>-4.001737</td>\n",
       "      <td>-1.545467</td>\n",
       "      <td>0.480301</td>\n",
       "      <td>0.444397</td>\n",
       "      <td>-0.695269</td>\n",
       "      <td>-1.618287</td>\n",
       "      <td>3.498178</td>\n",
       "      <td>1.620317</td>\n",
       "      <td>-0.508611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>-3.204404</td>\n",
       "      <td>-4.948918</td>\n",
       "      <td>-0.183310</td>\n",
       "      <td>5.298295</td>\n",
       "      <td>0.175799</td>\n",
       "      <td>-0.509867</td>\n",
       "      <td>-3.226442</td>\n",
       "      <td>-0.152705</td>\n",
       "      <td>1.643190</td>\n",
       "      <td>0.162761</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      feature 1  feature 2  feature 3  feature 4  feature 5  feature 6  \\\n",
       "0      1.722029  -4.689223  -0.207066   2.498555   2.883010   1.579690   \n",
       "1      0.236202  -2.412059  -2.977042   2.837931   4.201749   0.536090   \n",
       "2      0.592300  -3.678390  -0.282953   0.912839   1.055228   1.235441   \n",
       "3      1.579346  -1.135482   0.734795  -3.840698  -0.362227   2.641352   \n",
       "4     -2.962439   1.754583  -1.145055   1.857364   0.989132   2.567482   \n",
       "...         ...        ...        ...        ...        ...        ...   \n",
       "9995   1.022289  -3.230883  -2.495737   0.390261  -0.147182   0.064142   \n",
       "9996   1.015045  -1.849473   0.336990   3.014374   2.465954   2.384255   \n",
       "9997   0.872219  -1.853566  -2.775822  -0.093883   0.846248  -0.126794   \n",
       "9998   3.887696  -4.001737  -1.545467   0.480301   0.444397  -0.695269   \n",
       "9999  -3.204404  -4.948918  -0.183310   5.298295   0.175799  -0.509867   \n",
       "\n",
       "      feature 7  feature 8  feature 9  feature 10  \n",
       "0     -2.720014  -1.246192   1.168185    1.400007  \n",
       "1      0.266874  -1.308043   3.728172   -1.198629  \n",
       "2     -3.378884  -1.117221  -0.274793    0.098392  \n",
       "3     -3.080336  -1.728918  -2.738785   -1.061155  \n",
       "4      2.058646  -7.009674  -2.108419    1.437935  \n",
       "...         ...        ...        ...         ...  \n",
       "9995  -0.390135   2.211020   2.311376   -0.125661  \n",
       "9996   2.417506  -2.121998   1.909964    0.300671  \n",
       "9997  -0.486381   1.003340   1.796131    0.352305  \n",
       "9998  -1.618287   3.498178   1.620317   -0.508611  \n",
       "9999  -3.226442  -0.152705   1.643190    0.162761  \n",
       "\n",
       "[10000 rows x 10 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "be416526",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e53fbb19",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5d0a1af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc4d5bd6",
   "metadata": {},
   "source": [
    "### Step 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e1873857",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(10,activation='tanh', input_dim=10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d54bc95",
   "metadata": {},
   "source": [
    "### Step 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2043d5ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(5, activation='tanh'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb439f6c",
   "metadata": {},
   "source": [
    "### Step 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f465dd33",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "02efa974",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 10)                110       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 5)                 55        \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 6         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 171\n",
      "Trainable params: 171\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='sgd', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "663a9d36",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1600/1600 [==============================] - 3s 2ms/step - loss: 0.3868 - accuracy: 0.8152 - val_loss: 0.3277 - val_accuracy: 0.8540\n",
      "Epoch 2/100\n",
      "1600/1600 [==============================] - 3s 2ms/step - loss: 0.3264 - accuracy: 0.8478 - val_loss: 0.3018 - val_accuracy: 0.8690\n",
      "Epoch 3/100\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.2983 - accuracy: 0.8671 - val_loss: 0.2760 - val_accuracy: 0.8820\n",
      "Epoch 4/100\n",
      "1600/1600 [==============================] - 2s 2ms/step - loss: 0.2717 - accuracy: 0.8849 - val_loss: 0.2523 - val_accuracy: 0.8915\n",
      "Epoch 5/100\n",
      "1600/1600 [==============================] - 3s 2ms/step - loss: 0.2505 - accuracy: 0.8957 - val_loss: 0.2327 - val_accuracy: 0.9000\n",
      "Epoch 6/100\n",
      "1600/1600 [==============================] - 2s 2ms/step - loss: 0.2351 - accuracy: 0.9034 - val_loss: 0.2190 - val_accuracy: 0.9010\n",
      "Epoch 7/100\n",
      "1600/1600 [==============================] - 3s 2ms/step - loss: 0.2241 - accuracy: 0.9090 - val_loss: 0.2093 - val_accuracy: 0.9055\n",
      "Epoch 8/100\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.2163 - accuracy: 0.9136 - val_loss: 0.2024 - val_accuracy: 0.9080\n",
      "Epoch 9/100\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.2102 - accuracy: 0.9172 - val_loss: 0.1973 - val_accuracy: 0.9160\n",
      "Epoch 10/100\n",
      "1600/1600 [==============================] - 2s 2ms/step - loss: 0.2046 - accuracy: 0.9219 - val_loss: 0.1932 - val_accuracy: 0.9220\n",
      "Epoch 11/100\n",
      "1600/1600 [==============================] - 2s 2ms/step - loss: 0.1989 - accuracy: 0.9250 - val_loss: 0.1896 - val_accuracy: 0.9205\n",
      "Epoch 12/100\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.1942 - accuracy: 0.9268 - val_loss: 0.1863 - val_accuracy: 0.9220\n",
      "Epoch 13/100\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.1908 - accuracy: 0.9287 - val_loss: 0.1835 - val_accuracy: 0.9235\n",
      "Epoch 14/100\n",
      "1600/1600 [==============================] - 2s 2ms/step - loss: 0.1879 - accuracy: 0.9295 - val_loss: 0.1812 - val_accuracy: 0.9250\n",
      "Epoch 15/100\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.1855 - accuracy: 0.9304 - val_loss: 0.1795 - val_accuracy: 0.9260\n",
      "Epoch 16/100\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.1833 - accuracy: 0.9302 - val_loss: 0.1780 - val_accuracy: 0.9265\n",
      "Epoch 17/100\n",
      "1600/1600 [==============================] - 3s 2ms/step - loss: 0.1813 - accuracy: 0.9310 - val_loss: 0.1767 - val_accuracy: 0.9255\n",
      "Epoch 18/100\n",
      "1600/1600 [==============================] - 3s 2ms/step - loss: 0.1794 - accuracy: 0.9310 - val_loss: 0.1755 - val_accuracy: 0.9250\n",
      "Epoch 19/100\n",
      "1600/1600 [==============================] - 3s 2ms/step - loss: 0.1777 - accuracy: 0.9319 - val_loss: 0.1745 - val_accuracy: 0.9250\n",
      "Epoch 20/100\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.1760 - accuracy: 0.9324 - val_loss: 0.1734 - val_accuracy: 0.9265\n",
      "Epoch 21/100\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.1745 - accuracy: 0.9326 - val_loss: 0.1723 - val_accuracy: 0.9275\n",
      "Epoch 22/100\n",
      "1600/1600 [==============================] - 3s 2ms/step - loss: 0.1730 - accuracy: 0.9334 - val_loss: 0.1712 - val_accuracy: 0.9285\n",
      "Epoch 23/100\n",
      "1600/1600 [==============================] - 3s 2ms/step - loss: 0.1716 - accuracy: 0.9339 - val_loss: 0.1701 - val_accuracy: 0.9300\n",
      "Epoch 24/100\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.1704 - accuracy: 0.9345 - val_loss: 0.1689 - val_accuracy: 0.9300\n",
      "Epoch 25/100\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.1692 - accuracy: 0.9354 - val_loss: 0.1678 - val_accuracy: 0.9310\n",
      "Epoch 26/100\n",
      "1600/1600 [==============================] - 3s 2ms/step - loss: 0.1681 - accuracy: 0.9367 - val_loss: 0.1666 - val_accuracy: 0.9310\n",
      "Epoch 27/100\n",
      "1600/1600 [==============================] - 3s 2ms/step - loss: 0.1670 - accuracy: 0.9369 - val_loss: 0.1655 - val_accuracy: 0.9315\n",
      "Epoch 28/100\n",
      "1600/1600 [==============================] - 3s 2ms/step - loss: 0.1659 - accuracy: 0.9371 - val_loss: 0.1642 - val_accuracy: 0.9340\n",
      "Epoch 29/100\n",
      "1600/1600 [==============================] - 3s 2ms/step - loss: 0.1645 - accuracy: 0.9377 - val_loss: 0.1631 - val_accuracy: 0.9355\n",
      "Epoch 30/100\n",
      "1600/1600 [==============================] - 3s 2ms/step - loss: 0.1632 - accuracy: 0.9377 - val_loss: 0.1621 - val_accuracy: 0.9360\n",
      "Epoch 31/100\n",
      "1600/1600 [==============================] - 3s 2ms/step - loss: 0.1620 - accuracy: 0.9385 - val_loss: 0.1613 - val_accuracy: 0.9355\n",
      "Epoch 32/100\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.1610 - accuracy: 0.9389 - val_loss: 0.1606 - val_accuracy: 0.9360\n",
      "Epoch 33/100\n",
      "1600/1600 [==============================] - 2s 2ms/step - loss: 0.1601 - accuracy: 0.9391 - val_loss: 0.1599 - val_accuracy: 0.9355\n",
      "Epoch 34/100\n",
      "1600/1600 [==============================] - 3s 2ms/step - loss: 0.1594 - accuracy: 0.9391 - val_loss: 0.1594 - val_accuracy: 0.9360\n",
      "Epoch 35/100\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.1587 - accuracy: 0.9394 - val_loss: 0.1590 - val_accuracy: 0.9360\n",
      "Epoch 36/100\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.1582 - accuracy: 0.9399 - val_loss: 0.1587 - val_accuracy: 0.9345\n",
      "Epoch 37/100\n",
      "1600/1600 [==============================] - 3s 2ms/step - loss: 0.1577 - accuracy: 0.9401 - val_loss: 0.1584 - val_accuracy: 0.9360\n",
      "Epoch 38/100\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.1573 - accuracy: 0.9402 - val_loss: 0.1581 - val_accuracy: 0.9360\n",
      "Epoch 39/100\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.1570 - accuracy: 0.9408 - val_loss: 0.1579 - val_accuracy: 0.9365\n",
      "Epoch 40/100\n",
      "1600/1600 [==============================] - 3s 2ms/step - loss: 0.1566 - accuracy: 0.9404 - val_loss: 0.1577 - val_accuracy: 0.9370\n",
      "Epoch 41/100\n",
      "1600/1600 [==============================] - 3s 2ms/step - loss: 0.1563 - accuracy: 0.9400 - val_loss: 0.1576 - val_accuracy: 0.9365\n",
      "Epoch 42/100\n",
      "1600/1600 [==============================] - 3s 2ms/step - loss: 0.1561 - accuracy: 0.9400 - val_loss: 0.1574 - val_accuracy: 0.9375\n",
      "Epoch 43/100\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.1558 - accuracy: 0.9401 - val_loss: 0.1573 - val_accuracy: 0.9390\n",
      "Epoch 44/100\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.1556 - accuracy: 0.9402 - val_loss: 0.1572 - val_accuracy: 0.9385\n",
      "Epoch 45/100\n",
      "1600/1600 [==============================] - 3s 2ms/step - loss: 0.1554 - accuracy: 0.9404 - val_loss: 0.1571 - val_accuracy: 0.9395\n",
      "Epoch 46/100\n",
      "1600/1600 [==============================] - 2s 2ms/step - loss: 0.1552 - accuracy: 0.9406 - val_loss: 0.1570 - val_accuracy: 0.9395\n",
      "Epoch 47/100\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.1550 - accuracy: 0.9408 - val_loss: 0.1569 - val_accuracy: 0.9395\n",
      "Epoch 48/100\n",
      "1600/1600 [==============================] - 3s 2ms/step - loss: 0.1548 - accuracy: 0.9409 - val_loss: 0.1568 - val_accuracy: 0.9405\n",
      "Epoch 49/100\n",
      "1600/1600 [==============================] - 3s 2ms/step - loss: 0.1546 - accuracy: 0.9406 - val_loss: 0.1567 - val_accuracy: 0.9410\n",
      "Epoch 50/100\n",
      "1600/1600 [==============================] - 3s 2ms/step - loss: 0.1544 - accuracy: 0.9409 - val_loss: 0.1566 - val_accuracy: 0.9400\n",
      "Epoch 51/100\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.1543 - accuracy: 0.9408 - val_loss: 0.1565 - val_accuracy: 0.9395\n",
      "Epoch 52/100\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.1541 - accuracy: 0.9399 - val_loss: 0.1564 - val_accuracy: 0.9395\n",
      "Epoch 53/100\n",
      "1600/1600 [==============================] - 2s 2ms/step - loss: 0.1539 - accuracy: 0.9404 - val_loss: 0.1564 - val_accuracy: 0.9390\n",
      "Epoch 54/100\n",
      "1600/1600 [==============================] - 3s 2ms/step - loss: 0.1537 - accuracy: 0.9402 - val_loss: 0.1563 - val_accuracy: 0.9390\n",
      "Epoch 55/100\n",
      "1600/1600 [==============================] - 3s 2ms/step - loss: 0.1536 - accuracy: 0.9402 - val_loss: 0.1562 - val_accuracy: 0.9380\n",
      "Epoch 56/100\n",
      "1600/1600 [==============================] - 3s 2ms/step - loss: 0.1534 - accuracy: 0.9405 - val_loss: 0.1561 - val_accuracy: 0.9380\n",
      "Epoch 57/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.1532 - accuracy: 0.9409 - val_loss: 0.1560 - val_accuracy: 0.9380\n",
      "Epoch 58/100\n",
      "1600/1600 [==============================] - 2s 2ms/step - loss: 0.1531 - accuracy: 0.9408 - val_loss: 0.1559 - val_accuracy: 0.9380\n",
      "Epoch 59/100\n",
      "1600/1600 [==============================] - 3s 2ms/step - loss: 0.1529 - accuracy: 0.9411 - val_loss: 0.1558 - val_accuracy: 0.9385\n",
      "Epoch 60/100\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.1528 - accuracy: 0.9411 - val_loss: 0.1557 - val_accuracy: 0.9390\n",
      "Epoch 61/100\n",
      "1600/1600 [==============================] - 3s 2ms/step - loss: 0.1526 - accuracy: 0.9411 - val_loss: 0.1556 - val_accuracy: 0.9395\n",
      "Epoch 62/100\n",
      "1600/1600 [==============================] - 3s 2ms/step - loss: 0.1524 - accuracy: 0.9416 - val_loss: 0.1554 - val_accuracy: 0.9400\n",
      "Epoch 63/100\n",
      "1600/1600 [==============================] - 3s 2ms/step - loss: 0.1523 - accuracy: 0.9411 - val_loss: 0.1553 - val_accuracy: 0.9395\n",
      "Epoch 64/100\n",
      "1600/1600 [==============================] - 3s 2ms/step - loss: 0.1521 - accuracy: 0.9411 - val_loss: 0.1552 - val_accuracy: 0.9400\n",
      "Epoch 65/100\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.1520 - accuracy: 0.9410 - val_loss: 0.1551 - val_accuracy: 0.9395\n",
      "Epoch 66/100\n",
      "1600/1600 [==============================] - 2s 2ms/step - loss: 0.1518 - accuracy: 0.9410 - val_loss: 0.1550 - val_accuracy: 0.9405\n",
      "Epoch 67/100\n",
      "1600/1600 [==============================] - 3s 2ms/step - loss: 0.1516 - accuracy: 0.9414 - val_loss: 0.1549 - val_accuracy: 0.9400\n",
      "Epoch 68/100\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.1515 - accuracy: 0.9420 - val_loss: 0.1548 - val_accuracy: 0.9405\n",
      "Epoch 69/100\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.1513 - accuracy: 0.9419 - val_loss: 0.1547 - val_accuracy: 0.9405\n",
      "Epoch 70/100\n",
      "1600/1600 [==============================] - 2s 2ms/step - loss: 0.1511 - accuracy: 0.9417 - val_loss: 0.1546 - val_accuracy: 0.9400\n",
      "Epoch 71/100\n",
      "1600/1600 [==============================] - 3s 2ms/step - loss: 0.1510 - accuracy: 0.9417 - val_loss: 0.1545 - val_accuracy: 0.9410\n",
      "Epoch 72/100\n",
      "1600/1600 [==============================] - 3s 2ms/step - loss: 0.1508 - accuracy: 0.9419 - val_loss: 0.1544 - val_accuracy: 0.9405\n",
      "Epoch 73/100\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.1506 - accuracy: 0.9423 - val_loss: 0.1543 - val_accuracy: 0.9400\n",
      "Epoch 74/100\n",
      "1600/1600 [==============================] - 3s 2ms/step - loss: 0.1504 - accuracy: 0.9427 - val_loss: 0.1542 - val_accuracy: 0.9400\n",
      "Epoch 75/100\n",
      "1600/1600 [==============================] - 2s 2ms/step - loss: 0.1502 - accuracy: 0.9426 - val_loss: 0.1542 - val_accuracy: 0.9400\n",
      "Epoch 76/100\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.1500 - accuracy: 0.9427 - val_loss: 0.1541 - val_accuracy: 0.9405\n",
      "Epoch 77/100\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.1499 - accuracy: 0.9430 - val_loss: 0.1541 - val_accuracy: 0.9415\n",
      "Epoch 78/100\n",
      "1600/1600 [==============================] - 3s 2ms/step - loss: 0.1497 - accuracy: 0.9434 - val_loss: 0.1540 - val_accuracy: 0.9410\n",
      "Epoch 79/100\n",
      "1600/1600 [==============================] - 3s 2ms/step - loss: 0.1496 - accuracy: 0.9436 - val_loss: 0.1540 - val_accuracy: 0.9410\n",
      "Epoch 80/100\n",
      "1600/1600 [==============================] - 3s 2ms/step - loss: 0.1494 - accuracy: 0.9436 - val_loss: 0.1539 - val_accuracy: 0.9420\n",
      "Epoch 81/100\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.1493 - accuracy: 0.9438 - val_loss: 0.1538 - val_accuracy: 0.9425\n",
      "Epoch 82/100\n",
      "1600/1600 [==============================] - 3s 2ms/step - loss: 0.1491 - accuracy: 0.9440 - val_loss: 0.1538 - val_accuracy: 0.9430\n",
      "Epoch 83/100\n",
      "1600/1600 [==============================] - 3s 2ms/step - loss: 0.1490 - accuracy: 0.9440 - val_loss: 0.1537 - val_accuracy: 0.9435\n",
      "Epoch 84/100\n",
      "1600/1600 [==============================] - 2s 2ms/step - loss: 0.1489 - accuracy: 0.9439 - val_loss: 0.1536 - val_accuracy: 0.9430\n",
      "Epoch 85/100\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.1487 - accuracy: 0.9441 - val_loss: 0.1535 - val_accuracy: 0.9430\n",
      "Epoch 86/100\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.1486 - accuracy: 0.9442 - val_loss: 0.1533 - val_accuracy: 0.9430\n",
      "Epoch 87/100\n",
      "1600/1600 [==============================] - 2s 2ms/step - loss: 0.1485 - accuracy: 0.9445 - val_loss: 0.1532 - val_accuracy: 0.9435\n",
      "Epoch 88/100\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.1483 - accuracy: 0.9442 - val_loss: 0.1530 - val_accuracy: 0.9435\n",
      "Epoch 89/100\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.1482 - accuracy: 0.9444 - val_loss: 0.1528 - val_accuracy: 0.9435\n",
      "Epoch 90/100\n",
      "1600/1600 [==============================] - 3s 2ms/step - loss: 0.1481 - accuracy: 0.9445 - val_loss: 0.1526 - val_accuracy: 0.9415\n",
      "Epoch 91/100\n",
      "1600/1600 [==============================] - 3s 2ms/step - loss: 0.1479 - accuracy: 0.9448 - val_loss: 0.1524 - val_accuracy: 0.9415\n",
      "Epoch 92/100\n",
      "1600/1600 [==============================] - 3s 2ms/step - loss: 0.1478 - accuracy: 0.9448 - val_loss: 0.1522 - val_accuracy: 0.9420\n",
      "Epoch 93/100\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.1476 - accuracy: 0.9446 - val_loss: 0.1520 - val_accuracy: 0.9425\n",
      "Epoch 94/100\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.1475 - accuracy: 0.9446 - val_loss: 0.1519 - val_accuracy: 0.9425\n",
      "Epoch 95/100\n",
      "1600/1600 [==============================] - 3s 2ms/step - loss: 0.1473 - accuracy: 0.9444 - val_loss: 0.1517 - val_accuracy: 0.9410\n",
      "Epoch 96/100\n",
      "1600/1600 [==============================] - 2s 2ms/step - loss: 0.1471 - accuracy: 0.9445 - val_loss: 0.1516 - val_accuracy: 0.9405\n",
      "Epoch 97/100\n",
      "1600/1600 [==============================] - 3s 2ms/step - loss: 0.1470 - accuracy: 0.9445 - val_loss: 0.1514 - val_accuracy: 0.9410\n",
      "Epoch 98/100\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.1468 - accuracy: 0.9449 - val_loss: 0.1513 - val_accuracy: 0.9405\n",
      "Epoch 99/100\n",
      "1600/1600 [==============================] - 2s 2ms/step - loss: 0.1466 - accuracy: 0.9452 - val_loss: 0.1511 - val_accuracy: 0.9400\n",
      "Epoch 100/100\n",
      "1600/1600 [==============================] - 2s 2ms/step - loss: 0.1464 - accuracy: 0.9455 - val_loss: 0.1510 - val_accuracy: 0.9405\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X,y, epochs=100,batch_size=5,verbose=1,validation_split=0.2,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "486620d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAA4fklEQVR4nO3deXyU9bX48c/JZN9D2BMgoMimLBpxt1Sse8VardJrK9rW6k+t1i5ql9v93t5WvbbV1lr3VkutW9WLS0WpdUNAUGQTZA1JIIGQCSSTzHJ+f3yfhGEYYJBMBjLn/XrllXm2mfNEfM58d1FVjDHGmFgZqQ7AGGPMwckShDHGmLgsQRhjjInLEoQxxpi4LEEYY4yJyxKEMcaYuCxBmLQnIlUioiKSmcC5M0TkjZ6Iy5hUswRhDikislZEOkSkb8z+Rd5DvipFoRnT61iCMIeiNcD0zg0ROQrIS104B4dESkDG7A9LEOZQ9Gfgy1HblwOPRJ8gIiUi8oiINIjIOhH5gYhkeMd8InKbiDSKyGrg3DjX3i8idSKyUUR+LiK+RAITkb+LSL2INIvI6yIyLupYnojc7sXTLCJviEied+xkEXlLRLaJyAYRmeHtnyMiX416j12quLxS07UishJY6e37jfcefhFZICKnRJ3vE5HvicjHItLiHR8iIneLyO0x9/KciNyYyH2b3skShDkUvQMUi8gY78F9CfCXmHN+B5QAI4BP4RLKFd6xrwHnAZOAauCimGsfBkLA4d45ZwBfJTEvACOB/sB7wKNRx24DjgFOBPoA3wUiIjLUu+53QD9gIrAowc8DuAA4Dhjrbc/z3qMP8BjwdxHJ9Y7dhCt9nQMUA1cCrbh7nh6VRPsCU4G/7kccprdRVfuxn0PmB1gLnA78APhv4Czgn0AmoEAV4APagbFR130dmOO9fhW4OurYGd61mcAA79q8qOPTgde81zOANxKMtdR73xLcl7E2YEKc824Fnt7De8wBvhq1vcvne+9/2j7iaOr8XGAFMG0P5y0DPuO9vg6Yler/3vaT2h+rszSHqj8DrwPDialeAvoC2cC6qH3rgArv9WBgQ8yxTsOALKBORDr3ZcScH5dXmvkFcDGuJBCJiicHyAU+jnPpkD3sT9QusYnIt3AlnsG4BFLsxbCvz3oYuAyXcC8DfnMAMZlewKqYzCFJVdfhGqvPAZ6KOdwIBHEP+05DgY3e6zrcgzL6WKcNuBJEX1Ut9X6KVXUc+/ZFYBquhFOCK80AiBdTADgsznUb9rAfYAeQH7U9MM45XVMye+0NNwNfAMpUtRRo9mLY12f9BZgmIhOAMcAzezjPpAlLEOZQ9hVc9cqO6J2qGgYeB34hIkUiMgxX997ZTvE48A0RqRSRMuCWqGvrgJeB20WkWEQyROQwEflUAvEU4ZLLFtxD/b+i3jcCPADcISKDvcbiE0QkB9dOcbqIfEFEMkWkXEQmepcuAi4UkXwROdy7533FEAIagEwR+U9cCaLTfcDPRGSkOONFpNyLsQbXfvFn4ElVbUvgnk0vZgnCHLJU9WNVnb+Hw9fjvn2vBt7ANdY+4B37E/AS8D6uITm2BPJlXBXVUlz9/RPAoARCegRXXbXRu/admOPfBhbjHsJbgf8BMlR1Pa4k9C1v/yJggnfN/wIdwCZcFdCj7N1LuAbvj7xYAuxaBXUHLkG+DPiB+9m1i/DDwFG4JGHSnKjagkHGGEdETsWVtKq8Uo9JY1aCMMYAICJZwA3AfZYcDFiCMMYAIjIG2IarSrszpcGYg4ZVMRljjInLShDGGGPi6lUD5fr27atVVVWpDsMYYw4ZCxYsaFTVfvGO9aoEUVVVxfz5e+r1aIwxJpaIrNvTMatiMsYYE5clCGOMMXFZgjDGGBNXr2qDiCcYDFJTU0MgEEh1KL1Cbm4ulZWVZGVlpToUY0yS9foEUVNTQ1FREVVVVURN32w+AVVly5Yt1NTUMHz48FSHY4xJsl5fxRQIBCgvL7fk0A1EhPLyciuNGZMmen2CACw5dCP7WxqTPnp9FZMxxvQ2rR0h1ja2UtPUSk1TG+2hCNdM2dM6UJ+cJYgk2rJlC1OnTgWgvr4en89Hv35uwOK7775Ldnb2Hq+dP38+jzzyCL/97W97JFZjzIEJhiPUNwfY0NTKJn+AiDcfrggU5GRSlJtJcW4Wvgzp2l9ekEPfwuw9lsxVlXp/gGV1fpbW+llW18KyOj9rtuwgehq9/kU5liAONeXl5SxatAiAH//4xxQWFvLtb3+763goFCIzM/5/gurqaqqrq3siTGN6LVVlW2uQjdvaCATDXftzs3wU52ZRlJtJWzBMTVMbNU2tNG5vx98WoiUQpHF7R9c39LZgmMGleVSU5tGnIJuWgDvHHwjhbwvSEgjS0h7ik8x9mpuVweDSPFDc+wWChMIuuyjs8p5D++QzdlAx0yZWMHJAIUPK8qkoy6MsPzm9Ci1B9LAZM2bQp08fFi5cyNFHH80ll1zCjTfeSFtbG3l5eTz44IOMGjWKOXPmcNttt/H888/z4x//mPXr17N69WrWr1/PjTfeyDe+8Y1U34oxPa7zG/WK+hY2eA/1+uYAoYh2Hd/RHsYfCNLcFqS+OUBrR2diUA6TWqozPqJNc3gnMobNlO32GRkCxXlZ9MnPZkxxgC9UrGBgqNY9vBs7aKuNkJOZQU5WBu05fflw+LkU5eVQkpdFRWkelWV5DCjJJSvDNfFGVNneHupKKhHviR9RaGhpp6aplY3b2sgQoTjPJa1s387m4b6FOYwdXMzogUUU5fZs9/K0ShA/eW4JS2v93fqeYwcX86PPJrKe/U4fffQRr7zyCj6fD7/fz+uvv05mZiavvPIK3/ve93jyySd3u2b58uW89tprtLS0MGrUKK655hobi2AOeZGIsry+hfVbWynOzaQ4L4uczAz83sO0qbWDjU1tbNzWxtrGVpbX+2lqDXZdn+UTBpbk7vJALcxx7zOoOIfPD9nOpPCHDN+xiPLGeWQHGnf5/Ob8oezIH0JuViY5WT5yMjPwZQgC0LwBapfHDzyEW8y1Baisg/N+Bxm+7v7zpFxaJYiDxcUXX4zP5/4xNTc3c/nll7Ny5UpEhGAwGPeac889l5ycHHJycujfvz+bNm2isrKyJ8M2ZhcbtrbSEY501a3nZu39AamqNLS0s6TOz7I6PwvXb2Pe2q1sa43/bz5a38JsKsryOXPcQMYMct+mq/oW0K8wh4yMqPr7hhWweg6sfQPWvQWtXkIoGgwjT4Oqk2DYSdCxHda+QcnaNynZvsmdE/J+OpUMgfGXQNUpMGBc/ATwxp0w578gEoIL/rD7OeEQ1H8A6950MdXMg6DXTTzDB0d/Gab+CDL33B6ZSklNECJyFvAbwIdbxvCXMcfLcAvJH4bLx1eq6odRx33AfGCjqp53oPHs7zf9ZCkoKOh6/cMf/pBPf/rTPP3006xdu5YpU6bEvSYnJ6frtc/nIxQKxT3PmHhC4QhL6/zMXb2VmqZWJgwp5bgR5VSU5iX8HjvaQyyp9fPq8s38c2k9Hzfs2OV4dmYGxblZFOdmkp258xt9eyji6uvbQnSEd65kOqw8nzPGDuC44eUcMaCIHR2uPr895CWdvCxK8rIYXJJHXnsjrHoF+o+BgZXgi3l01cyHf/0PrHzZbZcMhZGfgaqTXUIoq3KtwtEGT4ITr0/4/uOacjNkZMCrP4eOHe6zwL3e8A6snwsdLW5fn8Ng1NmQW+q2/bXw9l0ukV30APQ5+AafJi1BeA/3u4HPADXAPBF5VlWXRp32PWCRqn5OREZ750+NOn4DsAwoTlacqdbc3ExFRQUADz30UGqD6SX8gSAfbmxmYHEuw8oLunqNHKi2jjANLe34A0H8bUH322uk1GCAMbqSEdsXUti+mbVDL2J55kgat7eTn+VzddoF2ZxwWDk5mZ+sKqIlEGR5vevF0tYRpjgvi+LcLJrbgiyta2ZZXQubW+IPYmzaEWR7u/tSkZuVwcNvuxme+xflkJPlHuaCeNUzmRTlZuHzHqihSIRVm7ezbmsrqpCZIRw3og+XHT+MPgXZXX8DfyBISyBEc1uQYChCQbiZT/v/QUmmn9qKSTT2PZbCPoMYO6iY0YOKKclLoIrUXwezfwYLHoKQd285xVBZDdneF60djbD+bcgrg9N+AEd9AcqGfaK/8Sdy6ncgIxNm/xSWP79zf99RMP5ilzSGnQTFg3a/dtzn4Nnr4I+nwrFfcQltyHHQ3gJr34T1b4EvZ2fJJ79P/BjCod2TZjdIZgliMrBKVVcDiMhMYBoQnSDGAv8NoKrLRaRKRAao6iYRqQTOBX4B3JTEOFPqu9/9Lpdffjl33HEHp512WqrDOSSEI66hcmNTG3XNbTS3uQdTQ0s789dtZWmtH6/NkrwsH6MGFjF2cDFjBhUzdlBR14NJFdqCYfxtoa6HfksgFJUA3IOvYXs7G5va2LKjY7dYhkk91/r+wfm+t8iVIBEVAmQzfumjbAlPYGboc7ynI8HVatO3MJsvTh7KJZOHUt8cYO6aLSxcv801jOZmUZSbRZbPnatAY0t7Vw+b2uY9j2AvyslkzKBiqof1IV46LMjJpLqqjOOGFtEvo4XlOwqYu6aJpXV+IhFFNExhsJHacD7NgQgbtraSHQlwXscLnNXxMttzBtB8xLFkVZ3A2Pxt5Nc+C/PfgfaoNr2y4e5BNvZE98B+908QbIWsPNj2NKzDPTSbToIdJ7lqG4kzVrd1i1cl86b7dh0JwYTpcOyVsHWNq6qpfQ9a6t35GZlw+k/cAzanaB//epLk5G/C5KsgHNwZU07hvq8bez4MmgDPfxPe+h288b/ub6JeSSun2L3n3D+47f7jvGRxImQVwLo33N+pYwdc+06331bS1qQWkYuAs1T1q972l4DjVPW6qHP+C8hV1ZtEZDLwlnfOAhF5Apc8ioBvJ1LFVF1drbELBi1btowxY8Z0232Znv2bhsIRNrW0s3JTC3PXbGXu6i0s3thMMLz7v9u8LB8ThpRw3PByJg0tpaGlnaVeffeyuhaa2/Zd1w2uF0thTiYl+Vkc7VvLhMw1lOVnU5afTVFuJnlZPnKzffTZ8h4lq54BXzahoy5l84BTWZ0/nqa2MBPqnqBy+X34Ak1E8sppG3QcdcXjeWtDgOX1LYTJYElkGEu1iqp+RWRlZHR9Aw9FdlbD9MnPptLrynhYv4KuRFecm9X1bT0/20dlWV78vvShdlf9sksdeCsUDXLfSPuNgo3vuW+qgWb3LXzoia664/2/uof10BMg4IfNS3a+b365e0gVDnDbGoFNS2HjAogE3UPuyM/DKd+G8sOg7n2vXeBNWPf2zmqXvRlwJAz/FBx3lasi6u06dsCGubD+HZcYqk6CgeMhEnYJsfPvt/4d998QICMLKo5x5376+5+ooVxEFqhq3D71yUwQFwNnxiSIyap6fdQ5xbg2iknAYmA08FVgCHCOqv4/EZnCXhKEiFwFXAUwdOjQY9at23VxJEsQ3a87/qbBcITVDTtYWtfM6oYdbGxqo6apjabWnd/SWzvC1PsDhL3iQGaGML6yhOqqPlSVF1BRlkdFaS4lee7BvbdGUlWltjnA8jp/VLdHl1SKc4Rhqx4hP9SMb/jJ5I44kYyGZTDnl/Dx7D3fRGae+9Z64jegaMDux9u3w9J/uP+x174Bzet3OyWSXUTG0OMgz6s6kAw4/HQ48sJP1ism2OaSwNo33cNkw7sQbgfEfWOvOtk9bDvP2V7v6sarTnIP5PoPXKxNa+GwqfCpm2Hoce69W7e6BFBSCf1G716nD9DR6s4pHuwSQzydDbdNa+IfzyqAIZP3XJ2S7sJBqF0EoTaoqIbs/AN6u1QliBOAH6vqmd72rQCq+t97OF+ANcB44FbgS7g+Bbm4NoinVPWyvX2mlSB6xif9m+5oD/HCh/U89V4N89c2dTVYZggMKsmjoiyP8oLsrudOti/DSwL5VPXNZ+KQUvKzu7lWtLkGnviKa1AUH2h45+/8cvfwP+oiV2UQK6doZz14InZscd+uwdWn18x3D+MN7+78Rhhshe2boPxw9+172In7eFN11S6dVTIb50O4wyWagUfBsJPdw3/oCbs/cFVdXXdunCa+jtYDfvCYQ8PeEkQy2yDmASNFZDiwEbgU+GJMYKVAq6p24EoOr6uqH5cgbvXOmYIrQew1OZiDR3NrkFdXbGL2ss00bm8H3KCgxTXNtAXDDCvP5/IThzFucAljBhUzol8BWb44ddHJpArLnoXnbnDfyC68z/UwqXnX1Xvnl7suiPuTAPaloHzX7bIql3yiRSKw/Dn416/gmasTf2/xubrs477uumUOPR5yS/ZxjcRPDmDJwQBJTBCqGhKR64CXcN1cH1DVJSJytXf8HmAM8IiIhHGN119JVjyme63c1ELNtrauevD6ZldFtH5rKx/UNBOOKP2Kchjed+cD9oJJFXz+6AqOGVbWM7PCbt/s1bvPh9Ihrs59wDhY+U/XJbL2PVfHe/FDO6tDDjvN/aRKRgaMnQajPwtr5rhePPtSOMBVA6Wqgdb0WkkdB6Gqs4BZMfvuiXr9NjByH+8xB5iThPDMJxCORGhq7eCLD7++y35fhjCoJJeK0jy+fuoIPjN2ABMqS3cOYgq1u2oPX0zXxnDIVedk5uy6PxJxDaR4VaDZBfG/zbdtc1Uq4KpnNszb2bNjy0ovuOyd52Tmuuqd0mHw2d+63jEH4yCljIzUJipjsJHUZj9sDwSpaWqjtT3M1z81gjPHDaQ41/WZLy/IJjO2mqh2kesX3lk3npHpGh+HnewegGvfdL02Qu07e2Lkl7sqnnVvQlvTzvfKzIWz/huOucJVjYQ64JUfwTu/3z3QnGJX5370l9xnDZoALXXufWvmuQFS47+we7IyxuwiaY3UqXAwNlJPmTKFW2+9lTPPPLNr35133slHH33E73+/+8NtypQp3HbbbVRXV3POOefw2GOPUVpauss58WaGjfXMM89wxBFHMHbsWAD+8z//k1NPPZXTTz99v+JXVfyBEI3b29nRHiIn00egYT0TjtrLqPRI2NWhv/4rtz1ogqveCQfdg3+TN1i+3xiXFLLy3cO7dqErTZRVeQ/28Tt78iz/P/j4VTew6ORvuraD2oVw9OXuPHAJaNAEV23UC+fFMSYZUtVIbYDp06czc+bMXRLEzJkz+fWvf73Pa2fNmrXPc/bkmWee4bzzzutKED/96U8TvlZVae3wZsRsDdIRjpDty2BQSS7lBTmsaNpLg7K/Dp76Gqz9N4y/FM7+petbH611q2skjm20bd/u5sgpGrj7+x5zJbx5p5vSYMnTrgH2kr/AmM8mfF/GmP2TFkuOptJFF13E888/T3u7682zdu1aamtreeyxx6iurmbcuHH86Ec/inttVVUVjY1usrFf/OIXjBo1itNPP50VK1Z0nfOnP/2JY489lgkTJvD5z3+e1tZW3nrrLZ599lm+853vMHHiRD7++GNmzJjBE088AcDs2bOZNGkSRx11FFdeeSWBQIBAMMzQYcO44Tu3Mm78RCZOGM+8RR+SnZnBsPJ8Rg0sol9R7q4To8Vq3gj3TnH94C/4A1z4x92TA7julrHJAdzI03jJAVyV1Ck3wRUvwDEz4Oo3LDkYk2TpVYJ44RaoX9y97znwKPcteQ/Ky8uZPHkyL774ItOmTWPmzJlccskl3HrrrfTp04dwOMzUqVP54IMPGD9+fNz3WLBgATNnzmThwoWEQiGOPvpojjnmGAAuvPBCvva1rwHwgx/8gPvvv5/rr7+e888/n/POO4+LLtq1G2UgEGDGjBnMnj2bqhGHc9mXvsRPf3Unl155NeGIUljSh5f+9TZ/e+Q+/vHIPZx///2J/R2CAfjbZa4E8JWX3d8lGYYet3PgljEmqawE0QM6q5nAVS9Nnz6dxx9/nKOPPppJkyaxZMkSli5dusfr//3vf/O5z32O/Px8iouLOf/887uOffjhh5xyyikcddRRPProoyxZsmS361WVcCSCvy3Iv95dxKDKoUSKBrK83s9npn2BBXPfoqI0j0xfBtfMmM6QPvmccsJxxI5K3yNVeP5G1230wnuTlxyMMT0qvUoQe/mmn0wXXHABN910E++99x5tbW2UlZVx2223MW/ePMrKypgxYwaBwJ4nYgP2OG5gxowZPPPMM0yYMIGHHnqIOXPmdB3rCIXZsLXVm3wuRFNrB6XejJ4FOZn0ycygsk8eBTmZlBfmIEBubi6wH1OKhzrgnbvdvD1Tvgejz03ob2KMOfhZCaIHFBYWMmXKFK688kqmT5+O3++noKCAkpISNm3axAsvvLDX60899VSefvpp2traaGlp4bnnnus61tLSQv8BA9m8bQcPPvxn2oJu/qKIL5dVGxtpbgtSkptFQU4mFaV5nHNKNfUbN9C+tZb+xbn87bHH+NSnPrXvmwgH3RQQ/jo3qdsrP4aHz4dfDnWvR5/npj02xvQa6VWCSKHp06dz4YUXMnPmTEaPHs2kSZMYN24cI0aM4KSTTtrrtZ1rV0+cOJFBFUOoPu5EtrcH2bK9nZtu+SHHTp7MoIohHD56LK3bt7PZH+CsaRfyk+/ewNN/uY8nnniC7MwMMn0Z5Obm8uCDD3LxxRcTCoU49thjufrqvUzpEO5wI5J3NNI1aC3Q7FbSGnAkHHO568I66mzXkGyM6TVsHMQhoK0jxJbtHTS1BVFVhK5HNb4MoSQvi7L8bPKzfQc2hYWqKyVs37RzPvpOeX3cjKWZub3ib2qMcWwcxCEoGI6wrdUt2h4IhskQoU9+FuWFOeRkZhBRt3BOZobsvetposJBN8Vzx3bIKYEs1xaBZLiuqrFTYRhjej1LEAeh7YEga7e0ElElL9vH4NI8SvOydpnKwid0z1KaGnFTWvhr3fxHJUPdOIWemEzPGHNQS4sEoao9M3toN2gJBFm3pZXszAyG9snf6yI4B0QjbkTz9k2unSErD8qHud97u6wXVUkaY/au1yeI3NxctmzZQnl5+UGfJFq8kkNOZgYj+hbsPvldd9gtMeS7FcJyivdZalBVtmzZ0tUV1hjTu/X6BFFZWUlNTQ0NDQ2pDmWvWjvCNLV2kJUh9C3MYeXWvTysI2E3A2q43U1Kl10Yf/H3WMFWNz12JAS+HLdYTFYEGmuB2oTizM3NpbKyMqFzjTGHtl6fILKyshg+fHiqw9gjVeX3cz7m1y+tZnJVH+798jGU5sdZnyASdpPUvXEnbPKmC8kqgOAO14h8wrVQ/ZX46/gG2+DFW2HBgzBoIkz9IRz2KWtnMMbsVa9PEAezcET5/tOLmTlvA9MmDuZXF40nJzOmzUEVljwFc34JjR+5xeLP+LlbfH7geLfmwuu/crOcvvoLN81F1cnQ9wiXADQC794Hm5fASTfAaT+0dRCMMQmxBJFC97+xmpnzNnDtpw/j22eM2r2NJOB3cxx9+CT0HwcXPwxjzt91QFrlMfDFv0HdB7Billtic/4DbtW0Tvl94T+ehJH7txaEMSa9WYJIkbWNO7j95Y/4zNgB8ZND7UL4+xWwbZ371n/yTXsfqTxo/M6Fc0Lt3nKdnrw+O8c1GGNMgixBpEAkotz85AdkZ2bw8wuO3DU5qMLcP8I/f+i++c/4Pxh24v59QGYOFA/u3qCNMWnHEkQKzJy3gblrtvLLC49iQHHUN/vWrfDs9W4d5yPOgmm/j7+wjjHG9ACbXa2HNa5fzvBZX+SqwWu55NghOw9seBf+eCp89BKc+V8wfaYlB2NMSiU1QYjIWSKyQkRWicgtcY6XicjTIvKBiLwrIkd6+4eIyGsiskxElojIDcmMsyetfOEuTpDF3Lr1+8irP3PrKfz7DnjgLDeW4SsvuS6r1gXVGJNiSatiEhEfcDfwGaAGmCciz6pq9NJp3wMWqernRGS0d/5UIAR8S1XfE5EiYIGI/DPm2kNOa3uQIXUv8VHeRI4YfRT8+3ZY8JBrUB57AZz/W8gtSXWYxhgDJLcEMRlYpaqrVbUDmAlMizlnLDAbQFWXA1UiMkBV61T1PW9/C7AMqEhirD1izpyXqWQz2cd8EabdBRfeB7mlcO4dcPFDlhyMMQeVZDZSVwAborZrgNjV5t8HLgTeEJHJwDCgEtjUeYKIVAGTgLnxPkRErgKuAhg6dGg3hd79IhGlZf7jBMlk2IlfcDvHX+x+jDHmIJTMEkS8SvTYqUB/CZSJyCLgemAhrnrJvYFIIfAkcKOq+uN9iKreq6rVqlrdr1+/bgk8Gf61YjMndbzBlgEnIfllqQ7HGGP2KZkliBogqpsOlcTMCOc99K8AEDcYYI33g4hk4ZLDo6r6VBLj7BH/eu0FPi2NhI67NNWhGGNMQpJZgpgHjBSR4SKSDVwKPBt9goiUescAvgq8rqp+L1ncDyxT1TuSGGOPWFHfwpDaFwlLFpljz011OMYYk5CkJQhVDQHXAS/hGpkfV9UlInK1iFztnTYGWCIiy4Gzgc7urCcBXwJOE5FF3s85yYo12W57cRnn+uYSPmyqNUQbYw4ZSR1JraqzgFkx++6Jev02MDLOdW8Qvw3jkPP2x1vYuuINBuZshfEXpTocY4xJmI2kTqJIRPnFrKV8Nn8pKj444oxUh2SMMQmzBJFEzyzayIcb/Xy25GNk8ESrXjLGHFIsQSRJW0eYX7+0gmMrcuizbTFUnZLqkIwxZr9YgkiSP7+zlrrmAD87egcSCVqCMMYccixBJEEoHOGhN9dywohyRrctgoxMGHp8qsMyxpj9YgkiCV5asona5gBXnjwc1v4bBh8NOYWpDssYY/aLJYgkeODNNQwrz+e04Xmw8T0YbtVLxphDjyWIbrZowzYWrGtixolV+Grmgoat/cEYc0iyBNHNHnxzDUU5mVxcPcRVL2VkwZDYSWyNMebgZwmiG9U3B/i/D+r4wrFDKMzJhDX/hspjITs/1aEZY8x+swTRjR6bu46wKpefUAWBZqhbZO0PxphDliWIbqKqPLVwIycf3peh5fmw9k3QiLU/GGMOWZYgusmCdU3UNLXxuUkV0LoVXroVCge6KiZjjDkEJXU213Ty9MKN5GX5OHNMX/j7JeCvhRmzICs31aEZY8wnYgmiG3SEIjz/QR1njBtAwb9+CqvnwLS7YYiVHowxhy6rYuoGr63YTHNbkK+VfwDv3A2Tvw6TLkt1WMYYc0AsQXSDZxZupDw/i3Erfg/9x8GZv0h1SMYYc8AsQRyg5rYgs5dt5pvD1yONy+Gkb4AvK9VhGWPMAbMEcYBeWFxHRzjCtLanoGgQjLsw1SEZY0y3sARxgP65dBOnldZTVPsmHHc1ZGanOiRjjOkW1ovpAATDEd5ZvYW/lL8EkUI4ZkaqQzLGmG6T1BKEiJwlIitEZJWI3BLneJmIPC0iH4jIuyJyZKLXHgze37CNoo7NTNg2GyZ9CfJKUx2SMcZ0m6QlCBHxAXcDZwNjgekiMjbmtO8Bi1R1PPBl4Df7cW3KrV7wT+7O/i1CBI6/JtXhGGNMt0pmCWIysEpVV6tqBzATmBZzzlhgNoCqLgeqRGRAgtemzubl8NB5fGHxVYzwNSDn/w7KhqU6KmOM6VbJTBAVwIao7RpvX7T3gQsBRGQyMAyoTPBavOuuEpH5IjK/oaGhm0LfhxdvRusX87PQl3mg+h82KM4Y0yslM0FInH0as/1LoExEFgHXAwuBUILXup2q96pqtapW9+vX7wDCTVA4CBvepWbIedwfOosTRlUm/zONMSYFktmLqQYYErVdCdRGn6CqfuAKABERYI33k7+va1Om7gMItjI3NIqczAyOHlaW6oiMMSYpklmCmAeMFJHhIpINXAo8G32CiJR6xwC+CrzuJY19Xpsy698C4MnGoUwe3ofcLF+KAzLGmORIWoJQ1RBwHfASsAx4XFWXiMjVInK1d9oYYImILMf1WLphb9cmK9b9su5tQqVVvN2QxUmH9011NMYYkzRJHSinqrOAWTH77ol6/TYwMtFrUy4SgfVvs7HvqVAPJ1uCMMb0YjbVxv5o/AjatjI3MorS/CzGDipOdUTGGJM0liD2h9f+8FLLCCZUlpKREa+zlTHG9A6WIPbHurfRgv68vqWIsYOt9GCM6d0sQeyP9W/j719NMIxVLxljer19JggROU9ELJFs2wDNG1idPx7AShDGmF4vkQf/pcBKEfmViIxJdkAHrfVvAzAvMprcrAyqygtSHJAxxiTXPhOEql4GTAI+Bh4Ukbe9+Y+Kkh7dwWTdW5BTzGvb+jF6YDE+a6A2xvRyCVUdeaObn8TNqjoI+Bzwnohcn8TYDi4189DKY1lSt8Oql4wxaSGRNojPisjTwKtAFjBZVc8GJgDfTnJ8B4f27bB5KS19J+APhBhjDdTGmDSQyEjqi4H/VdXXo3eqaquIXJmcsA4ydYtAI3ycPRqwHkzGmPSQSBXTj4B3OzdEJE9EqgBUdXaS4jq4bFwAwLyO4YjA6IHp1fxijElPiSSIvwORqO2wty991MyHsioWNGYwvLyAgpykTmFljDEHhUQSRKa37CcA3uvsvZzf+2xcABXHsKyuxdofjDFpI5EE0SAi53duiMg0oDF5IR1k/HXg30hgwCTWb221HkzGmLSRSF3J1cCjInIXbinQDcCXkxrVwcRrf1idPQZotwZqY0za2GeCUNWPgeNFpBAQVW1JflgHkY0LICOT9zoqgY+tiskYkzYSam0VkXOBcUCuWzoaVPWnSYzr4LFxPgw4ksWbOuhTkM2A4pxUR2SMMT0ikYFy9wCXANfjqpguBoYlOa6DQyQMGxdCxTGsatjOyP6FdCZIY4zp7RJppD5RVb8MNKnqT4ATgCHJDesg0bgSOlqgsprabW1UlOWlOiJjjOkxiSSIgPe7VUQGA0FgePJCOohsnA9AaOAkNvkDVJRagjDGpI9EEsRzIlIK/Bp4D1gL/DWJMR08Ni6AnBI25wwlojCoxBKEMSZ97DVBeAsFzVbVbar6JK7tYbSq/mciby4iZ4nIChFZJSK3xDleIiLPicj7IrJERK6IOvZNb9+HIvJXEcndz3s7cBvfg8ETqfO3AzCotOdDMMaYVNlrglDVCHB71Ha7qjYn8sYi4gPuBs4GxgLTRWRszGnXAktVdQIwBbhdRLJFpAL4BlCtqkcCPtzCRT0nEoHGj6D/WDZuc7Vsg60EYYxJI4lUMb0sIp+X/e++MxlYpaqrvek5ZgLTYs5RoMh770JgKxDyjmUCeSKSCeQDtfv5+QempRaCrdB3JHXb2gArQRhj0ksi4yBuAgqAkIgEcF1dVVX3NWKsAjfqulMNcFzMOXcBz+Ie/kXAJV6pZaOI3AasB9qAl1X15QRi7T6NH7nffY+gbnGAopxMinOzejQEY4xJpUSWHC1S1QxVzVbVYm87keHE8UocGrN9JrAIGAxMBO4SkWIRKcOVNoZ7xwpE5LK4H+KWP50vIvMbGhoSCCtBjSvd775HULutzUoPxpi0s88ShIicGm9/7AJCcdSw63iJSnavJroC+KWqKrBKRNYAo3GN4WtUtcGL4SngROAvceK4F7gXoLq6OjYBfXKNH0FOCRT2p655pfVgMsaknUSqmL4T9ToX17awADhtH9fNA0aKyHBgI66R+Ysx56wHpgL/FpEBwChgNa70cbyI5OOqmKYC8xOItfs0fgR9R4IItdvaOLLC5mAyxqSXRCbr+2z0togMAX6VwHUhEbkOeAnXC+kBVV0iIld7x+8BfgY8JCKLcUnhZlVtBBpF5AncuIsQsBCvlNBjGlfCiE8TCIbZsqPDShDGmLTzSZZGqwGOTOREVZ0FzIrZd0/U61rgjD1c+yPccqc9L+CHljroO5L6Zq+Lq42iNsakmUTaIH7HzsblDFxj8vtJjCn1tqxyv/seQW2z6+I6uMQaqY0x6SWREkR03X8I+KuqvpmkeA4OXT2YRlK73pUgBlkJwhiTZhJJEE8AAVUNgxshLSL5qtqa3NBSqPEjEB+UDafug3UADLIShDEmzSQykno2EP31OQ94JTnhHCQaP4I+wyEzm9rmAOUF2eRm+VIdlTHG9KhEEkSuqm7v3PBe5ycvpINA40roewQAdc02SM4Yk54SSRA7ROTozg0ROQY3NqF3Codg68duDARQty1gXVyNMWkpkTaIG4G/i0jnKOhBuCVIe6dt6yDc0VWCqN3WxvEj+qQ4KGOM6XmJDJSbJyKjcaOcBViuqsGkR5YqUXMwtQSCtLSHrAeTMSYt7bOKSUSuBQpU9UNVXQwUisj/S35oKdI5i2v54dTZIDljTBpLpA3ia6q6rXNDVZuAryUtolTbshIK+kF+H2q32SA5Y0z6SiRBZEQvFuStFJedvJBSLKoHU+02GyRnjElfiSSIl4DHRWSqiJwG/BV4IblhpVDjSig/DHBdXDMEBhTlpDgoY4zpeYn0YroZuAq4BtdIvRDXk6n3aW+B1kboMwJwJYj+Rblk+hLJo8YY07sksqJcBHgHt05DNW5thmVJjis1mta632VVgCtBDLZBcsaYNLXHEoSIHIFb5Gc6sAX4G4CqfrpnQkuBrWvc77LhANQ3BxgzyBYKMsakp72VIJbjSgufVdWTVfV3QLhnwkqRqBKEqlLvDzCg2EoQxpj0tLcE8XmgHnhNRP4kIlNxbRC9V9MayCuDvFJa2kO0doQZWGIN1MaY9LTHBKGqT6vqJcBoYA7wTWCAiPxBROKuAnfIa1rb1f6wyRskZyUIY0y6SqSReoeqPqqq5wGVwCLglmQHlhJb13S1P2zytwOWIIwx6Wu/+m+q6lZV/aOqnpasgFImHILmDV0liHq/K0EMtARhjElT1sG/k78GIiG3UBCwqTNB2DQbxpg0ZQmiU1cX1yrAdXEtycuyleSMMWkrqQlCRM4SkRUiskpEdmu3EJESEXlORN4XkSUickXUsVIReUJElovIMhE5IZmx7uziurMEYdVLxph0lrQE4U3qdzdwNjAWmC4iY2NOuxZYqqoTgCnA7SLSORHgb4AXVXU0MIFkj95uWgO+bCgeDLgE0b/YurgaY9JXMksQk4FVqrpaVTuAmcC0mHMUKPJmiy0EtgIhESkGTgXuB1DVjugpx5OiaS2UDoUMV6VUbyUIY0yaS2aCqAA2RG3XePui3QWMAWqBxcAN3txPI4AG4EERWSgi94lIQbwPEZGrRGS+iMxvaGj45NFGdXENhSM0tLRbA7UxJq0lM0HEG3WtMdtn4sZVDAYmAnd5pYdM4GjgD6o6CdjBHsZeqOq9qlqtqtX9+vX7ZJGq7jJIbsuODiJqYyCMMektmQmiBhgStV2JKylEuwJ4Sp1VwBrcyO0aoEZV53rnPYFLGMnR1gTt/q4urvU2itoYY5KaIOYBI0VkuNfwfCnwbMw563ETAiIiA4BRwGpVrQc2iMgo77ypwNKkRRrbxdUGyRljTEILBn0iqhoSketwK9L5gAdUdYmIXO0dvwf4GfCQiCzGVUndrKqN3ltcDzzqJZfVuNJGcjTtOs135yC5ATZRnzEmjSUtQQCo6ixgVsy+e6Je1wJxJ/5T1UW4BYqSrytBDANcgsjMEPoWWIIwxqQvG0kNroG6cABku45S9c3t9C/KISOjd89ubowxe2MJAmDr2q72B+gcJGftD8aY9GYJAlwVk9f+ADZIzhhjwBIERMJuFbn+o7t2bfIHbJCcMSbtJbWR+pCQ4YNr3uzabO0I0RII2RgIY0zasxJEjJ2D5KwHkzEmvVmCiGGD5IwxxrEEEWNz51rU1gZhjElzliBiWAnCGGMcSxAx6psDFOVkUpBj7ffGmPRmCSKGrSRnjDGOJYgYNgbCGGMcSxAxNvnbGVBkCcIYYyxBxPC3BSnNz051GMYYk3KWIKKEI0pLe4jiPGugNsYYSxBRtgdCABTnZqU4EmOMST1LEFH8gSAAxXmWIIwxxhJElOY2L0HkWhWTMcZYgohiJQhjjNnJEkQUf5u1QRhjTCdLEFF2liCsiskYY5KaIETkLBFZISKrROSWOMdLROQ5EXlfRJaIyBUxx30islBEnk9mnJ38XhtEkZUgjDEmeQlCRHzA3cDZwFhguoiMjTntWmCpqk4ApgC3i0j0KLUbgGXJijGWPxBCBIpsoj5jjElqCWIysEpVV6tqBzATmBZzjgJFIiJAIbAVCAGISCVwLnBfEmPchb8tSGFOJhkZ0lMfaYwxB61kJogKYEPUdo23L9pdwBigFlgM3KCqEe/YncB3gQh7ISJXich8EZnf0NBwQAH7A0FroDbGGE8yE0S8r+Eas30msAgYDEwE7hKRYhE5D9isqgv29SGqeq+qVqtqdb9+/Q4oYH9byLq4GmOMJ5kJogYYErVdiSspRLsCeEqdVcAaYDRwEnC+iKzFVU2dJiJ/SWKsQGcJwtofjDEGkpsg5gEjRWS41/B8KfBszDnrgakAIjIAGAWsVtVbVbVSVau8615V1cuSGCvg2iCsBGGMMU7Svi6rakhErgNeAnzAA6q6RESu9o7fA/wMeEhEFuOqpG5W1cZkxbQvLYGQtUEYY4wnqfUpqjoLmBWz756o17XAGft4jznAnCSEtxtXgrAqJmOMARtJ3aVrLQgrQRhjDGAJosv2dm8eJmuDMMYYwBJEF79N9W2MMbuwBOGxqb6NMWZXliA8NtW3McbsyhKEx6b6NsaYXVmC8Oxsg7AShDHGgCWILv6A9WIyxpholiA8nSWIQlsLwhhjAEsQXfyBIEU5mfhsLQhjjAEsQXSxqb6NMWZXliA8/kCQIhskZ4wxXSxBeGyqb2OM2ZUlCI/fpvo2xphdWILw2FTfxhizK0sQHrfcqJUgjDGmkyUIIBJRtrdbLyZjjIlmCQJoaQ+halN9G2NMNEsQRM3DZCUIY4zpYgmCqJlcrQ3CGGO6WIIgai0I68VkjDFdLEFgJQhjjIknqQlCRM4SkRUiskpEbolzvEREnhOR90VkiYhc4e0fIiKvicgyb/8NyYyzsw2ixNogjDGmS9IShIj4gLuBs4GxwHQRGRtz2rXAUlWdAEwBbheRbCAEfEtVxwDHA9fGubbbdK0FYSUIY4zpkswSxGRglaquVtUOYCYwLeYcBYpERIBCYCsQUtU6VX0PQFVbgGVARbIC7VoLwrq5GmNMl2QmiApgQ9R2Dbs/5O8CxgC1wGLgBlWNRJ8gIlXAJGBuvA8RkatEZL6IzG9oaPhEgdpaEMYYs7tkJoh4T1uN2T4TWAQMBiYCd4lIcdcbiBQCTwI3qqo/3oeo6r2qWq2q1f369ftEgfrbQjbVtzHGxEhmgqgBhkRtV+JKCtGuAJ5SZxWwBhgNICJZuOTwqKo+lcQ43TxM1kBtjDG7SGaCmAeMFJHhXsPzpcCzMeesB6YCiMgAYBSw2muTuB9Ypqp3JDFGwJvJ1RqojTFmF0lLEKoaAq4DXsI1Mj+uqktE5GoRudo77WfAiSKyGJgN3KyqjcBJwJeA00RkkfdzTrJi9QdCNkjOGGNiJPWpqKqzgFkx++6Jel0LnBHnujeI34aRFP62IGMGFvXUxxljzCHBRlJjbRDGGBNP2icIVWXq6P6MryxJdSjGGHNQSfuKdxHhzksnpToMY4w56KR9CcIYY0x8liCMMcbEZQnCGGNMXJYgjDHGxGUJwhhjTFyWIIwxxsRlCcIYY0xcliCMMcbEJaqxSzQcukSkAVj3CS/vCzR2YziHgnS8Z0jP+07He4b0vO/9vedhqhp3MZ1elSAOhIjMV9XqVMfRk9LxniE97zsd7xnS8767856tiskYY0xcliCMMcbEZQlip3tTHUAKpOM9Q3redzreM6TnfXfbPVsbhDHGmLisBGGMMSYuSxDGGGPiSvsEISJnicgKEVklIrekOp5kEZEhIvKaiCwTkSUicoO3v4+I/FNEVnq/y1Ida3cTEZ+ILBSR573tdLjnUhF5QkSWe//NT+jt9y0i3/T+bX8oIn8VkdzeeM8i8oCIbBaRD6P27fE+ReRW7/m2QkTO3J/PSusEISI+4G7gbGAsMF1ExqY2qqQJAd9S1THA8cC13r3eAsxW1ZHAbG+7t7kBWBa1nQ73/BvgRVUdDUzA3X+vvW8RqQC+AVSr6pGAD7iU3nnPDwFnxeyLe5/e/+OXAuO8a37vPfcSktYJApgMrFLV1araAcwEpqU4pqRQ1TpVfc973YJ7YFTg7vdh77SHgQtSEmCSiEglcC5wX9Tu3n7PxcCpwP0Aqtqhqtvo5feNW0I5T0QygXygll54z6r6OrA1Zvee7nMaMFNV21V1DbAK99xLSLoniApgQ9R2jbevVxORKmASMBcYoKp14JII0D+FoSXDncB3gUjUvt5+zyOABuBBr2rtPhEpoBfft6puBG4D1gN1QLOqvkwvvucYe7rPA3rGpXuCkDj7enW/XxEpBJ4EblRVf6rjSSYROQ/YrKoLUh1LD8sEjgb+oKqTgB30jqqVPfLq3KcBw4HBQIGIXJbaqA4KB/SMS/cEUQMMidquxBVLeyURycIlh0dV9Slv9yYRGeQdHwRsTlV8SXAScL6IrMVVH54mIn+hd98zuH/XNao619t+ApcwevN9nw6sUdUGVQ0CTwEn0rvvOdqe7vOAnnHpniDmASNFZLiIZOMac55NcUxJISKCq5Nepqp3RB16Frjce3058I+eji1ZVPVWVa1U1Srcf9tXVfUyevE9A6hqPbBBREZ5u6YCS+nd970eOF5E8r1/61Nx7Wy9+Z6j7ek+nwUuFZEcERkOjATeTfhdVTWtf4BzgI+Aj4HvpzqeJN7nybii5QfAIu/nHKAc1+thpfe7T6pjTdL9TwGe9173+nsGJgLzvf/ezwBlvf2+gZ8Ay4EPgT8DOb3xnoG/4tpZgrgSwlf2dp/A973n2wrg7P35LJtqwxhjTFzpXsVkjDFmDyxBGGOMicsShDHGmLgsQRhjjInLEoQxxpi4LEEYsx9EJCwii6J+um2EsohURc/QaUyqZaY6AGMOMW2qOjHVQRjTE6wEYUw3EJG1IvI/IvKu93O4t3+YiMwWkQ+830O9/QNE5GkRed/7OdF7K5+I/Mlb1+BlEclL2U2ZtGcJwpj9kxdTxXRJ1DG/qk4G7sLNIov3+hFVHQ88CvzW2/9b4F+qOgE3T9ISb/9I4G5VHQdsAz6f1LsxZi9sJLUx+0FEtqtqYZz9a4HTVHW1NylivaqWi0gjMEhVg97+OlXtKyINQKWqtke9RxXwT3WLviAiNwNZqvrzHrg1Y3ZjJQhjuo/u4fWezomnPep1GGsnNClkCcKY7nNJ1O+3vddv4WaSBfgP4A3v9WzgGuhaM7u4p4I0JlH27cSY/ZMnIouitl9U1c6urjkiMhf3xWu6t+8bwAMi8h3cKm9XePtvAO4Vka/gSgrX4GboNOagYW0QxnQDrw2iWlUbUx2LMd3FqpiMMcbEZSUIY4wxcVkJwhhjTFyWIIwxxsRlCcIYY0xcliCMMcbEZQnCGGNMXP8fxGipqX7OmU4AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc=\"upper left\")\n",
    "plt.show()\n",
    "\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc=\"upper left\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "20547e3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted proababilityfor each of the examples blonging to class 1: \n",
      "[[0.00305814]\n",
      " [0.6852765 ]\n",
      " [0.00348309]\n",
      " [0.9860264 ]\n",
      " [0.9792422 ]\n",
      " [0.00388524]\n",
      " [0.65761465]\n",
      " [0.00407234]\n",
      " [0.00466701]\n",
      " [0.995118  ]]\n",
      "Predicted class label for each of the examples: \n",
      "[[0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]]\n"
     ]
    }
   ],
   "source": [
    "y_predicted = model.predict(X.iloc[0:10,:])\n",
    "\n",
    "print('Predicted proababilityfor each of the examples blonging to class 1: ')\n",
    "print(y_predicted)\n",
    "\n",
    "print('Predicted class label for each of the examples: ')\n",
    "print(np.round(y_predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ff52063",
   "metadata": {},
   "source": [
    "## Activity 3.02: Advanced Fibrosis Diagnosis with Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b287a6ac",
   "metadata": {},
   "source": [
    "### Step 1: Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "29a1c978",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.read_csv('https://raw.githubusercontent.com/PacktWorkshops/The-Deep-Learning-with-Keras-Workshop/master/Chapter03/data/HCV_feats.csv')\n",
    "y = pd.read_csv('https://raw.githubusercontent.com/PacktWorkshops/The-Deep-Learning-with-Keras-Workshop/master/Chapter03/data/HCV_target.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39ef92c7",
   "metadata": {},
   "source": [
    "### Step 2: Print dataset shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "8c555ea5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "Number of examples:  1385 \n",
      " Number of features:  28 \n",
      " Possible classifications:  [0 1]\n"
     ]
    }
   ],
   "source": [
    "print(\" \\nNumber of examples: \",X.shape[0],\\\n",
    "    \"\\n Number of features: \",X.shape[1],\\\n",
    "    \"\\n Possible classifications: \", np.unique(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c693829a",
   "metadata": {},
   "source": [
    "### Step 3 Scale data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "5bc3f321",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.model_selection\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "434acfa2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = preprocessing.StandardScaler().fit(X)\n",
    "X_scaled = scaler.transform(X)\n",
    "X_scaled.mean(axis=0)\n",
    "X_scaled.std(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "f13b5725",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of examples in train:  1108\n",
      "Number of examples in test:  277\n"
     ]
    }
   ],
   "source": [
    "train, test = sklearn.model_selection.train_test_split(X_scaled, train_size=0.8, test_size=0.2, \n",
    "                                         shuffle=True, stratify=None)\n",
    "print(\"Number of examples in train: \",len(train))\n",
    "print(\"Number of examples in test: \", len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "0b24fe15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_16 (Dense)            (None, 3)                 87        \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 1)                 4         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 91\n",
      "Trainable params: 91\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "random.set_seed(42)\n",
    "classifier = Sequential()\n",
    "\n",
    "classifier.add(Dense(units=3, activation='tanh', input_dim=X_scaled.shape[1]))\n",
    "classifier.add(Dense(units=1, activation='sigmoid'))\n",
    "classifier.compile(optimizer='sgd', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "classifier.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "ae0a07a3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7857 - accuracy: 0.4920 - val_loss: 0.8507 - val_accuracy: 0.3957\n",
      "Epoch 2/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.7555 - accuracy: 0.4920 - val_loss: 0.8112 - val_accuracy: 0.3957\n",
      "Epoch 3/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.7375 - accuracy: 0.4920 - val_loss: 0.7845 - val_accuracy: 0.3957\n",
      "Epoch 4/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.7263 - accuracy: 0.4920 - val_loss: 0.7655 - val_accuracy: 0.3957\n",
      "Epoch 5/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.7187 - accuracy: 0.4848 - val_loss: 0.7514 - val_accuracy: 0.4892\n",
      "Epoch 6/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.7133 - accuracy: 0.4976 - val_loss: 0.7406 - val_accuracy: 0.4892\n",
      "Epoch 7/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.7092 - accuracy: 0.4976 - val_loss: 0.7320 - val_accuracy: 0.4892\n",
      "Epoch 8/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.7061 - accuracy: 0.4896 - val_loss: 0.7251 - val_accuracy: 0.4892\n",
      "Epoch 9/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.7036 - accuracy: 0.4880 - val_loss: 0.7194 - val_accuracy: 0.4892\n",
      "Epoch 10/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.7016 - accuracy: 0.4912 - val_loss: 0.7147 - val_accuracy: 0.4892\n",
      "Epoch 11/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.7000 - accuracy: 0.4928 - val_loss: 0.7108 - val_accuracy: 0.4892\n",
      "Epoch 12/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6986 - accuracy: 0.4872 - val_loss: 0.7074 - val_accuracy: 0.4892\n",
      "Epoch 13/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6976 - accuracy: 0.4848 - val_loss: 0.7046 - val_accuracy: 0.4892\n",
      "Epoch 14/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6967 - accuracy: 0.4864 - val_loss: 0.7022 - val_accuracy: 0.4892\n",
      "Epoch 15/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6960 - accuracy: 0.4920 - val_loss: 0.7001 - val_accuracy: 0.4892\n",
      "Epoch 16/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6954 - accuracy: 0.4976 - val_loss: 0.6982 - val_accuracy: 0.4892\n",
      "Epoch 17/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6950 - accuracy: 0.4976 - val_loss: 0.6967 - val_accuracy: 0.4892\n",
      "Epoch 18/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6946 - accuracy: 0.4976 - val_loss: 0.6953 - val_accuracy: 0.4892\n",
      "Epoch 19/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6943 - accuracy: 0.4976 - val_loss: 0.6941 - val_accuracy: 0.4892\n",
      "Epoch 20/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6940 - accuracy: 0.4976 - val_loss: 0.6930 - val_accuracy: 0.4892\n",
      "Epoch 21/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6938 - accuracy: 0.4952 - val_loss: 0.6921 - val_accuracy: 0.5827\n",
      "Epoch 22/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6936 - accuracy: 0.5072 - val_loss: 0.6913 - val_accuracy: 0.5827\n",
      "Epoch 23/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6935 - accuracy: 0.5072 - val_loss: 0.6906 - val_accuracy: 0.5827\n",
      "Epoch 24/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6934 - accuracy: 0.5072 - val_loss: 0.6899 - val_accuracy: 0.5827\n",
      "Epoch 25/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6933 - accuracy: 0.5072 - val_loss: 0.6894 - val_accuracy: 0.5827\n",
      "Epoch 26/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5072 - val_loss: 0.6889 - val_accuracy: 0.5827\n",
      "Epoch 27/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5024 - val_loss: 0.6884 - val_accuracy: 0.5827\n",
      "Epoch 28/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5128 - val_loss: 0.6880 - val_accuracy: 0.6115\n",
      "Epoch 29/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5112 - val_loss: 0.6877 - val_accuracy: 0.6115\n",
      "Epoch 30/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6930 - accuracy: 0.5128 - val_loss: 0.6873 - val_accuracy: 0.6115\n",
      "Epoch 31/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6930 - accuracy: 0.5128 - val_loss: 0.6871 - val_accuracy: 0.6115\n",
      "Epoch 32/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6930 - accuracy: 0.5128 - val_loss: 0.6868 - val_accuracy: 0.6115\n",
      "Epoch 33/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6930 - accuracy: 0.5128 - val_loss: 0.6866 - val_accuracy: 0.6115\n",
      "Epoch 34/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6930 - accuracy: 0.5128 - val_loss: 0.6864 - val_accuracy: 0.6115\n",
      "Epoch 35/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6930 - accuracy: 0.5128 - val_loss: 0.6862 - val_accuracy: 0.6115\n",
      "Epoch 36/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6930 - accuracy: 0.5128 - val_loss: 0.6860 - val_accuracy: 0.6115\n",
      "Epoch 37/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6929 - accuracy: 0.5128 - val_loss: 0.6859 - val_accuracy: 0.6115\n",
      "Epoch 38/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6929 - accuracy: 0.5128 - val_loss: 0.6857 - val_accuracy: 0.6115\n",
      "Epoch 39/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6929 - accuracy: 0.5128 - val_loss: 0.6856 - val_accuracy: 0.6115\n",
      "Epoch 40/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6929 - accuracy: 0.5128 - val_loss: 0.6855 - val_accuracy: 0.6115\n",
      "Epoch 41/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6929 - accuracy: 0.5128 - val_loss: 0.6854 - val_accuracy: 0.6115\n",
      "Epoch 42/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6929 - accuracy: 0.5128 - val_loss: 0.6853 - val_accuracy: 0.6115\n",
      "Epoch 43/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6929 - accuracy: 0.5128 - val_loss: 0.6852 - val_accuracy: 0.6115\n",
      "Epoch 44/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6929 - accuracy: 0.5128 - val_loss: 0.6852 - val_accuracy: 0.6115\n",
      "Epoch 45/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6929 - accuracy: 0.5128 - val_loss: 0.6851 - val_accuracy: 0.6115\n",
      "Epoch 46/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6929 - accuracy: 0.5128 - val_loss: 0.6851 - val_accuracy: 0.6115\n",
      "Epoch 47/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6929 - accuracy: 0.5128 - val_loss: 0.6850 - val_accuracy: 0.6115\n",
      "Epoch 48/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6929 - accuracy: 0.5128 - val_loss: 0.6850 - val_accuracy: 0.6115\n",
      "Epoch 49/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6929 - accuracy: 0.5128 - val_loss: 0.6849 - val_accuracy: 0.6115\n",
      "Epoch 50/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6929 - accuracy: 0.5128 - val_loss: 0.6849 - val_accuracy: 0.6115\n",
      "Epoch 51/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6929 - accuracy: 0.5128 - val_loss: 0.6848 - val_accuracy: 0.6115\n",
      "Epoch 52/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6929 - accuracy: 0.5128 - val_loss: 0.6848 - val_accuracy: 0.6115\n",
      "Epoch 53/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6929 - accuracy: 0.5128 - val_loss: 0.6848 - val_accuracy: 0.6115\n",
      "Epoch 54/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6929 - accuracy: 0.5128 - val_loss: 0.6847 - val_accuracy: 0.6115\n",
      "Epoch 55/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6929 - accuracy: 0.5128 - val_loss: 0.6847 - val_accuracy: 0.6115\n",
      "Epoch 56/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6929 - accuracy: 0.5128 - val_loss: 0.6847 - val_accuracy: 0.6115\n",
      "Epoch 57/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6929 - accuracy: 0.5128 - val_loss: 0.6847 - val_accuracy: 0.6115\n",
      "Epoch 58/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6929 - accuracy: 0.5128 - val_loss: 0.6847 - val_accuracy: 0.6115\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6929 - accuracy: 0.5128 - val_loss: 0.6847 - val_accuracy: 0.6115\n",
      "Epoch 60/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6929 - accuracy: 0.5128 - val_loss: 0.6846 - val_accuracy: 0.6115\n",
      "Epoch 61/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6929 - accuracy: 0.5128 - val_loss: 0.6846 - val_accuracy: 0.6115\n",
      "Epoch 62/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6929 - accuracy: 0.5128 - val_loss: 0.6846 - val_accuracy: 0.6115\n",
      "Epoch 63/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6929 - accuracy: 0.5128 - val_loss: 0.6846 - val_accuracy: 0.6115\n",
      "Epoch 64/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6929 - accuracy: 0.5128 - val_loss: 0.6846 - val_accuracy: 0.6115\n",
      "Epoch 65/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6929 - accuracy: 0.5128 - val_loss: 0.6846 - val_accuracy: 0.6115\n",
      "Epoch 66/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6929 - accuracy: 0.5128 - val_loss: 0.6846 - val_accuracy: 0.6115\n",
      "Epoch 67/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6929 - accuracy: 0.5128 - val_loss: 0.6846 - val_accuracy: 0.6115\n",
      "Epoch 68/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6929 - accuracy: 0.5128 - val_loss: 0.6846 - val_accuracy: 0.6115\n",
      "Epoch 69/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6929 - accuracy: 0.5128 - val_loss: 0.6846 - val_accuracy: 0.6115\n",
      "Epoch 70/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6929 - accuracy: 0.5128 - val_loss: 0.6846 - val_accuracy: 0.6115\n",
      "Epoch 71/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6929 - accuracy: 0.5128 - val_loss: 0.6845 - val_accuracy: 0.6115\n",
      "Epoch 72/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6929 - accuracy: 0.5128 - val_loss: 0.6845 - val_accuracy: 0.6115\n",
      "Epoch 73/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6929 - accuracy: 0.5128 - val_loss: 0.6845 - val_accuracy: 0.6115\n",
      "Epoch 74/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6929 - accuracy: 0.5128 - val_loss: 0.6845 - val_accuracy: 0.6115\n",
      "Epoch 75/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6929 - accuracy: 0.5128 - val_loss: 0.6845 - val_accuracy: 0.6115\n",
      "Epoch 76/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6929 - accuracy: 0.5128 - val_loss: 0.6845 - val_accuracy: 0.6115\n",
      "Epoch 77/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6929 - accuracy: 0.5128 - val_loss: 0.6845 - val_accuracy: 0.6115\n",
      "Epoch 78/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6929 - accuracy: 0.5128 - val_loss: 0.6845 - val_accuracy: 0.6115\n",
      "Epoch 79/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6929 - accuracy: 0.5128 - val_loss: 0.6845 - val_accuracy: 0.6115\n",
      "Epoch 80/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6929 - accuracy: 0.5128 - val_loss: 0.6845 - val_accuracy: 0.6115\n",
      "Epoch 81/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6929 - accuracy: 0.5128 - val_loss: 0.6845 - val_accuracy: 0.6115\n",
      "Epoch 82/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6929 - accuracy: 0.5128 - val_loss: 0.6845 - val_accuracy: 0.6115\n",
      "Epoch 83/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6929 - accuracy: 0.5128 - val_loss: 0.6845 - val_accuracy: 0.6115\n",
      "Epoch 84/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6929 - accuracy: 0.5128 - val_loss: 0.6845 - val_accuracy: 0.6115\n",
      "Epoch 85/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6929 - accuracy: 0.5128 - val_loss: 0.6845 - val_accuracy: 0.6115\n",
      "Epoch 86/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6929 - accuracy: 0.5128 - val_loss: 0.6845 - val_accuracy: 0.6115\n",
      "Epoch 87/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6929 - accuracy: 0.5128 - val_loss: 0.6845 - val_accuracy: 0.6115\n",
      "Epoch 88/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6929 - accuracy: 0.5128 - val_loss: 0.6845 - val_accuracy: 0.6115\n",
      "Epoch 89/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6929 - accuracy: 0.5128 - val_loss: 0.6845 - val_accuracy: 0.6115\n",
      "Epoch 90/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6929 - accuracy: 0.5128 - val_loss: 0.6845 - val_accuracy: 0.6115\n",
      "Epoch 91/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6929 - accuracy: 0.5128 - val_loss: 0.6845 - val_accuracy: 0.6115\n",
      "Epoch 92/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6929 - accuracy: 0.5128 - val_loss: 0.6845 - val_accuracy: 0.6115\n",
      "Epoch 93/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6929 - accuracy: 0.5128 - val_loss: 0.6845 - val_accuracy: 0.6115\n",
      "Epoch 94/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6929 - accuracy: 0.5128 - val_loss: 0.6845 - val_accuracy: 0.6115\n",
      "Epoch 95/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6929 - accuracy: 0.5128 - val_loss: 0.6845 - val_accuracy: 0.6115\n",
      "Epoch 96/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6929 - accuracy: 0.5128 - val_loss: 0.6845 - val_accuracy: 0.6115\n",
      "Epoch 97/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6929 - accuracy: 0.5128 - val_loss: 0.6845 - val_accuracy: 0.6115\n",
      "Epoch 98/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6929 - accuracy: 0.5128 - val_loss: 0.6845 - val_accuracy: 0.6115\n",
      "Epoch 99/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6929 - accuracy: 0.5128 - val_loss: 0.6845 - val_accuracy: 0.6115\n",
      "Epoch 100/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6929 - accuracy: 0.5128 - val_loss: 0.6845 - val_accuracy: 0.6115\n"
     ]
    }
   ],
   "source": [
    "history = classifier.fit(X,y, epochs=100,batch_size=20,verbose=1,validation_split=0.1,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "5e0c2177",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6115108132362366"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(history.history['val_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "0ed04854",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc=\"upper left\")\n",
    "plt.show()\n",
    "\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc=\"upper left\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "df6089ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_18 (Dense)            (None, 4)                 116       \n",
      "                                                                 \n",
      " dense_19 (Dense)            (None, 2)                 10        \n",
      "                                                                 \n",
      " dense_20 (Dense)            (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 129\n",
      "Trainable params: 129\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "random.set_seed(42)\n",
    "classifier = Sequential()\n",
    "\n",
    "classifier.add(Dense(units=10, activation='tanh', input_dim=X_scaled.shape[1]))\n",
    "classifier.add(Dense(units=4, activation='tanh'))\n",
    "classifier.add(Dense(units=2, activation='tanh'))\n",
    "classifier.add(Dense(units=1, activation='sigmoid'))\n",
    "classifier.compile(optimizer='sgd', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "classifier.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "4c92827b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6933 - accuracy: 0.5080 - val_loss: 0.6905 - val_accuracy: 0.5827\n",
      "Epoch 2/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6933 - accuracy: 0.5080 - val_loss: 0.6905 - val_accuracy: 0.5827\n",
      "Epoch 3/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6933 - accuracy: 0.5080 - val_loss: 0.6905 - val_accuracy: 0.5827\n",
      "Epoch 4/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6933 - accuracy: 0.5080 - val_loss: 0.6905 - val_accuracy: 0.5827\n",
      "Epoch 5/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6933 - accuracy: 0.5080 - val_loss: 0.6905 - val_accuracy: 0.5827\n",
      "Epoch 6/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6933 - accuracy: 0.5080 - val_loss: 0.6905 - val_accuracy: 0.5827\n",
      "Epoch 7/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6933 - accuracy: 0.5080 - val_loss: 0.6905 - val_accuracy: 0.5827\n",
      "Epoch 8/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6932 - accuracy: 0.5080 - val_loss: 0.6905 - val_accuracy: 0.5827\n",
      "Epoch 9/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5080 - val_loss: 0.6904 - val_accuracy: 0.5827\n",
      "Epoch 10/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5080 - val_loss: 0.6904 - val_accuracy: 0.5827\n",
      "Epoch 11/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5080 - val_loss: 0.6904 - val_accuracy: 0.5827\n",
      "Epoch 12/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6932 - accuracy: 0.5080 - val_loss: 0.6904 - val_accuracy: 0.5827\n",
      "Epoch 13/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6932 - accuracy: 0.5080 - val_loss: 0.6904 - val_accuracy: 0.5827\n",
      "Epoch 14/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5080 - val_loss: 0.6904 - val_accuracy: 0.5827\n",
      "Epoch 15/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5080 - val_loss: 0.6904 - val_accuracy: 0.5827\n",
      "Epoch 16/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5080 - val_loss: 0.6904 - val_accuracy: 0.5827\n",
      "Epoch 17/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5080 - val_loss: 0.6904 - val_accuracy: 0.5827\n",
      "Epoch 18/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5080 - val_loss: 0.6904 - val_accuracy: 0.5827\n",
      "Epoch 19/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5080 - val_loss: 0.6904 - val_accuracy: 0.5827\n",
      "Epoch 20/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5080 - val_loss: 0.6904 - val_accuracy: 0.5827\n",
      "Epoch 21/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5080 - val_loss: 0.6904 - val_accuracy: 0.5827\n",
      "Epoch 22/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5080 - val_loss: 0.6904 - val_accuracy: 0.5827\n",
      "Epoch 23/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5080 - val_loss: 0.6904 - val_accuracy: 0.5827\n",
      "Epoch 24/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5080 - val_loss: 0.6904 - val_accuracy: 0.5827\n",
      "Epoch 25/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5080 - val_loss: 0.6904 - val_accuracy: 0.5827\n",
      "Epoch 26/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5080 - val_loss: 0.6904 - val_accuracy: 0.5827\n",
      "Epoch 27/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5080 - val_loss: 0.6904 - val_accuracy: 0.5827\n",
      "Epoch 28/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5080 - val_loss: 0.6904 - val_accuracy: 0.5827\n",
      "Epoch 29/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5080 - val_loss: 0.6904 - val_accuracy: 0.5827\n",
      "Epoch 30/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5080 - val_loss: 0.6904 - val_accuracy: 0.5827\n",
      "Epoch 31/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5080 - val_loss: 0.6904 - val_accuracy: 0.5827\n",
      "Epoch 32/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5080 - val_loss: 0.6904 - val_accuracy: 0.5827\n",
      "Epoch 33/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5080 - val_loss: 0.6904 - val_accuracy: 0.5827\n",
      "Epoch 34/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5080 - val_loss: 0.6904 - val_accuracy: 0.5827\n",
      "Epoch 35/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5080 - val_loss: 0.6904 - val_accuracy: 0.5827\n",
      "Epoch 36/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5080 - val_loss: 0.6904 - val_accuracy: 0.5827\n",
      "Epoch 37/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5080 - val_loss: 0.6904 - val_accuracy: 0.5827\n",
      "Epoch 38/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5080 - val_loss: 0.6904 - val_accuracy: 0.5827\n",
      "Epoch 39/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5080 - val_loss: 0.6904 - val_accuracy: 0.5827\n",
      "Epoch 40/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5080 - val_loss: 0.6904 - val_accuracy: 0.5827\n",
      "Epoch 41/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5072 - val_loss: 0.6904 - val_accuracy: 0.5827\n",
      "Epoch 42/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5072 - val_loss: 0.6904 - val_accuracy: 0.5827\n",
      "Epoch 43/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5088 - val_loss: 0.6904 - val_accuracy: 0.5827\n",
      "Epoch 44/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5088 - val_loss: 0.6904 - val_accuracy: 0.5827\n",
      "Epoch 45/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5064 - val_loss: 0.6904 - val_accuracy: 0.5827\n",
      "Epoch 46/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5064 - val_loss: 0.6904 - val_accuracy: 0.5827\n",
      "Epoch 47/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5040 - val_loss: 0.6904 - val_accuracy: 0.5827\n",
      "Epoch 48/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5080 - val_loss: 0.6904 - val_accuracy: 0.5827\n",
      "Epoch 49/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5096 - val_loss: 0.6904 - val_accuracy: 0.5827\n",
      "Epoch 50/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5088 - val_loss: 0.6904 - val_accuracy: 0.5827\n",
      "Epoch 51/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5080 - val_loss: 0.6904 - val_accuracy: 0.5827\n",
      "Epoch 52/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5096 - val_loss: 0.6904 - val_accuracy: 0.5827\n",
      "Epoch 53/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5088 - val_loss: 0.6904 - val_accuracy: 0.5827\n",
      "Epoch 54/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5048 - val_loss: 0.6904 - val_accuracy: 0.5827\n",
      "Epoch 55/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5064 - val_loss: 0.6904 - val_accuracy: 0.5827\n",
      "Epoch 56/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5056 - val_loss: 0.6904 - val_accuracy: 0.5827\n",
      "Epoch 57/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5064 - val_loss: 0.6904 - val_accuracy: 0.5827\n",
      "Epoch 58/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5048 - val_loss: 0.6904 - val_accuracy: 0.5827\n",
      "Epoch 59/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5072 - val_loss: 0.6904 - val_accuracy: 0.5827\n",
      "Epoch 60/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5072 - val_loss: 0.6904 - val_accuracy: 0.5827\n",
      "Epoch 61/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5072 - val_loss: 0.6904 - val_accuracy: 0.5827\n",
      "Epoch 62/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5104 - val_loss: 0.6904 - val_accuracy: 0.6043\n",
      "Epoch 63/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5080 - val_loss: 0.6904 - val_accuracy: 0.6043\n",
      "Epoch 64/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5088 - val_loss: 0.6904 - val_accuracy: 0.6043\n",
      "Epoch 65/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5088 - val_loss: 0.6904 - val_accuracy: 0.6043\n",
      "Epoch 66/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5088 - val_loss: 0.6904 - val_accuracy: 0.6043\n",
      "Epoch 67/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5080 - val_loss: 0.6904 - val_accuracy: 0.6043\n",
      "Epoch 68/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5080 - val_loss: 0.6904 - val_accuracy: 0.6043\n",
      "Epoch 69/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5080 - val_loss: 0.6904 - val_accuracy: 0.6043\n",
      "Epoch 70/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6932 - accuracy: 0.5096 - val_loss: 0.6904 - val_accuracy: 0.6043\n",
      "Epoch 71/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6932 - accuracy: 0.5104 - val_loss: 0.6904 - val_accuracy: 0.6043\n",
      "Epoch 72/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6932 - accuracy: 0.5112 - val_loss: 0.6904 - val_accuracy: 0.6043\n",
      "Epoch 73/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5104 - val_loss: 0.6904 - val_accuracy: 0.6043\n",
      "Epoch 74/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5104 - val_loss: 0.6904 - val_accuracy: 0.6043\n",
      "Epoch 75/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5088 - val_loss: 0.6904 - val_accuracy: 0.6043\n",
      "Epoch 76/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5088 - val_loss: 0.6904 - val_accuracy: 0.6043\n",
      "Epoch 77/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5088 - val_loss: 0.6904 - val_accuracy: 0.6043\n",
      "Epoch 78/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5088 - val_loss: 0.6904 - val_accuracy: 0.6043\n",
      "Epoch 79/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5088 - val_loss: 0.6904 - val_accuracy: 0.6043\n",
      "Epoch 80/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5088 - val_loss: 0.6904 - val_accuracy: 0.6043\n",
      "Epoch 81/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5064 - val_loss: 0.6904 - val_accuracy: 0.6043\n",
      "Epoch 82/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5064 - val_loss: 0.6904 - val_accuracy: 0.6043\n",
      "Epoch 83/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5064 - val_loss: 0.6904 - val_accuracy: 0.6043\n",
      "Epoch 84/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5064 - val_loss: 0.6904 - val_accuracy: 0.6043\n",
      "Epoch 85/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5064 - val_loss: 0.6904 - val_accuracy: 0.6043\n",
      "Epoch 86/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5064 - val_loss: 0.6904 - val_accuracy: 0.6043\n",
      "Epoch 87/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5080 - val_loss: 0.6904 - val_accuracy: 0.6043\n",
      "Epoch 88/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5080 - val_loss: 0.6904 - val_accuracy: 0.6043\n",
      "Epoch 89/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5080 - val_loss: 0.6904 - val_accuracy: 0.6043\n",
      "Epoch 90/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5080 - val_loss: 0.6904 - val_accuracy: 0.6043\n",
      "Epoch 91/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5080 - val_loss: 0.6904 - val_accuracy: 0.6043\n",
      "Epoch 92/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5080 - val_loss: 0.6904 - val_accuracy: 0.6043\n",
      "Epoch 93/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5080 - val_loss: 0.6904 - val_accuracy: 0.6043\n",
      "Epoch 94/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5080 - val_loss: 0.6904 - val_accuracy: 0.6043\n",
      "Epoch 95/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5080 - val_loss: 0.6904 - val_accuracy: 0.6043\n",
      "Epoch 96/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5080 - val_loss: 0.6904 - val_accuracy: 0.6043\n",
      "Epoch 97/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5080 - val_loss: 0.6904 - val_accuracy: 0.6043\n",
      "Epoch 98/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5080 - val_loss: 0.6904 - val_accuracy: 0.6043\n",
      "Epoch 99/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5080 - val_loss: 0.6904 - val_accuracy: 0.6043\n",
      "Epoch 100/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5080 - val_loss: 0.6904 - val_accuracy: 0.6043\n",
      "Epoch 101/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6932 - accuracy: 0.5080 - val_loss: 0.6904 - val_accuracy: 0.6043\n",
      "Epoch 102/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6932 - accuracy: 0.5080 - val_loss: 0.6904 - val_accuracy: 0.6043\n",
      "Epoch 103/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6932 - accuracy: 0.5080 - val_loss: 0.6904 - val_accuracy: 0.6043\n",
      "Epoch 104/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6932 - accuracy: 0.5080 - val_loss: 0.6904 - val_accuracy: 0.6043\n",
      "Epoch 105/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6932 - accuracy: 0.5080 - val_loss: 0.6904 - val_accuracy: 0.6043\n",
      "Epoch 106/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6932 - accuracy: 0.5080 - val_loss: 0.6904 - val_accuracy: 0.6043\n",
      "Epoch 107/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6932 - accuracy: 0.5080 - val_loss: 0.6904 - val_accuracy: 0.6043\n",
      "Epoch 108/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6932 - accuracy: 0.5080 - val_loss: 0.6904 - val_accuracy: 0.6043\n",
      "Epoch 109/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6932 - accuracy: 0.5080 - val_loss: 0.6904 - val_accuracy: 0.6043\n",
      "Epoch 110/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5080 - val_loss: 0.6904 - val_accuracy: 0.6043\n",
      "Epoch 111/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5080 - val_loss: 0.6904 - val_accuracy: 0.6043\n",
      "Epoch 112/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5080 - val_loss: 0.6905 - val_accuracy: 0.6043\n",
      "Epoch 113/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5080 - val_loss: 0.6905 - val_accuracy: 0.6043\n",
      "Epoch 114/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5080 - val_loss: 0.6905 - val_accuracy: 0.6043\n",
      "Epoch 115/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5080 - val_loss: 0.6905 - val_accuracy: 0.6043\n",
      "Epoch 116/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5080 - val_loss: 0.6905 - val_accuracy: 0.6043\n",
      "Epoch 117/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5080 - val_loss: 0.6905 - val_accuracy: 0.6043\n",
      "Epoch 118/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5080 - val_loss: 0.6905 - val_accuracy: 0.6043\n",
      "Epoch 119/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5080 - val_loss: 0.6905 - val_accuracy: 0.6043\n",
      "Epoch 120/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5080 - val_loss: 0.6905 - val_accuracy: 0.6043\n",
      "Epoch 121/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6932 - accuracy: 0.5080 - val_loss: 0.6905 - val_accuracy: 0.6043\n",
      "Epoch 122/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6932 - accuracy: 0.5080 - val_loss: 0.6905 - val_accuracy: 0.6043\n",
      "Epoch 123/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6932 - accuracy: 0.5080 - val_loss: 0.6905 - val_accuracy: 0.6043\n",
      "Epoch 124/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5080 - val_loss: 0.6905 - val_accuracy: 0.6043\n",
      "Epoch 125/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5080 - val_loss: 0.6905 - val_accuracy: 0.6043\n",
      "Epoch 126/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6932 - accuracy: 0.5080 - val_loss: 0.6905 - val_accuracy: 0.6043\n",
      "Epoch 127/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6932 - accuracy: 0.5080 - val_loss: 0.6905 - val_accuracy: 0.6043\n",
      "Epoch 128/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6932 - accuracy: 0.5080 - val_loss: 0.6905 - val_accuracy: 0.6043\n",
      "Epoch 129/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6932 - accuracy: 0.5080 - val_loss: 0.6905 - val_accuracy: 0.6043\n",
      "Epoch 130/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6932 - accuracy: 0.5080 - val_loss: 0.6905 - val_accuracy: 0.6043\n",
      "Epoch 131/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6932 - accuracy: 0.5080 - val_loss: 0.6905 - val_accuracy: 0.6043\n",
      "Epoch 132/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6932 - accuracy: 0.5080 - val_loss: 0.6905 - val_accuracy: 0.6043\n",
      "Epoch 133/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6932 - accuracy: 0.5080 - val_loss: 0.6905 - val_accuracy: 0.6043\n",
      "Epoch 134/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6932 - accuracy: 0.5080 - val_loss: 0.6905 - val_accuracy: 0.6043\n",
      "Epoch 135/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5080 - val_loss: 0.6905 - val_accuracy: 0.6043\n",
      "Epoch 136/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5080 - val_loss: 0.6905 - val_accuracy: 0.6043\n",
      "Epoch 137/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6932 - accuracy: 0.5080 - val_loss: 0.6905 - val_accuracy: 0.6043\n",
      "Epoch 138/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5080 - val_loss: 0.6905 - val_accuracy: 0.6043\n",
      "Epoch 139/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5080 - val_loss: 0.6905 - val_accuracy: 0.6043\n",
      "Epoch 140/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5080 - val_loss: 0.6905 - val_accuracy: 0.6043\n",
      "Epoch 141/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5080 - val_loss: 0.6905 - val_accuracy: 0.6043\n",
      "Epoch 142/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5080 - val_loss: 0.6905 - val_accuracy: 0.6043\n",
      "Epoch 143/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5080 - val_loss: 0.6905 - val_accuracy: 0.6043\n",
      "Epoch 144/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5080 - val_loss: 0.6905 - val_accuracy: 0.6043\n",
      "Epoch 145/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5080 - val_loss: 0.6905 - val_accuracy: 0.6043\n",
      "Epoch 146/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5080 - val_loss: 0.6905 - val_accuracy: 0.6043\n",
      "Epoch 147/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5080 - val_loss: 0.6905 - val_accuracy: 0.6043\n",
      "Epoch 148/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5080 - val_loss: 0.6905 - val_accuracy: 0.6043\n",
      "Epoch 149/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5080 - val_loss: 0.6905 - val_accuracy: 0.6043\n",
      "Epoch 150/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5080 - val_loss: 0.6905 - val_accuracy: 0.6043\n",
      "Epoch 151/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5080 - val_loss: 0.6905 - val_accuracy: 0.6043\n",
      "Epoch 152/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5080 - val_loss: 0.6905 - val_accuracy: 0.6043\n",
      "Epoch 153/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5080 - val_loss: 0.6905 - val_accuracy: 0.6043\n",
      "Epoch 154/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5080 - val_loss: 0.6905 - val_accuracy: 0.6043\n",
      "Epoch 155/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5080 - val_loss: 0.6905 - val_accuracy: 0.6043\n",
      "Epoch 156/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5080 - val_loss: 0.6905 - val_accuracy: 0.6043\n",
      "Epoch 157/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5080 - val_loss: 0.6905 - val_accuracy: 0.6043\n",
      "Epoch 158/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5080 - val_loss: 0.6906 - val_accuracy: 0.6043\n",
      "Epoch 159/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5080 - val_loss: 0.6906 - val_accuracy: 0.6043\n",
      "Epoch 160/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5080 - val_loss: 0.6906 - val_accuracy: 0.6043\n",
      "Epoch 161/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5080 - val_loss: 0.6906 - val_accuracy: 0.6043\n",
      "Epoch 162/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5080 - val_loss: 0.6906 - val_accuracy: 0.6043\n",
      "Epoch 163/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5080 - val_loss: 0.6906 - val_accuracy: 0.6043\n",
      "Epoch 164/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5080 - val_loss: 0.6906 - val_accuracy: 0.6043\n",
      "Epoch 165/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5080 - val_loss: 0.6906 - val_accuracy: 0.6043\n",
      "Epoch 166/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5080 - val_loss: 0.6906 - val_accuracy: 0.6043\n",
      "Epoch 167/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5080 - val_loss: 0.6906 - val_accuracy: 0.6043\n",
      "Epoch 168/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5080 - val_loss: 0.6906 - val_accuracy: 0.6043\n",
      "Epoch 169/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6932 - accuracy: 0.5080 - val_loss: 0.6906 - val_accuracy: 0.6043\n",
      "Epoch 170/1000\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.6932 - accuracy: 0.5080 - val_loss: 0.6906 - val_accuracy: 0.6043\n",
      "Epoch 171/1000\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.6932 - accuracy: 0.5080 - val_loss: 0.6906 - val_accuracy: 0.6043\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 172/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6932 - accuracy: 0.5080 - val_loss: 0.6906 - val_accuracy: 0.6043\n",
      "Epoch 173/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6932 - accuracy: 0.5080 - val_loss: 0.6906 - val_accuracy: 0.6043\n",
      "Epoch 174/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6932 - accuracy: 0.5080 - val_loss: 0.6906 - val_accuracy: 0.6043\n",
      "Epoch 175/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6932 - accuracy: 0.5080 - val_loss: 0.6906 - val_accuracy: 0.6043\n",
      "Epoch 176/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6932 - accuracy: 0.5080 - val_loss: 0.6906 - val_accuracy: 0.6043\n",
      "Epoch 177/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6932 - accuracy: 0.5080 - val_loss: 0.6906 - val_accuracy: 0.6043\n",
      "Epoch 178/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5080 - val_loss: 0.6906 - val_accuracy: 0.6043\n",
      "Epoch 179/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5080 - val_loss: 0.6906 - val_accuracy: 0.6043\n",
      "Epoch 180/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5080 - val_loss: 0.6906 - val_accuracy: 0.6043\n",
      "Epoch 181/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5080 - val_loss: 0.6906 - val_accuracy: 0.6043\n",
      "Epoch 182/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5080 - val_loss: 0.6906 - val_accuracy: 0.6043\n",
      "Epoch 183/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5080 - val_loss: 0.6906 - val_accuracy: 0.6043\n",
      "Epoch 184/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5080 - val_loss: 0.6906 - val_accuracy: 0.6043\n",
      "Epoch 185/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5080 - val_loss: 0.6906 - val_accuracy: 0.6043\n",
      "Epoch 186/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5080 - val_loss: 0.6906 - val_accuracy: 0.6043\n",
      "Epoch 187/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5080 - val_loss: 0.6906 - val_accuracy: 0.6043\n",
      "Epoch 188/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5080 - val_loss: 0.6906 - val_accuracy: 0.6043\n",
      "Epoch 189/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5080 - val_loss: 0.6906 - val_accuracy: 0.6043\n",
      "Epoch 190/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5080 - val_loss: 0.6906 - val_accuracy: 0.6043\n",
      "Epoch 191/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5080 - val_loss: 0.6906 - val_accuracy: 0.6043\n",
      "Epoch 192/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5080 - val_loss: 0.6906 - val_accuracy: 0.6043\n",
      "Epoch 193/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5080 - val_loss: 0.6906 - val_accuracy: 0.5971\n",
      "Epoch 194/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6932 - accuracy: 0.5080 - val_loss: 0.6906 - val_accuracy: 0.5971\n",
      "Epoch 195/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6906 - val_accuracy: 0.5971\n",
      "Epoch 196/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6906 - val_accuracy: 0.5971\n",
      "Epoch 197/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6906 - val_accuracy: 0.5971\n",
      "Epoch 198/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6906 - val_accuracy: 0.5971\n",
      "Epoch 199/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6906 - val_accuracy: 0.5971\n",
      "Epoch 200/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6906 - val_accuracy: 0.5971\n",
      "Epoch 201/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6906 - val_accuracy: 0.5971\n",
      "Epoch 202/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6906 - val_accuracy: 0.5971\n",
      "Epoch 203/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6907 - val_accuracy: 0.5971\n",
      "Epoch 204/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6907 - val_accuracy: 0.5971\n",
      "Epoch 205/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6907 - val_accuracy: 0.5971\n",
      "Epoch 206/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6907 - val_accuracy: 0.5971\n",
      "Epoch 207/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6907 - val_accuracy: 0.5971\n",
      "Epoch 208/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6907 - val_accuracy: 0.5971\n",
      "Epoch 209/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6907 - val_accuracy: 0.5971\n",
      "Epoch 210/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6907 - val_accuracy: 0.5971\n",
      "Epoch 211/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6907 - val_accuracy: 0.5971\n",
      "Epoch 212/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6907 - val_accuracy: 0.5971\n",
      "Epoch 213/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6907 - val_accuracy: 0.5971\n",
      "Epoch 214/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6907 - val_accuracy: 0.5971\n",
      "Epoch 215/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6907 - val_accuracy: 0.5971\n",
      "Epoch 216/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6907 - val_accuracy: 0.5971\n",
      "Epoch 217/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6907 - val_accuracy: 0.5971\n",
      "Epoch 218/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6907 - val_accuracy: 0.5971\n",
      "Epoch 219/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6907 - val_accuracy: 0.5971\n",
      "Epoch 220/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6907 - val_accuracy: 0.5971\n",
      "Epoch 221/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6907 - val_accuracy: 0.5971\n",
      "Epoch 222/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6907 - val_accuracy: 0.5971\n",
      "Epoch 223/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6907 - val_accuracy: 0.5971\n",
      "Epoch 224/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6907 - val_accuracy: 0.5971\n",
      "Epoch 225/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6907 - val_accuracy: 0.5971\n",
      "Epoch 226/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6907 - val_accuracy: 0.5971\n",
      "Epoch 227/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6907 - val_accuracy: 0.5971\n",
      "Epoch 228/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6907 - val_accuracy: 0.5971\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 229/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6907 - val_accuracy: 0.5971\n",
      "Epoch 230/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6907 - val_accuracy: 0.5971\n",
      "Epoch 231/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6907 - val_accuracy: 0.5971\n",
      "Epoch 232/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6907 - val_accuracy: 0.5971\n",
      "Epoch 233/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6907 - val_accuracy: 0.5971\n",
      "Epoch 234/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6907 - val_accuracy: 0.5971\n",
      "Epoch 235/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6907 - val_accuracy: 0.5971\n",
      "Epoch 236/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6907 - val_accuracy: 0.5971\n",
      "Epoch 237/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6907 - val_accuracy: 0.5971\n",
      "Epoch 238/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6907 - val_accuracy: 0.5971\n",
      "Epoch 239/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6907 - val_accuracy: 0.5971\n",
      "Epoch 240/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6907 - val_accuracy: 0.5971\n",
      "Epoch 241/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6907 - val_accuracy: 0.5971\n",
      "Epoch 242/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6907 - val_accuracy: 0.5971\n",
      "Epoch 243/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6907 - val_accuracy: 0.5971\n",
      "Epoch 244/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6907 - val_accuracy: 0.5971\n",
      "Epoch 245/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6907 - val_accuracy: 0.5971\n",
      "Epoch 246/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6907 - val_accuracy: 0.5971\n",
      "Epoch 247/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6907 - val_accuracy: 0.5971\n",
      "Epoch 248/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6907 - val_accuracy: 0.5971\n",
      "Epoch 249/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6907 - val_accuracy: 0.5971\n",
      "Epoch 250/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6907 - val_accuracy: 0.5971\n",
      "Epoch 251/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6908 - val_accuracy: 0.5971\n",
      "Epoch 252/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6908 - val_accuracy: 0.5971\n",
      "Epoch 253/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6908 - val_accuracy: 0.5971\n",
      "Epoch 254/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6908 - val_accuracy: 0.5971\n",
      "Epoch 255/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6908 - val_accuracy: 0.5971\n",
      "Epoch 256/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6908 - val_accuracy: 0.5971\n",
      "Epoch 257/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6908 - val_accuracy: 0.5971\n",
      "Epoch 258/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6908 - val_accuracy: 0.5971\n",
      "Epoch 259/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6908 - val_accuracy: 0.5971\n",
      "Epoch 260/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6908 - val_accuracy: 0.5971\n",
      "Epoch 261/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6908 - val_accuracy: 0.5971\n",
      "Epoch 262/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6908 - val_accuracy: 0.5971\n",
      "Epoch 263/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6908 - val_accuracy: 0.5971\n",
      "Epoch 264/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6908 - val_accuracy: 0.5971\n",
      "Epoch 265/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6908 - val_accuracy: 0.5971\n",
      "Epoch 266/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6908 - val_accuracy: 0.5971\n",
      "Epoch 267/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6908 - val_accuracy: 0.5971\n",
      "Epoch 268/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6908 - val_accuracy: 0.5971\n",
      "Epoch 269/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6908 - val_accuracy: 0.5971\n",
      "Epoch 270/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6908 - val_accuracy: 0.5971\n",
      "Epoch 271/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6908 - val_accuracy: 0.5971\n",
      "Epoch 272/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6908 - val_accuracy: 0.5971\n",
      "Epoch 273/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6908 - val_accuracy: 0.5971\n",
      "Epoch 274/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6908 - val_accuracy: 0.5971\n",
      "Epoch 275/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6908 - val_accuracy: 0.5971\n",
      "Epoch 276/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6908 - val_accuracy: 0.5971\n",
      "Epoch 277/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6908 - val_accuracy: 0.5971\n",
      "Epoch 278/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6908 - val_accuracy: 0.5971\n",
      "Epoch 279/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6908 - val_accuracy: 0.5971\n",
      "Epoch 280/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6908 - val_accuracy: 0.5971\n",
      "Epoch 281/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6908 - val_accuracy: 0.5971\n",
      "Epoch 282/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6908 - val_accuracy: 0.5971\n",
      "Epoch 283/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6908 - val_accuracy: 0.5971\n",
      "Epoch 284/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6908 - val_accuracy: 0.5971\n",
      "Epoch 285/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6908 - val_accuracy: 0.5971\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 286/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6908 - val_accuracy: 0.5971\n",
      "Epoch 287/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6908 - val_accuracy: 0.5971\n",
      "Epoch 288/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6908 - val_accuracy: 0.5971\n",
      "Epoch 289/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6908 - val_accuracy: 0.5971\n",
      "Epoch 290/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6908 - val_accuracy: 0.5971\n",
      "Epoch 291/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6908 - val_accuracy: 0.5971\n",
      "Epoch 292/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6908 - val_accuracy: 0.5971\n",
      "Epoch 293/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6908 - val_accuracy: 0.5971\n",
      "Epoch 294/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6908 - val_accuracy: 0.5971\n",
      "Epoch 295/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6908 - val_accuracy: 0.5971\n",
      "Epoch 296/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6908 - val_accuracy: 0.5971\n",
      "Epoch 297/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6908 - val_accuracy: 0.5971\n",
      "Epoch 298/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6908 - val_accuracy: 0.5971\n",
      "Epoch 299/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6908 - val_accuracy: 0.5971\n",
      "Epoch 300/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6908 - val_accuracy: 0.5971\n",
      "Epoch 301/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6908 - val_accuracy: 0.5971\n",
      "Epoch 302/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6908 - val_accuracy: 0.5971\n",
      "Epoch 303/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6908 - val_accuracy: 0.5971\n",
      "Epoch 304/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6908 - val_accuracy: 0.5971\n",
      "Epoch 305/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6909 - val_accuracy: 0.5971\n",
      "Epoch 306/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6909 - val_accuracy: 0.5971\n",
      "Epoch 307/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6909 - val_accuracy: 0.5971\n",
      "Epoch 308/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6909 - val_accuracy: 0.5971\n",
      "Epoch 309/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6909 - val_accuracy: 0.5971\n",
      "Epoch 310/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6909 - val_accuracy: 0.5971\n",
      "Epoch 311/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6909 - val_accuracy: 0.5971\n",
      "Epoch 312/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6909 - val_accuracy: 0.5971\n",
      "Epoch 313/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6909 - val_accuracy: 0.5971\n",
      "Epoch 314/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6909 - val_accuracy: 0.5971\n",
      "Epoch 315/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6909 - val_accuracy: 0.5971\n",
      "Epoch 316/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6909 - val_accuracy: 0.5971\n",
      "Epoch 317/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6909 - val_accuracy: 0.5971\n",
      "Epoch 318/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6909 - val_accuracy: 0.5971\n",
      "Epoch 319/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6909 - val_accuracy: 0.5971\n",
      "Epoch 320/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6909 - val_accuracy: 0.5971\n",
      "Epoch 321/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6909 - val_accuracy: 0.5971\n",
      "Epoch 322/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6909 - val_accuracy: 0.5971\n",
      "Epoch 323/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6909 - val_accuracy: 0.5971\n",
      "Epoch 324/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6909 - val_accuracy: 0.5971\n",
      "Epoch 325/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6909 - val_accuracy: 0.5971\n",
      "Epoch 326/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6909 - val_accuracy: 0.5971\n",
      "Epoch 327/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6909 - val_accuracy: 0.5971\n",
      "Epoch 328/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6909 - val_accuracy: 0.5971\n",
      "Epoch 329/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6909 - val_accuracy: 0.5971\n",
      "Epoch 330/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6909 - val_accuracy: 0.5971\n",
      "Epoch 331/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6909 - val_accuracy: 0.5971\n",
      "Epoch 332/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6909 - val_accuracy: 0.5971\n",
      "Epoch 333/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6909 - val_accuracy: 0.5971\n",
      "Epoch 334/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6909 - val_accuracy: 0.5971\n",
      "Epoch 335/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6909 - val_accuracy: 0.5971\n",
      "Epoch 336/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6909 - val_accuracy: 0.5971\n",
      "Epoch 337/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6909 - val_accuracy: 0.5971\n",
      "Epoch 338/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6909 - val_accuracy: 0.5971\n",
      "Epoch 339/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6909 - val_accuracy: 0.5971\n",
      "Epoch 340/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6909 - val_accuracy: 0.5971\n",
      "Epoch 341/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6909 - val_accuracy: 0.5971\n",
      "Epoch 342/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6909 - val_accuracy: 0.5971\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 343/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6909 - val_accuracy: 0.5971\n",
      "Epoch 344/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6909 - val_accuracy: 0.5971\n",
      "Epoch 345/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6909 - val_accuracy: 0.5971\n",
      "Epoch 346/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6909 - val_accuracy: 0.5971\n",
      "Epoch 347/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6909 - val_accuracy: 0.5971\n",
      "Epoch 348/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6909 - val_accuracy: 0.5971\n",
      "Epoch 349/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6909 - val_accuracy: 0.5971\n",
      "Epoch 350/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6909 - val_accuracy: 0.5971\n",
      "Epoch 351/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6909 - val_accuracy: 0.5971\n",
      "Epoch 352/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6909 - val_accuracy: 0.5971\n",
      "Epoch 353/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6909 - val_accuracy: 0.5971\n",
      "Epoch 354/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6909 - val_accuracy: 0.5971\n",
      "Epoch 355/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6909 - val_accuracy: 0.5971\n",
      "Epoch 356/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6909 - val_accuracy: 0.5971\n",
      "Epoch 357/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6909 - val_accuracy: 0.5971\n",
      "Epoch 358/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6909 - val_accuracy: 0.5971\n",
      "Epoch 359/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6909 - val_accuracy: 0.5971\n",
      "Epoch 360/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6909 - val_accuracy: 0.5971\n",
      "Epoch 361/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6909 - val_accuracy: 0.5971\n",
      "Epoch 362/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6909 - val_accuracy: 0.5971\n",
      "Epoch 363/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6909 - val_accuracy: 0.5971\n",
      "Epoch 364/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6909 - val_accuracy: 0.5971\n",
      "Epoch 365/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6909 - val_accuracy: 0.5971\n",
      "Epoch 366/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6910 - val_accuracy: 0.5971\n",
      "Epoch 367/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6910 - val_accuracy: 0.5971\n",
      "Epoch 368/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6910 - val_accuracy: 0.5971\n",
      "Epoch 369/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6910 - val_accuracy: 0.5971\n",
      "Epoch 370/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6910 - val_accuracy: 0.5971\n",
      "Epoch 371/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6910 - val_accuracy: 0.5971\n",
      "Epoch 372/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6910 - val_accuracy: 0.5971\n",
      "Epoch 373/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6910 - val_accuracy: 0.5971\n",
      "Epoch 374/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6910 - val_accuracy: 0.5971\n",
      "Epoch 375/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6910 - val_accuracy: 0.5971\n",
      "Epoch 376/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6910 - val_accuracy: 0.5971\n",
      "Epoch 377/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6910 - val_accuracy: 0.5971\n",
      "Epoch 378/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6910 - val_accuracy: 0.5971\n",
      "Epoch 379/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6910 - val_accuracy: 0.5971\n",
      "Epoch 380/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6910 - val_accuracy: 0.5971\n",
      "Epoch 381/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6910 - val_accuracy: 0.5971\n",
      "Epoch 382/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6910 - val_accuracy: 0.5971\n",
      "Epoch 383/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6910 - val_accuracy: 0.5971\n",
      "Epoch 384/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6910 - val_accuracy: 0.5971\n",
      "Epoch 385/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6910 - val_accuracy: 0.5971\n",
      "Epoch 386/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6910 - val_accuracy: 0.5971\n",
      "Epoch 387/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6910 - val_accuracy: 0.5971\n",
      "Epoch 388/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6910 - val_accuracy: 0.5971\n",
      "Epoch 389/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6910 - val_accuracy: 0.5971\n",
      "Epoch 390/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6910 - val_accuracy: 0.5971\n",
      "Epoch 391/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6910 - val_accuracy: 0.5971\n",
      "Epoch 392/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6910 - val_accuracy: 0.5971\n",
      "Epoch 393/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6910 - val_accuracy: 0.5971\n",
      "Epoch 394/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6910 - val_accuracy: 0.5971\n",
      "Epoch 395/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6910 - val_accuracy: 0.5971\n",
      "Epoch 396/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6910 - val_accuracy: 0.5971\n",
      "Epoch 397/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6910 - val_accuracy: 0.5971\n",
      "Epoch 398/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6910 - val_accuracy: 0.5971\n",
      "Epoch 399/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6910 - val_accuracy: 0.5971\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 400/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6910 - val_accuracy: 0.5971\n",
      "Epoch 401/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6910 - val_accuracy: 0.5971\n",
      "Epoch 402/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6910 - val_accuracy: 0.5971\n",
      "Epoch 403/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5064 - val_loss: 0.6910 - val_accuracy: 0.5971\n",
      "Epoch 404/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5064 - val_loss: 0.6910 - val_accuracy: 0.5971\n",
      "Epoch 405/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5064 - val_loss: 0.6910 - val_accuracy: 0.5971\n",
      "Epoch 406/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5064 - val_loss: 0.6910 - val_accuracy: 0.5971\n",
      "Epoch 407/1000\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.6931 - accuracy: 0.5064 - val_loss: 0.6910 - val_accuracy: 0.5971\n",
      "Epoch 408/1000\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.6931 - accuracy: 0.5064 - val_loss: 0.6910 - val_accuracy: 0.5971\n",
      "Epoch 409/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5064 - val_loss: 0.6910 - val_accuracy: 0.5971\n",
      "Epoch 410/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5064 - val_loss: 0.6910 - val_accuracy: 0.5971\n",
      "Epoch 411/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5064 - val_loss: 0.6910 - val_accuracy: 0.5971\n",
      "Epoch 412/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5064 - val_loss: 0.6910 - val_accuracy: 0.5971\n",
      "Epoch 413/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5064 - val_loss: 0.6910 - val_accuracy: 0.5971\n",
      "Epoch 414/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5064 - val_loss: 0.6910 - val_accuracy: 0.5971\n",
      "Epoch 415/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5064 - val_loss: 0.6910 - val_accuracy: 0.5971\n",
      "Epoch 416/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5064 - val_loss: 0.6910 - val_accuracy: 0.5971\n",
      "Epoch 417/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5064 - val_loss: 0.6910 - val_accuracy: 0.5971\n",
      "Epoch 418/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5064 - val_loss: 0.6910 - val_accuracy: 0.5971\n",
      "Epoch 419/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5064 - val_loss: 0.6910 - val_accuracy: 0.5971\n",
      "Epoch 420/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5064 - val_loss: 0.6910 - val_accuracy: 0.5971\n",
      "Epoch 421/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5064 - val_loss: 0.6910 - val_accuracy: 0.5971\n",
      "Epoch 422/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5064 - val_loss: 0.6910 - val_accuracy: 0.5971\n",
      "Epoch 423/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5064 - val_loss: 0.6910 - val_accuracy: 0.5971\n",
      "Epoch 424/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5064 - val_loss: 0.6910 - val_accuracy: 0.5971\n",
      "Epoch 425/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5064 - val_loss: 0.6910 - val_accuracy: 0.5971\n",
      "Epoch 426/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5064 - val_loss: 0.6910 - val_accuracy: 0.5971\n",
      "Epoch 427/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5064 - val_loss: 0.6910 - val_accuracy: 0.5971\n",
      "Epoch 428/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5064 - val_loss: 0.6910 - val_accuracy: 0.5971\n",
      "Epoch 429/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5064 - val_loss: 0.6910 - val_accuracy: 0.5971\n",
      "Epoch 430/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5064 - val_loss: 0.6910 - val_accuracy: 0.5971\n",
      "Epoch 431/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5064 - val_loss: 0.6910 - val_accuracy: 0.5971\n",
      "Epoch 432/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5064 - val_loss: 0.6910 - val_accuracy: 0.5971\n",
      "Epoch 433/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5064 - val_loss: 0.6910 - val_accuracy: 0.5971\n",
      "Epoch 434/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5064 - val_loss: 0.6910 - val_accuracy: 0.5971\n",
      "Epoch 435/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5064 - val_loss: 0.6910 - val_accuracy: 0.5971\n",
      "Epoch 436/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5064 - val_loss: 0.6910 - val_accuracy: 0.5971\n",
      "Epoch 437/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5064 - val_loss: 0.6910 - val_accuracy: 0.5971\n",
      "Epoch 438/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5064 - val_loss: 0.6910 - val_accuracy: 0.5971\n",
      "Epoch 439/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5064 - val_loss: 0.6910 - val_accuracy: 0.5971\n",
      "Epoch 440/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5064 - val_loss: 0.6911 - val_accuracy: 0.5971\n",
      "Epoch 441/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5064 - val_loss: 0.6911 - val_accuracy: 0.5971\n",
      "Epoch 442/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5064 - val_loss: 0.6911 - val_accuracy: 0.5971\n",
      "Epoch 443/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5064 - val_loss: 0.6911 - val_accuracy: 0.5971\n",
      "Epoch 444/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5064 - val_loss: 0.6911 - val_accuracy: 0.5971\n",
      "Epoch 445/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5064 - val_loss: 0.6911 - val_accuracy: 0.5971\n",
      "Epoch 446/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5064 - val_loss: 0.6911 - val_accuracy: 0.5971\n",
      "Epoch 447/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5064 - val_loss: 0.6911 - val_accuracy: 0.5971\n",
      "Epoch 448/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5064 - val_loss: 0.6911 - val_accuracy: 0.5971\n",
      "Epoch 449/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5064 - val_loss: 0.6911 - val_accuracy: 0.5971\n",
      "Epoch 450/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5064 - val_loss: 0.6911 - val_accuracy: 0.5971\n",
      "Epoch 451/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5088 - val_loss: 0.6911 - val_accuracy: 0.5971\n",
      "Epoch 452/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5088 - val_loss: 0.6911 - val_accuracy: 0.5971\n",
      "Epoch 453/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5088 - val_loss: 0.6911 - val_accuracy: 0.5971\n",
      "Epoch 454/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5088 - val_loss: 0.6911 - val_accuracy: 0.5971\n",
      "Epoch 455/1000\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.6931 - accuracy: 0.5088 - val_loss: 0.6911 - val_accuracy: 0.5971\n",
      "Epoch 456/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5088 - val_loss: 0.6911 - val_accuracy: 0.5971\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 457/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5088 - val_loss: 0.6911 - val_accuracy: 0.5971\n",
      "Epoch 458/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5088 - val_loss: 0.6911 - val_accuracy: 0.5971\n",
      "Epoch 459/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5088 - val_loss: 0.6911 - val_accuracy: 0.5971\n",
      "Epoch 460/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5088 - val_loss: 0.6911 - val_accuracy: 0.5971\n",
      "Epoch 461/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5088 - val_loss: 0.6911 - val_accuracy: 0.5971\n",
      "Epoch 462/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5088 - val_loss: 0.6911 - val_accuracy: 0.5971\n",
      "Epoch 463/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5088 - val_loss: 0.6911 - val_accuracy: 0.5971\n",
      "Epoch 464/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5088 - val_loss: 0.6911 - val_accuracy: 0.5971\n",
      "Epoch 465/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5088 - val_loss: 0.6911 - val_accuracy: 0.5971\n",
      "Epoch 466/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5088 - val_loss: 0.6911 - val_accuracy: 0.5971\n",
      "Epoch 467/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5088 - val_loss: 0.6911 - val_accuracy: 0.5971\n",
      "Epoch 468/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5088 - val_loss: 0.6911 - val_accuracy: 0.5971\n",
      "Epoch 469/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5088 - val_loss: 0.6911 - val_accuracy: 0.5971\n",
      "Epoch 470/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5088 - val_loss: 0.6911 - val_accuracy: 0.5971\n",
      "Epoch 471/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5088 - val_loss: 0.6911 - val_accuracy: 0.5971\n",
      "Epoch 472/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5088 - val_loss: 0.6911 - val_accuracy: 0.5971\n",
      "Epoch 473/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5088 - val_loss: 0.6911 - val_accuracy: 0.5971\n",
      "Epoch 474/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5088 - val_loss: 0.6911 - val_accuracy: 0.5971\n",
      "Epoch 475/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5088 - val_loss: 0.6911 - val_accuracy: 0.5971\n",
      "Epoch 476/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5088 - val_loss: 0.6911 - val_accuracy: 0.5971\n",
      "Epoch 477/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5088 - val_loss: 0.6911 - val_accuracy: 0.5971\n",
      "Epoch 478/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5088 - val_loss: 0.6911 - val_accuracy: 0.5971\n",
      "Epoch 479/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5088 - val_loss: 0.6911 - val_accuracy: 0.5971\n",
      "Epoch 480/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5088 - val_loss: 0.6911 - val_accuracy: 0.5971\n",
      "Epoch 481/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5088 - val_loss: 0.6911 - val_accuracy: 0.5971\n",
      "Epoch 482/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5088 - val_loss: 0.6911 - val_accuracy: 0.5971\n",
      "Epoch 483/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5088 - val_loss: 0.6911 - val_accuracy: 0.5971\n",
      "Epoch 484/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5088 - val_loss: 0.6911 - val_accuracy: 0.5971\n",
      "Epoch 485/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5088 - val_loss: 0.6911 - val_accuracy: 0.5971\n",
      "Epoch 486/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5088 - val_loss: 0.6911 - val_accuracy: 0.5971\n",
      "Epoch 487/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5088 - val_loss: 0.6911 - val_accuracy: 0.5971\n",
      "Epoch 488/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5088 - val_loss: 0.6911 - val_accuracy: 0.5971\n",
      "Epoch 489/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5088 - val_loss: 0.6911 - val_accuracy: 0.5971\n",
      "Epoch 490/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5088 - val_loss: 0.6911 - val_accuracy: 0.5971\n",
      "Epoch 491/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5088 - val_loss: 0.6911 - val_accuracy: 0.5971\n",
      "Epoch 492/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5088 - val_loss: 0.6911 - val_accuracy: 0.5971\n",
      "Epoch 493/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5088 - val_loss: 0.6911 - val_accuracy: 0.5971\n",
      "Epoch 494/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5088 - val_loss: 0.6911 - val_accuracy: 0.5971\n",
      "Epoch 495/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5088 - val_loss: 0.6911 - val_accuracy: 0.5971\n",
      "Epoch 496/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5088 - val_loss: 0.6911 - val_accuracy: 0.5971\n",
      "Epoch 497/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5088 - val_loss: 0.6911 - val_accuracy: 0.5971\n",
      "Epoch 498/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5088 - val_loss: 0.6911 - val_accuracy: 0.5971\n",
      "Epoch 499/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5088 - val_loss: 0.6911 - val_accuracy: 0.5971\n",
      "Epoch 500/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5088 - val_loss: 0.6911 - val_accuracy: 0.5971\n",
      "Epoch 501/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5088 - val_loss: 0.6911 - val_accuracy: 0.5971\n",
      "Epoch 502/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5088 - val_loss: 0.6911 - val_accuracy: 0.5971\n",
      "Epoch 503/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5088 - val_loss: 0.6911 - val_accuracy: 0.5971\n",
      "Epoch 504/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5088 - val_loss: 0.6911 - val_accuracy: 0.5971\n",
      "Epoch 505/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5088 - val_loss: 0.6911 - val_accuracy: 0.5971\n",
      "Epoch 506/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5088 - val_loss: 0.6911 - val_accuracy: 0.5971\n",
      "Epoch 507/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5088 - val_loss: 0.6911 - val_accuracy: 0.5971\n",
      "Epoch 508/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5096 - val_loss: 0.6911 - val_accuracy: 0.5971\n",
      "Epoch 509/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5096 - val_loss: 0.6911 - val_accuracy: 0.5971\n",
      "Epoch 510/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5096 - val_loss: 0.6911 - val_accuracy: 0.5971\n",
      "Epoch 511/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5096 - val_loss: 0.6911 - val_accuracy: 0.5971\n",
      "Epoch 512/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5096 - val_loss: 0.6911 - val_accuracy: 0.5971\n",
      "Epoch 513/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5096 - val_loss: 0.6911 - val_accuracy: 0.5971\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 514/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5088 - val_loss: 0.6911 - val_accuracy: 0.5971\n",
      "Epoch 515/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5088 - val_loss: 0.6911 - val_accuracy: 0.5971\n",
      "Epoch 516/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5088 - val_loss: 0.6911 - val_accuracy: 0.5971\n",
      "Epoch 517/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5088 - val_loss: 0.6911 - val_accuracy: 0.5971\n",
      "Epoch 518/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5088 - val_loss: 0.6911 - val_accuracy: 0.5971\n",
      "Epoch 519/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5088 - val_loss: 0.6911 - val_accuracy: 0.5971\n",
      "Epoch 520/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5088 - val_loss: 0.6911 - val_accuracy: 0.5971\n",
      "Epoch 521/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5088 - val_loss: 0.6911 - val_accuracy: 0.5971\n",
      "Epoch 522/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5088 - val_loss: 0.6911 - val_accuracy: 0.5971\n",
      "Epoch 523/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5088 - val_loss: 0.6911 - val_accuracy: 0.5971\n",
      "Epoch 524/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5088 - val_loss: 0.6911 - val_accuracy: 0.5971\n",
      "Epoch 525/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5088 - val_loss: 0.6911 - val_accuracy: 0.5971\n",
      "Epoch 526/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5088 - val_loss: 0.6911 - val_accuracy: 0.5971\n",
      "Epoch 527/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5088 - val_loss: 0.6911 - val_accuracy: 0.5971\n",
      "Epoch 528/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5088 - val_loss: 0.6911 - val_accuracy: 0.5971\n",
      "Epoch 529/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5088 - val_loss: 0.6911 - val_accuracy: 0.5971\n",
      "Epoch 530/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5104 - val_loss: 0.6911 - val_accuracy: 0.5971\n",
      "Epoch 531/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5104 - val_loss: 0.6911 - val_accuracy: 0.5971\n",
      "Epoch 532/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5104 - val_loss: 0.6911 - val_accuracy: 0.5971\n",
      "Epoch 533/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5104 - val_loss: 0.6911 - val_accuracy: 0.5971\n",
      "Epoch 534/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5104 - val_loss: 0.6911 - val_accuracy: 0.5971\n",
      "Epoch 535/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5104 - val_loss: 0.6912 - val_accuracy: 0.5971\n",
      "Epoch 536/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5104 - val_loss: 0.6912 - val_accuracy: 0.5971\n",
      "Epoch 537/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5104 - val_loss: 0.6912 - val_accuracy: 0.5971\n",
      "Epoch 538/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5104 - val_loss: 0.6912 - val_accuracy: 0.5971\n",
      "Epoch 539/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5104 - val_loss: 0.6912 - val_accuracy: 0.5971\n",
      "Epoch 540/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5104 - val_loss: 0.6912 - val_accuracy: 0.5971\n",
      "Epoch 541/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5104 - val_loss: 0.6912 - val_accuracy: 0.5971\n",
      "Epoch 542/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5104 - val_loss: 0.6912 - val_accuracy: 0.5971\n",
      "Epoch 543/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5104 - val_loss: 0.6912 - val_accuracy: 0.5971\n",
      "Epoch 544/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5104 - val_loss: 0.6912 - val_accuracy: 0.5971\n",
      "Epoch 545/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5104 - val_loss: 0.6912 - val_accuracy: 0.5971\n",
      "Epoch 546/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5104 - val_loss: 0.6912 - val_accuracy: 0.5971\n",
      "Epoch 547/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5104 - val_loss: 0.6912 - val_accuracy: 0.5971\n",
      "Epoch 548/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5104 - val_loss: 0.6912 - val_accuracy: 0.5971\n",
      "Epoch 549/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5112 - val_loss: 0.6912 - val_accuracy: 0.5971\n",
      "Epoch 550/1000\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.6931 - accuracy: 0.5112 - val_loss: 0.6912 - val_accuracy: 0.5971\n",
      "Epoch 551/1000\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.6931 - accuracy: 0.5112 - val_loss: 0.6912 - val_accuracy: 0.5971\n",
      "Epoch 552/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5112 - val_loss: 0.6912 - val_accuracy: 0.5971\n",
      "Epoch 553/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5112 - val_loss: 0.6912 - val_accuracy: 0.5971\n",
      "Epoch 554/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5112 - val_loss: 0.6912 - val_accuracy: 0.5971\n",
      "Epoch 555/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5112 - val_loss: 0.6912 - val_accuracy: 0.5971\n",
      "Epoch 556/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5112 - val_loss: 0.6912 - val_accuracy: 0.5971\n",
      "Epoch 557/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5112 - val_loss: 0.6912 - val_accuracy: 0.5971\n",
      "Epoch 558/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5112 - val_loss: 0.6912 - val_accuracy: 0.5971\n",
      "Epoch 559/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5112 - val_loss: 0.6912 - val_accuracy: 0.5971\n",
      "Epoch 560/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5112 - val_loss: 0.6912 - val_accuracy: 0.5971\n",
      "Epoch 561/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5112 - val_loss: 0.6912 - val_accuracy: 0.5971\n",
      "Epoch 562/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5112 - val_loss: 0.6912 - val_accuracy: 0.5971\n",
      "Epoch 563/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5112 - val_loss: 0.6912 - val_accuracy: 0.5971\n",
      "Epoch 564/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5112 - val_loss: 0.6912 - val_accuracy: 0.5971\n",
      "Epoch 565/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5104 - val_loss: 0.6912 - val_accuracy: 0.5971\n",
      "Epoch 566/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5096 - val_loss: 0.6912 - val_accuracy: 0.5971\n",
      "Epoch 567/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5096 - val_loss: 0.6912 - val_accuracy: 0.5971\n",
      "Epoch 568/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5096 - val_loss: 0.6912 - val_accuracy: 0.5971\n",
      "Epoch 569/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5096 - val_loss: 0.6912 - val_accuracy: 0.5971\n",
      "Epoch 570/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5096 - val_loss: 0.6912 - val_accuracy: 0.5971\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 571/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5096 - val_loss: 0.6912 - val_accuracy: 0.5971\n",
      "Epoch 572/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5096 - val_loss: 0.6912 - val_accuracy: 0.5971\n",
      "Epoch 573/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5096 - val_loss: 0.6912 - val_accuracy: 0.5971\n",
      "Epoch 574/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5096 - val_loss: 0.6912 - val_accuracy: 0.5971\n",
      "Epoch 575/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5096 - val_loss: 0.6912 - val_accuracy: 0.5971\n",
      "Epoch 576/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5096 - val_loss: 0.6912 - val_accuracy: 0.5971\n",
      "Epoch 577/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5096 - val_loss: 0.6912 - val_accuracy: 0.5971\n",
      "Epoch 578/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5096 - val_loss: 0.6912 - val_accuracy: 0.5971\n",
      "Epoch 579/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5096 - val_loss: 0.6912 - val_accuracy: 0.5971\n",
      "Epoch 580/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5096 - val_loss: 0.6912 - val_accuracy: 0.5971\n",
      "Epoch 581/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5096 - val_loss: 0.6912 - val_accuracy: 0.5971\n",
      "Epoch 582/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5096 - val_loss: 0.6912 - val_accuracy: 0.5971\n",
      "Epoch 583/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5096 - val_loss: 0.6912 - val_accuracy: 0.5971\n",
      "Epoch 584/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5096 - val_loss: 0.6912 - val_accuracy: 0.5971\n",
      "Epoch 585/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5096 - val_loss: 0.6912 - val_accuracy: 0.5971\n",
      "Epoch 586/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5096 - val_loss: 0.6912 - val_accuracy: 0.5971\n",
      "Epoch 587/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5096 - val_loss: 0.6912 - val_accuracy: 0.5971\n",
      "Epoch 588/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5096 - val_loss: 0.6912 - val_accuracy: 0.5971\n",
      "Epoch 589/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5096 - val_loss: 0.6912 - val_accuracy: 0.5971\n",
      "Epoch 590/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5096 - val_loss: 0.6912 - val_accuracy: 0.5971\n",
      "Epoch 591/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5096 - val_loss: 0.6912 - val_accuracy: 0.5971\n",
      "Epoch 592/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5096 - val_loss: 0.6912 - val_accuracy: 0.5971\n",
      "Epoch 593/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5096 - val_loss: 0.6912 - val_accuracy: 0.5971\n",
      "Epoch 594/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5096 - val_loss: 0.6912 - val_accuracy: 0.5971\n",
      "Epoch 595/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5096 - val_loss: 0.6912 - val_accuracy: 0.5971\n",
      "Epoch 596/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5096 - val_loss: 0.6912 - val_accuracy: 0.5971\n",
      "Epoch 597/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5096 - val_loss: 0.6912 - val_accuracy: 0.5971\n",
      "Epoch 598/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5096 - val_loss: 0.6912 - val_accuracy: 0.5971\n",
      "Epoch 599/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5096 - val_loss: 0.6912 - val_accuracy: 0.5971\n",
      "Epoch 600/1000\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.6931 - accuracy: 0.5096 - val_loss: 0.6912 - val_accuracy: 0.5971\n",
      "Epoch 601/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5096 - val_loss: 0.6912 - val_accuracy: 0.5971\n",
      "Epoch 602/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5096 - val_loss: 0.6912 - val_accuracy: 0.5971\n",
      "Epoch 603/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6912 - val_accuracy: 0.5971\n",
      "Epoch 604/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6912 - val_accuracy: 0.5971\n",
      "Epoch 605/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6912 - val_accuracy: 0.5971\n",
      "Epoch 606/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6912 - val_accuracy: 0.5971\n",
      "Epoch 607/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6912 - val_accuracy: 0.5971\n",
      "Epoch 608/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6912 - val_accuracy: 0.5971\n",
      "Epoch 609/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6912 - val_accuracy: 0.5971\n",
      "Epoch 610/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6912 - val_accuracy: 0.5971\n",
      "Epoch 611/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6912 - val_accuracy: 0.5971\n",
      "Epoch 612/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6912 - val_accuracy: 0.5971\n",
      "Epoch 613/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6912 - val_accuracy: 0.5971\n",
      "Epoch 614/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6912 - val_accuracy: 0.5971\n",
      "Epoch 615/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6912 - val_accuracy: 0.5971\n",
      "Epoch 616/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6912 - val_accuracy: 0.5971\n",
      "Epoch 617/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6912 - val_accuracy: 0.5971\n",
      "Epoch 618/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6912 - val_accuracy: 0.5971\n",
      "Epoch 619/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6912 - val_accuracy: 0.5971\n",
      "Epoch 620/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6912 - val_accuracy: 0.5971\n",
      "Epoch 621/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6912 - val_accuracy: 0.5971\n",
      "Epoch 622/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6912 - val_accuracy: 0.5971\n",
      "Epoch 623/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6912 - val_accuracy: 0.5971\n",
      "Epoch 624/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6912 - val_accuracy: 0.5971\n",
      "Epoch 625/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6912 - val_accuracy: 0.5971\n",
      "Epoch 626/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6912 - val_accuracy: 0.5971\n",
      "Epoch 627/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6912 - val_accuracy: 0.5971\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 628/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6912 - val_accuracy: 0.5971\n",
      "Epoch 629/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6912 - val_accuracy: 0.5971\n",
      "Epoch 630/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6912 - val_accuracy: 0.5971\n",
      "Epoch 631/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6912 - val_accuracy: 0.5971\n",
      "Epoch 632/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6912 - val_accuracy: 0.5971\n",
      "Epoch 633/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6912 - val_accuracy: 0.5971\n",
      "Epoch 634/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6912 - val_accuracy: 0.5971\n",
      "Epoch 635/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6912 - val_accuracy: 0.5971\n",
      "Epoch 636/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6912 - val_accuracy: 0.5971\n",
      "Epoch 637/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6912 - val_accuracy: 0.5971\n",
      "Epoch 638/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6912 - val_accuracy: 0.5971\n",
      "Epoch 639/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6912 - val_accuracy: 0.5971\n",
      "Epoch 640/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6912 - val_accuracy: 0.5971\n",
      "Epoch 641/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6912 - val_accuracy: 0.5971\n",
      "Epoch 642/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6912 - val_accuracy: 0.5971\n",
      "Epoch 643/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6912 - val_accuracy: 0.5971\n",
      "Epoch 644/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6912 - val_accuracy: 0.5971\n",
      "Epoch 645/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6912 - val_accuracy: 0.5971\n",
      "Epoch 646/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6912 - val_accuracy: 0.5971\n",
      "Epoch 647/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6912 - val_accuracy: 0.5971\n",
      "Epoch 648/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6912 - val_accuracy: 0.5971\n",
      "Epoch 649/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6912 - val_accuracy: 0.5971\n",
      "Epoch 650/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6912 - val_accuracy: 0.5971\n",
      "Epoch 651/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6912 - val_accuracy: 0.5971\n",
      "Epoch 652/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6912 - val_accuracy: 0.5971\n",
      "Epoch 653/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6912 - val_accuracy: 0.5971\n",
      "Epoch 654/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6912 - val_accuracy: 0.5971\n",
      "Epoch 655/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6912 - val_accuracy: 0.5971\n",
      "Epoch 656/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6912 - val_accuracy: 0.5971\n",
      "Epoch 657/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6912 - val_accuracy: 0.5971\n",
      "Epoch 658/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6912 - val_accuracy: 0.5971\n",
      "Epoch 659/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6912 - val_accuracy: 0.5971\n",
      "Epoch 660/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6912 - val_accuracy: 0.5971\n",
      "Epoch 661/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6912 - val_accuracy: 0.5971\n",
      "Epoch 662/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6912 - val_accuracy: 0.5971\n",
      "Epoch 663/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6912 - val_accuracy: 0.5971\n",
      "Epoch 664/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6912 - val_accuracy: 0.5971\n",
      "Epoch 665/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6912 - val_accuracy: 0.5971\n",
      "Epoch 666/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6912 - val_accuracy: 0.5971\n",
      "Epoch 667/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6912 - val_accuracy: 0.5971\n",
      "Epoch 668/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6912 - val_accuracy: 0.5971\n",
      "Epoch 669/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6912 - val_accuracy: 0.5971\n",
      "Epoch 670/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6912 - val_accuracy: 0.5971\n",
      "Epoch 671/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6912 - val_accuracy: 0.5971\n",
      "Epoch 672/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6912 - val_accuracy: 0.5971\n",
      "Epoch 673/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6913 - val_accuracy: 0.5971\n",
      "Epoch 674/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6913 - val_accuracy: 0.5971\n",
      "Epoch 675/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6913 - val_accuracy: 0.5971\n",
      "Epoch 676/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6913 - val_accuracy: 0.5971\n",
      "Epoch 677/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6913 - val_accuracy: 0.5971\n",
      "Epoch 678/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6913 - val_accuracy: 0.5971\n",
      "Epoch 679/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6913 - val_accuracy: 0.5971\n",
      "Epoch 680/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6913 - val_accuracy: 0.5971\n",
      "Epoch 681/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6913 - val_accuracy: 0.5971\n",
      "Epoch 682/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6913 - val_accuracy: 0.5971\n",
      "Epoch 683/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6913 - val_accuracy: 0.5971\n",
      "Epoch 684/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6913 - val_accuracy: 0.5971\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 685/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6913 - val_accuracy: 0.5971\n",
      "Epoch 686/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6913 - val_accuracy: 0.5971\n",
      "Epoch 687/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6913 - val_accuracy: 0.5971\n",
      "Epoch 688/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6913 - val_accuracy: 0.5971\n",
      "Epoch 689/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6913 - val_accuracy: 0.5971\n",
      "Epoch 690/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5088 - val_loss: 0.6913 - val_accuracy: 0.5971\n",
      "Epoch 691/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5088 - val_loss: 0.6913 - val_accuracy: 0.5971\n",
      "Epoch 692/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5088 - val_loss: 0.6913 - val_accuracy: 0.5971\n",
      "Epoch 693/1000\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.6931 - accuracy: 0.5088 - val_loss: 0.6913 - val_accuracy: 0.5971\n",
      "Epoch 694/1000\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.6931 - accuracy: 0.5088 - val_loss: 0.6913 - val_accuracy: 0.5971\n",
      "Epoch 695/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5088 - val_loss: 0.6913 - val_accuracy: 0.5971\n",
      "Epoch 696/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5088 - val_loss: 0.6913 - val_accuracy: 0.5971\n",
      "Epoch 697/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5088 - val_loss: 0.6913 - val_accuracy: 0.5971\n",
      "Epoch 698/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5088 - val_loss: 0.6913 - val_accuracy: 0.5971\n",
      "Epoch 699/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5088 - val_loss: 0.6913 - val_accuracy: 0.5971\n",
      "Epoch 700/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5088 - val_loss: 0.6913 - val_accuracy: 0.5971\n",
      "Epoch 701/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5088 - val_loss: 0.6913 - val_accuracy: 0.5971\n",
      "Epoch 702/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5088 - val_loss: 0.6913 - val_accuracy: 0.5971\n",
      "Epoch 703/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5088 - val_loss: 0.6913 - val_accuracy: 0.5971\n",
      "Epoch 704/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5088 - val_loss: 0.6913 - val_accuracy: 0.5971\n",
      "Epoch 705/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5088 - val_loss: 0.6913 - val_accuracy: 0.5971\n",
      "Epoch 706/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5088 - val_loss: 0.6913 - val_accuracy: 0.5971\n",
      "Epoch 707/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5088 - val_loss: 0.6913 - val_accuracy: 0.5971\n",
      "Epoch 708/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5088 - val_loss: 0.6913 - val_accuracy: 0.5971\n",
      "Epoch 709/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5088 - val_loss: 0.6913 - val_accuracy: 0.5971\n",
      "Epoch 710/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5088 - val_loss: 0.6913 - val_accuracy: 0.5971\n",
      "Epoch 711/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5088 - val_loss: 0.6913 - val_accuracy: 0.5971\n",
      "Epoch 712/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5088 - val_loss: 0.6913 - val_accuracy: 0.5971\n",
      "Epoch 713/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5088 - val_loss: 0.6913 - val_accuracy: 0.5971\n",
      "Epoch 714/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5088 - val_loss: 0.6913 - val_accuracy: 0.5971\n",
      "Epoch 715/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5088 - val_loss: 0.6913 - val_accuracy: 0.5971\n",
      "Epoch 716/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5088 - val_loss: 0.6913 - val_accuracy: 0.5971\n",
      "Epoch 717/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5088 - val_loss: 0.6913 - val_accuracy: 0.5971\n",
      "Epoch 718/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5088 - val_loss: 0.6913 - val_accuracy: 0.5971\n",
      "Epoch 719/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5088 - val_loss: 0.6913 - val_accuracy: 0.5971\n",
      "Epoch 720/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5088 - val_loss: 0.6913 - val_accuracy: 0.5971\n",
      "Epoch 721/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5088 - val_loss: 0.6913 - val_accuracy: 0.5971\n",
      "Epoch 722/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5088 - val_loss: 0.6913 - val_accuracy: 0.5971\n",
      "Epoch 723/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5088 - val_loss: 0.6913 - val_accuracy: 0.5971\n",
      "Epoch 724/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5088 - val_loss: 0.6913 - val_accuracy: 0.5971\n",
      "Epoch 725/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5088 - val_loss: 0.6913 - val_accuracy: 0.5971\n",
      "Epoch 726/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5088 - val_loss: 0.6913 - val_accuracy: 0.5971\n",
      "Epoch 727/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5088 - val_loss: 0.6913 - val_accuracy: 0.5971\n",
      "Epoch 728/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5088 - val_loss: 0.6913 - val_accuracy: 0.5971\n",
      "Epoch 729/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5088 - val_loss: 0.6913 - val_accuracy: 0.5971\n",
      "Epoch 730/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5088 - val_loss: 0.6913 - val_accuracy: 0.5971\n",
      "Epoch 731/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5088 - val_loss: 0.6913 - val_accuracy: 0.5971\n",
      "Epoch 732/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5088 - val_loss: 0.6913 - val_accuracy: 0.5971\n",
      "Epoch 733/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5088 - val_loss: 0.6913 - val_accuracy: 0.5971\n",
      "Epoch 734/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5088 - val_loss: 0.6913 - val_accuracy: 0.5971\n",
      "Epoch 735/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5088 - val_loss: 0.6913 - val_accuracy: 0.5971\n",
      "Epoch 736/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5088 - val_loss: 0.6913 - val_accuracy: 0.5971\n",
      "Epoch 737/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5088 - val_loss: 0.6913 - val_accuracy: 0.5971\n",
      "Epoch 738/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5088 - val_loss: 0.6913 - val_accuracy: 0.5971\n",
      "Epoch 739/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5088 - val_loss: 0.6913 - val_accuracy: 0.5971\n",
      "Epoch 740/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5088 - val_loss: 0.6913 - val_accuracy: 0.5971\n",
      "Epoch 741/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5088 - val_loss: 0.6913 - val_accuracy: 0.5971\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 742/1000\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.6931 - accuracy: 0.5088 - val_loss: 0.6913 - val_accuracy: 0.5971\n",
      "Epoch 743/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5088 - val_loss: 0.6913 - val_accuracy: 0.5971\n",
      "Epoch 744/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5088 - val_loss: 0.6913 - val_accuracy: 0.5971\n",
      "Epoch 745/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5088 - val_loss: 0.6913 - val_accuracy: 0.5971\n",
      "Epoch 746/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5088 - val_loss: 0.6913 - val_accuracy: 0.5971\n",
      "Epoch 747/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5088 - val_loss: 0.6913 - val_accuracy: 0.5971\n",
      "Epoch 748/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5088 - val_loss: 0.6913 - val_accuracy: 0.5971\n",
      "Epoch 749/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5088 - val_loss: 0.6913 - val_accuracy: 0.5971\n",
      "Epoch 750/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5088 - val_loss: 0.6913 - val_accuracy: 0.5971\n",
      "Epoch 751/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5088 - val_loss: 0.6913 - val_accuracy: 0.5971\n",
      "Epoch 752/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5088 - val_loss: 0.6913 - val_accuracy: 0.5971\n",
      "Epoch 753/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5088 - val_loss: 0.6913 - val_accuracy: 0.5971\n",
      "Epoch 754/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5088 - val_loss: 0.6913 - val_accuracy: 0.5971\n",
      "Epoch 755/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5088 - val_loss: 0.6913 - val_accuracy: 0.5971\n",
      "Epoch 756/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5088 - val_loss: 0.6913 - val_accuracy: 0.5971\n",
      "Epoch 757/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5088 - val_loss: 0.6913 - val_accuracy: 0.5971\n",
      "Epoch 758/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5088 - val_loss: 0.6913 - val_accuracy: 0.5971\n",
      "Epoch 759/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6913 - val_accuracy: 0.5971\n",
      "Epoch 760/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6913 - val_accuracy: 0.5971\n",
      "Epoch 761/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6913 - val_accuracy: 0.5971\n",
      "Epoch 762/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6913 - val_accuracy: 0.5971\n",
      "Epoch 763/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6913 - val_accuracy: 0.5971\n",
      "Epoch 764/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6913 - val_accuracy: 0.5971\n",
      "Epoch 765/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6913 - val_accuracy: 0.5971\n",
      "Epoch 766/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6913 - val_accuracy: 0.5971\n",
      "Epoch 767/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6913 - val_accuracy: 0.5971\n",
      "Epoch 768/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6913 - val_accuracy: 0.5971\n",
      "Epoch 769/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6913 - val_accuracy: 0.5971\n",
      "Epoch 770/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6913 - val_accuracy: 0.5971\n",
      "Epoch 771/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6913 - val_accuracy: 0.5971\n",
      "Epoch 772/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6913 - val_accuracy: 0.5971\n",
      "Epoch 773/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6913 - val_accuracy: 0.5971\n",
      "Epoch 774/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6913 - val_accuracy: 0.5971\n",
      "Epoch 775/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6913 - val_accuracy: 0.5971\n",
      "Epoch 776/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6913 - val_accuracy: 0.5971\n",
      "Epoch 777/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6913 - val_accuracy: 0.5971\n",
      "Epoch 778/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6913 - val_accuracy: 0.5971\n",
      "Epoch 779/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6913 - val_accuracy: 0.5971\n",
      "Epoch 780/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6913 - val_accuracy: 0.5971\n",
      "Epoch 781/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6913 - val_accuracy: 0.5971\n",
      "Epoch 782/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6913 - val_accuracy: 0.5971\n",
      "Epoch 783/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6913 - val_accuracy: 0.5971\n",
      "Epoch 784/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6913 - val_accuracy: 0.5971\n",
      "Epoch 785/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6913 - val_accuracy: 0.5971\n",
      "Epoch 786/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6913 - val_accuracy: 0.5971\n",
      "Epoch 787/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6913 - val_accuracy: 0.5971\n",
      "Epoch 788/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6913 - val_accuracy: 0.5971\n",
      "Epoch 789/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6913 - val_accuracy: 0.5971\n",
      "Epoch 790/1000\n",
      " 1/63 [..............................] - ETA: 0s - loss: 0.6917 - accuracy: 0.4500"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-107-9f1f7934ad06>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvalidation_split\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1206\u001b[0m         \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_epoch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1207\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcatch_stop_iteration\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1208\u001b[1;33m           \u001b[1;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1209\u001b[0m             with tf.profiler.experimental.Trace(\n\u001b[0;32m   1210\u001b[0m                 \u001b[1;34m'train'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\keras\\engine\\data_adapter.py\u001b[0m in \u001b[0;36msteps\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1248\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_insufficient_data\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# Set by `catch_stop_iteration`.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1249\u001b[0m         \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1250\u001b[1;33m       \u001b[0moriginal_spe\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_steps_per_execution\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1251\u001b[0m       can_run_full_execution = (\n\u001b[0;32m   1252\u001b[0m           \u001b[0moriginal_spe\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32mor\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    643\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    644\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 645\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    646\u001b[0m     raise NotImplementedError(\n\u001b[0;32m    647\u001b[0m         \"numpy() is only available when eager execution is enabled.\")\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1147\u001b[0m     \"\"\"\n\u001b[0;32m   1148\u001b[0m     \u001b[1;31m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1149\u001b[1;33m     \u001b[0mmaybe_arr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1150\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmaybe_arr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1151\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1113\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1114\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1115\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1116\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1117\u001b[0m       \u001b[1;32mraise\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history = classifier.fit(X,y, epochs=1000,batch_size=20,verbose=1,validation_split=0.1,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "580f3595",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train Loss', 'Validation Loss'], loc=\"upper right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1634eb8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
