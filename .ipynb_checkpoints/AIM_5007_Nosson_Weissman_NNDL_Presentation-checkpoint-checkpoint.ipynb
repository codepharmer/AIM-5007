{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d831d2d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation\n",
    "from tensorflow import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eaab91e",
   "metadata": {},
   "source": [
    "## Exercise 3.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "48ea85bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num examples in dataset =  10000\n",
      "Number of Features for each example =  10\n",
      "Number of possible output class =  [0 1]\n"
     ]
    }
   ],
   "source": [
    "X = pd.read_csv('https://raw.githubusercontent.com/PacktWorkshops/The-Deep-Learning-with-Keras-Workshop/master/Chapter03/data/tree_class_feats.csv')\n",
    "y = pd.read_csv('https://raw.githubusercontent.com/PacktWorkshops/The-Deep-Learning-with-Keras-Workshop/master/Chapter03/data/tree_class_target.csv')\n",
    "\n",
    "print(\"Num examples in dataset = \",X.shape[0])\n",
    "print(\"Number of Features for each example = \", X.shape[1])\n",
    "print(\"Number of possible output class = \", np.unique(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "be416526",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e53fbb19",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5d0a1af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc4d5bd6",
   "metadata": {},
   "source": [
    "### Step 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e1873857",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(10,activation='tanh', input_dim=10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d54bc95",
   "metadata": {},
   "source": [
    "### Step 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2043d5ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(5, activation='tanh'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb439f6c",
   "metadata": {},
   "source": [
    "### Step 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f465dd33",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "02efa974",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 10)                110       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                110       \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 5)                 55        \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 6         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 281\n",
      "Trainable params: 281\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='sgd', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "663a9d36",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.4622 - accuracy: 0.7751 - val_loss: 0.3426 - val_accuracy: 0.8515\n",
      "Epoch 2/100\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3429 - accuracy: 0.8454 - val_loss: 0.3036 - val_accuracy: 0.8645\n",
      "Epoch 3/100\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3096 - accuracy: 0.8621 - val_loss: 0.2845 - val_accuracy: 0.8760\n",
      "Epoch 4/100\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.2864 - accuracy: 0.8776 - val_loss: 0.2651 - val_accuracy: 0.8915\n",
      "Epoch 5/100\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.2620 - accuracy: 0.8906 - val_loss: 0.2382 - val_accuracy: 0.9055\n",
      "Epoch 6/100\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.2384 - accuracy: 0.9026 - val_loss: 0.2132 - val_accuracy: 0.9125\n",
      "Epoch 7/100\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.2194 - accuracy: 0.9116 - val_loss: 0.1970 - val_accuracy: 0.9200\n",
      "Epoch 8/100\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.2070 - accuracy: 0.9146 - val_loss: 0.1876 - val_accuracy: 0.9230\n",
      "Epoch 9/100\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.1992 - accuracy: 0.9197 - val_loss: 0.1818 - val_accuracy: 0.9285\n",
      "Epoch 10/100\n",
      "1600/1600 [==============================] - 3s 2ms/step - loss: 0.1936 - accuracy: 0.9239 - val_loss: 0.1779 - val_accuracy: 0.9310\n",
      "Epoch 11/100\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.1895 - accuracy: 0.9258 - val_loss: 0.1755 - val_accuracy: 0.9305\n",
      "Epoch 12/100\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.1865 - accuracy: 0.9266 - val_loss: 0.1740 - val_accuracy: 0.9315\n",
      "Epoch 13/100\n",
      "1600/1600 [==============================] - 3s 2ms/step - loss: 0.1842 - accuracy: 0.9269 - val_loss: 0.1728 - val_accuracy: 0.9315\n",
      "Epoch 14/100\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.1824 - accuracy: 0.9284 - val_loss: 0.1718 - val_accuracy: 0.9330\n",
      "Epoch 15/100\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.1807 - accuracy: 0.9290 - val_loss: 0.1707 - val_accuracy: 0.9320\n",
      "Epoch 16/100\n",
      "1600/1600 [==============================] - 3s 2ms/step - loss: 0.1792 - accuracy: 0.9295 - val_loss: 0.1697 - val_accuracy: 0.9310\n",
      "Epoch 17/100\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.1778 - accuracy: 0.9301 - val_loss: 0.1686 - val_accuracy: 0.9325\n",
      "Epoch 18/100\n",
      "1600/1600 [==============================] - 3s 2ms/step - loss: 0.1764 - accuracy: 0.9314 - val_loss: 0.1673 - val_accuracy: 0.9350\n",
      "Epoch 19/100\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.1749 - accuracy: 0.9330 - val_loss: 0.1657 - val_accuracy: 0.9350\n",
      "Epoch 20/100\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.1733 - accuracy: 0.9344 - val_loss: 0.1639 - val_accuracy: 0.9365\n",
      "Epoch 21/100\n",
      "1600/1600 [==============================] - 3s 2ms/step - loss: 0.1718 - accuracy: 0.9349 - val_loss: 0.1620 - val_accuracy: 0.9380\n",
      "Epoch 22/100\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.1703 - accuracy: 0.9349 - val_loss: 0.1603 - val_accuracy: 0.9385\n",
      "Epoch 23/100\n",
      "1600/1600 [==============================] - 3s 2ms/step - loss: 0.1688 - accuracy: 0.9352 - val_loss: 0.1587 - val_accuracy: 0.9420\n",
      "Epoch 24/100\n",
      "1600/1600 [==============================] - 3s 2ms/step - loss: 0.1673 - accuracy: 0.9358 - val_loss: 0.1571 - val_accuracy: 0.9415\n",
      "Epoch 25/100\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.1659 - accuracy: 0.9361 - val_loss: 0.1555 - val_accuracy: 0.9420\n",
      "Epoch 26/100\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.1644 - accuracy: 0.9359 - val_loss: 0.1541 - val_accuracy: 0.9425\n",
      "Epoch 27/100\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.1630 - accuracy: 0.9365 - val_loss: 0.1529 - val_accuracy: 0.9430\n",
      "Epoch 28/100\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.1616 - accuracy: 0.9367 - val_loss: 0.1520 - val_accuracy: 0.9425\n",
      "Epoch 29/100\n",
      "1600/1600 [==============================] - 3s 2ms/step - loss: 0.1604 - accuracy: 0.9367 - val_loss: 0.1513 - val_accuracy: 0.9420\n",
      "Epoch 30/100\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.1592 - accuracy: 0.9370 - val_loss: 0.1508 - val_accuracy: 0.9410\n",
      "Epoch 31/100\n",
      "1600/1600 [==============================] - 3s 2ms/step - loss: 0.1580 - accuracy: 0.9373 - val_loss: 0.1505 - val_accuracy: 0.9410\n",
      "Epoch 32/100\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.1570 - accuracy: 0.9369 - val_loss: 0.1504 - val_accuracy: 0.9445\n",
      "Epoch 33/100\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.1560 - accuracy: 0.9376 - val_loss: 0.1503 - val_accuracy: 0.9435\n",
      "Epoch 34/100\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.1550 - accuracy: 0.9383 - val_loss: 0.1503 - val_accuracy: 0.9430\n",
      "Epoch 35/100\n",
      "1600/1600 [==============================] - 2s 2ms/step - loss: 0.1542 - accuracy: 0.9388 - val_loss: 0.1505 - val_accuracy: 0.9435\n",
      "Epoch 36/100\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.1533 - accuracy: 0.9394 - val_loss: 0.1506 - val_accuracy: 0.9440\n",
      "Epoch 37/100\n",
      "1600/1600 [==============================] - 3s 2ms/step - loss: 0.1526 - accuracy: 0.9394 - val_loss: 0.1508 - val_accuracy: 0.9440\n",
      "Epoch 38/100\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.1519 - accuracy: 0.9404 - val_loss: 0.1510 - val_accuracy: 0.9420\n",
      "Epoch 39/100\n",
      "1600/1600 [==============================] - 3s 2ms/step - loss: 0.1512 - accuracy: 0.9417 - val_loss: 0.1511 - val_accuracy: 0.9435\n",
      "Epoch 40/100\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.1506 - accuracy: 0.9419 - val_loss: 0.1513 - val_accuracy: 0.9435\n",
      "Epoch 41/100\n",
      "1600/1600 [==============================] - 3s 2ms/step - loss: 0.1500 - accuracy: 0.9423 - val_loss: 0.1514 - val_accuracy: 0.9435\n",
      "Epoch 42/100\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.1495 - accuracy: 0.9427 - val_loss: 0.1514 - val_accuracy: 0.9435\n",
      "Epoch 43/100\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.1490 - accuracy: 0.9434 - val_loss: 0.1515 - val_accuracy: 0.9440\n",
      "Epoch 44/100\n",
      "1600/1600 [==============================] - 3s 2ms/step - loss: 0.1485 - accuracy: 0.9434 - val_loss: 0.1516 - val_accuracy: 0.9440\n",
      "Epoch 45/100\n",
      "1600/1600 [==============================] - 3s 2ms/step - loss: 0.1480 - accuracy: 0.9436 - val_loss: 0.1516 - val_accuracy: 0.9435\n",
      "Epoch 46/100\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.1475 - accuracy: 0.9438 - val_loss: 0.1516 - val_accuracy: 0.9430\n",
      "Epoch 47/100\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.1471 - accuracy: 0.9439 - val_loss: 0.1516 - val_accuracy: 0.9435\n",
      "Epoch 48/100\n",
      "1600/1600 [==============================] - 3s 2ms/step - loss: 0.1466 - accuracy: 0.9435 - val_loss: 0.1516 - val_accuracy: 0.9430\n",
      "Epoch 49/100\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.1462 - accuracy: 0.9438 - val_loss: 0.1516 - val_accuracy: 0.9425\n",
      "Epoch 50/100\n",
      "1600/1600 [==============================] - 3s 2ms/step - loss: 0.1458 - accuracy: 0.9439 - val_loss: 0.1516 - val_accuracy: 0.9420\n",
      "Epoch 51/100\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.1453 - accuracy: 0.9438 - val_loss: 0.1516 - val_accuracy: 0.9425\n",
      "Epoch 52/100\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.1449 - accuracy: 0.9444 - val_loss: 0.1517 - val_accuracy: 0.9415\n",
      "Epoch 53/100\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.1445 - accuracy: 0.9444 - val_loss: 0.1518 - val_accuracy: 0.9410\n",
      "Epoch 54/100\n",
      "1600/1600 [==============================] - 3s 2ms/step - loss: 0.1440 - accuracy: 0.9441 - val_loss: 0.1520 - val_accuracy: 0.9405\n",
      "Epoch 55/100\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.1436 - accuracy: 0.9441 - val_loss: 0.1522 - val_accuracy: 0.9395\n",
      "Epoch 56/100\n",
      "1600/1600 [==============================] - 3s 2ms/step - loss: 0.1432 - accuracy: 0.9441 - val_loss: 0.1524 - val_accuracy: 0.9385\n",
      "Epoch 57/100\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.1428 - accuracy: 0.9441 - val_loss: 0.1526 - val_accuracy: 0.93801s - los - ETA: 0s - loss: 0.1438 - \n",
      "Epoch 58/100\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.1424 - accuracy: 0.9442 - val_loss: 0.1528 - val_accuracy: 0.9370\n",
      "Epoch 59/100\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.1420 - accuracy: 0.9442 - val_loss: 0.1531 - val_accuracy: 0.9385\n",
      "Epoch 60/100\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.1416 - accuracy: 0.9442 - val_loss: 0.1533 - val_accuracy: 0.9365\n",
      "Epoch 61/100\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.1413 - accuracy: 0.9449 - val_loss: 0.1536 - val_accuracy: 0.9365\n",
      "Epoch 62/100\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.1409 - accuracy: 0.9450 - val_loss: 0.1538 - val_accuracy: 0.9360\n",
      "Epoch 63/100\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.1406 - accuracy: 0.9454 - val_loss: 0.1541 - val_accuracy: 0.9360\n",
      "Epoch 64/100\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.1402 - accuracy: 0.9460 - val_loss: 0.1544 - val_accuracy: 0.9365\n",
      "Epoch 65/100\n",
      "1600/1600 [==============================] - 3s 2ms/step - loss: 0.1399 - accuracy: 0.9457 - val_loss: 0.1546 - val_accuracy: 0.9370\n",
      "Epoch 66/100\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.1396 - accuracy: 0.9463 - val_loss: 0.1548 - val_accuracy: 0.9370\n",
      "Epoch 67/100\n",
      "1600/1600 [==============================] - 3s 2ms/step - loss: 0.1393 - accuracy: 0.9466 - val_loss: 0.1551 - val_accuracy: 0.9375\n",
      "Epoch 68/100\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.1390 - accuracy: 0.9467 - val_loss: 0.1553 - val_accuracy: 0.9370\n",
      "Epoch 69/100\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.1387 - accuracy: 0.9470 - val_loss: 0.1555 - val_accuracy: 0.9360\n",
      "Epoch 70/100\n",
      "1600/1600 [==============================] - 3s 2ms/step - loss: 0.1384 - accuracy: 0.9475 - val_loss: 0.1557 - val_accuracy: 0.9360\n",
      "Epoch 71/100\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.1381 - accuracy: 0.9482 - val_loss: 0.1558 - val_accuracy: 0.9355\n",
      "Epoch 72/100\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.1378 - accuracy: 0.9485 - val_loss: 0.1560 - val_accuracy: 0.9355\n",
      "Epoch 73/100\n",
      "1600/1600 [==============================] - 2s 2ms/step - loss: 0.1376 - accuracy: 0.9488 - val_loss: 0.1561 - val_accuracy: 0.9360\n",
      "Epoch 74/100\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.1374 - accuracy: 0.9486 - val_loss: 0.1562 - val_accuracy: 0.9370oss: 0.1399 - accuracy\n",
      "Epoch 75/100\n",
      "1600/1600 [==============================] - 2s 2ms/step - loss: 0.1371 - accuracy: 0.9485 - val_loss: 0.1564 - val_accuracy: 0.9380\n",
      "Epoch 76/100\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.1369 - accuracy: 0.9488 - val_loss: 0.1564 - val_accuracy: 0.9375\n",
      "Epoch 77/100\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.1367 - accuracy: 0.9488 - val_loss: 0.1565 - val_accuracy: 0.9370\n",
      "Epoch 78/100\n",
      "1600/1600 [==============================] - 3s 2ms/step - loss: 0.1365 - accuracy: 0.9485 - val_loss: 0.1566 - val_accuracy: 0.9370\n",
      "Epoch 79/100\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.1363 - accuracy: 0.9488 - val_loss: 0.1567 - val_accuracy: 0.9370\n",
      "Epoch 80/100\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.1361 - accuracy: 0.9489 - val_loss: 0.1567 - val_accuracy: 0.9370\n",
      "Epoch 81/100\n",
      "1600/1600 [==============================] - 3s 2ms/step - loss: 0.1360 - accuracy: 0.9484 - val_loss: 0.1568 - val_accuracy: 0.9370\n",
      "Epoch 82/100\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.1358 - accuracy: 0.9481 - val_loss: 0.1569 - val_accuracy: 0.9365\n",
      "Epoch 83/100\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.1356 - accuracy: 0.9485 - val_loss: 0.1569 - val_accuracy: 0.9370\n",
      "Epoch 84/100\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.1355 - accuracy: 0.9490 - val_loss: 0.1570 - val_accuracy: 0.9370\n",
      "Epoch 85/100\n",
      "1600/1600 [==============================] - 2s 2ms/step - loss: 0.1353 - accuracy: 0.9485 - val_loss: 0.1570 - val_accuracy: 0.9370\n",
      "Epoch 86/100\n",
      "1600/1600 [==============================] - 3s 2ms/step - loss: 0.1352 - accuracy: 0.9486 - val_loss: 0.1571 - val_accuracy: 0.9375\n",
      "Epoch 87/100\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.1350 - accuracy: 0.9488 - val_loss: 0.1571 - val_accuracy: 0.9370\n",
      "Epoch 88/100\n",
      "1600/1600 [==============================] - 3s 2ms/step - loss: 0.1349 - accuracy: 0.9488 - val_loss: 0.1571 - val_accuracy: 0.9370\n",
      "Epoch 89/100\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.1348 - accuracy: 0.9490 - val_loss: 0.1572 - val_accuracy: 0.9370\n",
      "Epoch 90/100\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.1346 - accuracy: 0.9489 - val_loss: 0.1572 - val_accuracy: 0.9370\n",
      "Epoch 91/100\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.1345 - accuracy: 0.9491 - val_loss: 0.1573 - val_accuracy: 0.9370\n",
      "Epoch 92/100\n",
      "1600/1600 [==============================] - 2s 2ms/step - loss: 0.1344 - accuracy: 0.9496 - val_loss: 0.1573 - val_accuracy: 0.9365\n",
      "Epoch 93/100\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.1343 - accuracy: 0.9495 - val_loss: 0.1573 - val_accuracy: 0.9370\n",
      "Epoch 94/100\n",
      "1600/1600 [==============================] - 3s 2ms/step - loss: 0.1342 - accuracy: 0.9498 - val_loss: 0.1574 - val_accuracy: 0.9375\n",
      "Epoch 95/100\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.1340 - accuracy: 0.9499 - val_loss: 0.1574 - val_accuracy: 0.9375\n",
      "Epoch 96/100\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.1339 - accuracy: 0.9499 - val_loss: 0.1574 - val_accuracy: 0.9380\n",
      "Epoch 97/100\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.1338 - accuracy: 0.9499 - val_loss: 0.1574 - val_accuracy: 0.9380\n",
      "Epoch 98/100\n",
      "1600/1600 [==============================] - 2s 2ms/step - loss: 0.1337 - accuracy: 0.9500 - val_loss: 0.1574 - val_accuracy: 0.9385\n",
      "Epoch 99/100\n",
      "1600/1600 [==============================] - 3s 2ms/step - loss: 0.1336 - accuracy: 0.9501 - val_loss: 0.1574 - val_accuracy: 0.9385\n",
      "Epoch 100/100\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.1335 - accuracy: 0.9504 - val_loss: 0.1574 - val_accuracy: 0.9385\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X,y, epochs=100,batch_size=5,verbose=1,validation_split=0.2,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "486620d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc=\"upper left\")\n",
    "plt.show()\n",
    "\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc=\"upper left\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "20547e3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted proababilityfor each of the examples blonging to class 1: \n",
      "[[0.00305814]\n",
      " [0.6852765 ]\n",
      " [0.00348309]\n",
      " [0.9860264 ]\n",
      " [0.9792422 ]\n",
      " [0.00388524]\n",
      " [0.65761465]\n",
      " [0.00407234]\n",
      " [0.00466701]\n",
      " [0.995118  ]]\n",
      "Predicted class label for each of the examples: \n",
      "[[0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]]\n"
     ]
    }
   ],
   "source": [
    "y_predicted = model.predict(X.iloc[0:10,:])\n",
    "\n",
    "print('Predicted proababilityfor each of the examples blonging to class 1: ')\n",
    "print(y_predicted)\n",
    "\n",
    "print('Predicted class label for each of the examples: ')\n",
    "print(np.round(y_predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ff52063",
   "metadata": {},
   "source": [
    "## Activity 3.02: Advanced Fibrosis Diagnosis with Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b287a6ac",
   "metadata": {},
   "source": [
    "### Step 1: Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "29a1c978",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.read_csv('https://raw.githubusercontent.com/PacktWorkshops/The-Deep-Learning-with-Keras-Workshop/master/Chapter03/data/HCV_feats.csv')\n",
    "y = pd.read_csv('https://raw.githubusercontent.com/PacktWorkshops/The-Deep-Learning-with-Keras-Workshop/master/Chapter03/data/HCV_target.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39ef92c7",
   "metadata": {},
   "source": [
    "### Step 2: Print dataset shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "8c555ea5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "Number of examples:  1385 \n",
      " Number of features:  28 \n",
      " Possible classifications:  [0 1]\n"
     ]
    }
   ],
   "source": [
    "print(\" \\nNumber of examples: \",X.shape[0],\\\n",
    "    \"\\n Number of features: \",X.shape[1],\\\n",
    "    \"\\n Possible classifications: \", np.unique(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c693829a",
   "metadata": {},
   "source": [
    "### Step 3 Scale data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "5bc3f321",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.model_selection\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "434acfa2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = preprocessing.StandardScaler().fit(X)\n",
    "X_scaled = scaler.transform(X)\n",
    "X_scaled.mean(axis=0)\n",
    "X_scaled.std(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "f13b5725",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of examples in train:  1108\n",
      "Number of examples in test:  277\n"
     ]
    }
   ],
   "source": [
    "train, test = sklearn.model_selection.train_test_split(X_scaled, train_size=0.8, test_size=0.2, \n",
    "                                         shuffle=True, stratify=None)\n",
    "print(\"Number of examples in train: \",len(train))\n",
    "print(\"Number of examples in test: \", len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "0b24fe15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_16 (Dense)            (None, 3)                 87        \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 1)                 4         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 91\n",
      "Trainable params: 91\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "random.set_seed(42)\n",
    "classifier = Sequential()\n",
    "\n",
    "classifier.add(Dense(units=3, activation='tanh', input_dim=X_scaled.shape[1]))\n",
    "classifier.add(Dense(units=1, activation='sigmoid'))\n",
    "classifier.compile(optimizer='sgd', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "classifier.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "ae0a07a3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7857 - accuracy: 0.4920 - val_loss: 0.8507 - val_accuracy: 0.3957\n",
      "Epoch 2/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.7555 - accuracy: 0.4920 - val_loss: 0.8112 - val_accuracy: 0.3957\n",
      "Epoch 3/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.7375 - accuracy: 0.4920 - val_loss: 0.7845 - val_accuracy: 0.3957\n",
      "Epoch 4/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.7263 - accuracy: 0.4920 - val_loss: 0.7655 - val_accuracy: 0.3957\n",
      "Epoch 5/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.7187 - accuracy: 0.4848 - val_loss: 0.7514 - val_accuracy: 0.4892\n",
      "Epoch 6/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.7133 - accuracy: 0.4976 - val_loss: 0.7406 - val_accuracy: 0.4892\n",
      "Epoch 7/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.7092 - accuracy: 0.4976 - val_loss: 0.7320 - val_accuracy: 0.4892\n",
      "Epoch 8/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.7061 - accuracy: 0.4896 - val_loss: 0.7251 - val_accuracy: 0.4892\n",
      "Epoch 9/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.7036 - accuracy: 0.4880 - val_loss: 0.7194 - val_accuracy: 0.4892\n",
      "Epoch 10/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.7016 - accuracy: 0.4912 - val_loss: 0.7147 - val_accuracy: 0.4892\n",
      "Epoch 11/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.7000 - accuracy: 0.4928 - val_loss: 0.7108 - val_accuracy: 0.4892\n",
      "Epoch 12/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6986 - accuracy: 0.4872 - val_loss: 0.7074 - val_accuracy: 0.4892\n",
      "Epoch 13/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6976 - accuracy: 0.4848 - val_loss: 0.7046 - val_accuracy: 0.4892\n",
      "Epoch 14/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6967 - accuracy: 0.4864 - val_loss: 0.7022 - val_accuracy: 0.4892\n",
      "Epoch 15/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6960 - accuracy: 0.4920 - val_loss: 0.7001 - val_accuracy: 0.4892\n",
      "Epoch 16/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6954 - accuracy: 0.4976 - val_loss: 0.6982 - val_accuracy: 0.4892\n",
      "Epoch 17/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6950 - accuracy: 0.4976 - val_loss: 0.6967 - val_accuracy: 0.4892\n",
      "Epoch 18/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6946 - accuracy: 0.4976 - val_loss: 0.6953 - val_accuracy: 0.4892\n",
      "Epoch 19/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6943 - accuracy: 0.4976 - val_loss: 0.6941 - val_accuracy: 0.4892\n",
      "Epoch 20/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6940 - accuracy: 0.4976 - val_loss: 0.6930 - val_accuracy: 0.4892\n",
      "Epoch 21/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6938 - accuracy: 0.4952 - val_loss: 0.6921 - val_accuracy: 0.5827\n",
      "Epoch 22/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6936 - accuracy: 0.5072 - val_loss: 0.6913 - val_accuracy: 0.5827\n",
      "Epoch 23/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6935 - accuracy: 0.5072 - val_loss: 0.6906 - val_accuracy: 0.5827\n",
      "Epoch 24/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6934 - accuracy: 0.5072 - val_loss: 0.6899 - val_accuracy: 0.5827\n",
      "Epoch 25/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6933 - accuracy: 0.5072 - val_loss: 0.6894 - val_accuracy: 0.5827\n",
      "Epoch 26/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5072 - val_loss: 0.6889 - val_accuracy: 0.5827\n",
      "Epoch 27/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5024 - val_loss: 0.6884 - val_accuracy: 0.5827\n",
      "Epoch 28/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5128 - val_loss: 0.6880 - val_accuracy: 0.6115\n",
      "Epoch 29/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5112 - val_loss: 0.6877 - val_accuracy: 0.6115\n",
      "Epoch 30/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6930 - accuracy: 0.5128 - val_loss: 0.6873 - val_accuracy: 0.6115\n",
      "Epoch 31/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6930 - accuracy: 0.5128 - val_loss: 0.6871 - val_accuracy: 0.6115\n",
      "Epoch 32/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6930 - accuracy: 0.5128 - val_loss: 0.6868 - val_accuracy: 0.6115\n",
      "Epoch 33/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6930 - accuracy: 0.5128 - val_loss: 0.6866 - val_accuracy: 0.6115\n",
      "Epoch 34/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6930 - accuracy: 0.5128 - val_loss: 0.6864 - val_accuracy: 0.6115\n",
      "Epoch 35/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6930 - accuracy: 0.5128 - val_loss: 0.6862 - val_accuracy: 0.6115\n",
      "Epoch 36/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6930 - accuracy: 0.5128 - val_loss: 0.6860 - val_accuracy: 0.6115\n",
      "Epoch 37/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6929 - accuracy: 0.5128 - val_loss: 0.6859 - val_accuracy: 0.6115\n",
      "Epoch 38/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6929 - accuracy: 0.5128 - val_loss: 0.6857 - val_accuracy: 0.6115\n",
      "Epoch 39/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6929 - accuracy: 0.5128 - val_loss: 0.6856 - val_accuracy: 0.6115\n",
      "Epoch 40/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6929 - accuracy: 0.5128 - val_loss: 0.6855 - val_accuracy: 0.6115\n",
      "Epoch 41/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6929 - accuracy: 0.5128 - val_loss: 0.6854 - val_accuracy: 0.6115\n",
      "Epoch 42/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6929 - accuracy: 0.5128 - val_loss: 0.6853 - val_accuracy: 0.6115\n",
      "Epoch 43/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6929 - accuracy: 0.5128 - val_loss: 0.6852 - val_accuracy: 0.6115\n",
      "Epoch 44/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6929 - accuracy: 0.5128 - val_loss: 0.6852 - val_accuracy: 0.6115\n",
      "Epoch 45/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6929 - accuracy: 0.5128 - val_loss: 0.6851 - val_accuracy: 0.6115\n",
      "Epoch 46/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6929 - accuracy: 0.5128 - val_loss: 0.6851 - val_accuracy: 0.6115\n",
      "Epoch 47/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6929 - accuracy: 0.5128 - val_loss: 0.6850 - val_accuracy: 0.6115\n",
      "Epoch 48/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6929 - accuracy: 0.5128 - val_loss: 0.6850 - val_accuracy: 0.6115\n",
      "Epoch 49/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6929 - accuracy: 0.5128 - val_loss: 0.6849 - val_accuracy: 0.6115\n",
      "Epoch 50/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6929 - accuracy: 0.5128 - val_loss: 0.6849 - val_accuracy: 0.6115\n",
      "Epoch 51/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6929 - accuracy: 0.5128 - val_loss: 0.6848 - val_accuracy: 0.6115\n",
      "Epoch 52/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6929 - accuracy: 0.5128 - val_loss: 0.6848 - val_accuracy: 0.6115\n",
      "Epoch 53/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6929 - accuracy: 0.5128 - val_loss: 0.6848 - val_accuracy: 0.6115\n",
      "Epoch 54/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6929 - accuracy: 0.5128 - val_loss: 0.6847 - val_accuracy: 0.6115\n",
      "Epoch 55/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6929 - accuracy: 0.5128 - val_loss: 0.6847 - val_accuracy: 0.6115\n",
      "Epoch 56/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6929 - accuracy: 0.5128 - val_loss: 0.6847 - val_accuracy: 0.6115\n",
      "Epoch 57/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6929 - accuracy: 0.5128 - val_loss: 0.6847 - val_accuracy: 0.6115\n",
      "Epoch 58/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6929 - accuracy: 0.5128 - val_loss: 0.6847 - val_accuracy: 0.6115\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6929 - accuracy: 0.5128 - val_loss: 0.6847 - val_accuracy: 0.6115\n",
      "Epoch 60/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6929 - accuracy: 0.5128 - val_loss: 0.6846 - val_accuracy: 0.6115\n",
      "Epoch 61/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6929 - accuracy: 0.5128 - val_loss: 0.6846 - val_accuracy: 0.6115\n",
      "Epoch 62/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6929 - accuracy: 0.5128 - val_loss: 0.6846 - val_accuracy: 0.6115\n",
      "Epoch 63/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6929 - accuracy: 0.5128 - val_loss: 0.6846 - val_accuracy: 0.6115\n",
      "Epoch 64/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6929 - accuracy: 0.5128 - val_loss: 0.6846 - val_accuracy: 0.6115\n",
      "Epoch 65/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6929 - accuracy: 0.5128 - val_loss: 0.6846 - val_accuracy: 0.6115\n",
      "Epoch 66/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6929 - accuracy: 0.5128 - val_loss: 0.6846 - val_accuracy: 0.6115\n",
      "Epoch 67/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6929 - accuracy: 0.5128 - val_loss: 0.6846 - val_accuracy: 0.6115\n",
      "Epoch 68/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6929 - accuracy: 0.5128 - val_loss: 0.6846 - val_accuracy: 0.6115\n",
      "Epoch 69/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6929 - accuracy: 0.5128 - val_loss: 0.6846 - val_accuracy: 0.6115\n",
      "Epoch 70/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6929 - accuracy: 0.5128 - val_loss: 0.6846 - val_accuracy: 0.6115\n",
      "Epoch 71/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6929 - accuracy: 0.5128 - val_loss: 0.6845 - val_accuracy: 0.6115\n",
      "Epoch 72/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6929 - accuracy: 0.5128 - val_loss: 0.6845 - val_accuracy: 0.6115\n",
      "Epoch 73/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6929 - accuracy: 0.5128 - val_loss: 0.6845 - val_accuracy: 0.6115\n",
      "Epoch 74/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6929 - accuracy: 0.5128 - val_loss: 0.6845 - val_accuracy: 0.6115\n",
      "Epoch 75/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6929 - accuracy: 0.5128 - val_loss: 0.6845 - val_accuracy: 0.6115\n",
      "Epoch 76/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6929 - accuracy: 0.5128 - val_loss: 0.6845 - val_accuracy: 0.6115\n",
      "Epoch 77/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6929 - accuracy: 0.5128 - val_loss: 0.6845 - val_accuracy: 0.6115\n",
      "Epoch 78/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6929 - accuracy: 0.5128 - val_loss: 0.6845 - val_accuracy: 0.6115\n",
      "Epoch 79/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6929 - accuracy: 0.5128 - val_loss: 0.6845 - val_accuracy: 0.6115\n",
      "Epoch 80/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6929 - accuracy: 0.5128 - val_loss: 0.6845 - val_accuracy: 0.6115\n",
      "Epoch 81/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6929 - accuracy: 0.5128 - val_loss: 0.6845 - val_accuracy: 0.6115\n",
      "Epoch 82/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6929 - accuracy: 0.5128 - val_loss: 0.6845 - val_accuracy: 0.6115\n",
      "Epoch 83/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6929 - accuracy: 0.5128 - val_loss: 0.6845 - val_accuracy: 0.6115\n",
      "Epoch 84/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6929 - accuracy: 0.5128 - val_loss: 0.6845 - val_accuracy: 0.6115\n",
      "Epoch 85/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6929 - accuracy: 0.5128 - val_loss: 0.6845 - val_accuracy: 0.6115\n",
      "Epoch 86/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6929 - accuracy: 0.5128 - val_loss: 0.6845 - val_accuracy: 0.6115\n",
      "Epoch 87/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6929 - accuracy: 0.5128 - val_loss: 0.6845 - val_accuracy: 0.6115\n",
      "Epoch 88/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6929 - accuracy: 0.5128 - val_loss: 0.6845 - val_accuracy: 0.6115\n",
      "Epoch 89/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6929 - accuracy: 0.5128 - val_loss: 0.6845 - val_accuracy: 0.6115\n",
      "Epoch 90/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6929 - accuracy: 0.5128 - val_loss: 0.6845 - val_accuracy: 0.6115\n",
      "Epoch 91/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6929 - accuracy: 0.5128 - val_loss: 0.6845 - val_accuracy: 0.6115\n",
      "Epoch 92/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6929 - accuracy: 0.5128 - val_loss: 0.6845 - val_accuracy: 0.6115\n",
      "Epoch 93/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6929 - accuracy: 0.5128 - val_loss: 0.6845 - val_accuracy: 0.6115\n",
      "Epoch 94/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6929 - accuracy: 0.5128 - val_loss: 0.6845 - val_accuracy: 0.6115\n",
      "Epoch 95/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6929 - accuracy: 0.5128 - val_loss: 0.6845 - val_accuracy: 0.6115\n",
      "Epoch 96/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6929 - accuracy: 0.5128 - val_loss: 0.6845 - val_accuracy: 0.6115\n",
      "Epoch 97/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6929 - accuracy: 0.5128 - val_loss: 0.6845 - val_accuracy: 0.6115\n",
      "Epoch 98/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6929 - accuracy: 0.5128 - val_loss: 0.6845 - val_accuracy: 0.6115\n",
      "Epoch 99/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6929 - accuracy: 0.5128 - val_loss: 0.6845 - val_accuracy: 0.6115\n",
      "Epoch 100/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6929 - accuracy: 0.5128 - val_loss: 0.6845 - val_accuracy: 0.6115\n"
     ]
    }
   ],
   "source": [
    "history = classifier.fit(X,y, epochs=100,batch_size=20,verbose=1,validation_split=0.1,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "5e0c2177",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6115108132362366"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(history.history['val_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "0ed04854",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc=\"upper left\")\n",
    "plt.show()\n",
    "\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc=\"upper left\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "df6089ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_18 (Dense)            (None, 4)                 116       \n",
      "                                                                 \n",
      " dense_19 (Dense)            (None, 2)                 10        \n",
      "                                                                 \n",
      " dense_20 (Dense)            (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 129\n",
      "Trainable params: 129\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "random.set_seed(42)\n",
    "classifier = Sequential()\n",
    "\n",
    "classifier.add(Dense(units=10, activation='tanh', input_dim=X_scaled.shape[1]))\n",
    "classifier.add(Dense(units=4, activation='tanh'))\n",
    "classifier.add(Dense(units=2, activation='tanh'))\n",
    "classifier.add(Dense(units=1, activation='sigmoid'))\n",
    "classifier.compile(optimizer='sgd', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "classifier.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "4c92827b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6933 - accuracy: 0.5080 - val_loss: 0.6905 - val_accuracy: 0.5827\n",
      "Epoch 2/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6933 - accuracy: 0.5080 - val_loss: 0.6905 - val_accuracy: 0.5827\n",
      "Epoch 3/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6933 - accuracy: 0.5080 - val_loss: 0.6905 - val_accuracy: 0.5827\n",
      "Epoch 4/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6933 - accuracy: 0.5080 - val_loss: 0.6905 - val_accuracy: 0.5827\n",
      "Epoch 5/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6933 - accuracy: 0.5080 - val_loss: 0.6905 - val_accuracy: 0.5827\n",
      "Epoch 6/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6933 - accuracy: 0.5080 - val_loss: 0.6905 - val_accuracy: 0.5827\n",
      "Epoch 7/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6933 - accuracy: 0.5080 - val_loss: 0.6905 - val_accuracy: 0.5827\n",
      "Epoch 8/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6932 - accuracy: 0.5080 - val_loss: 0.6905 - val_accuracy: 0.5827\n",
      "Epoch 9/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5080 - val_loss: 0.6904 - val_accuracy: 0.5827\n",
      "Epoch 10/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5080 - val_loss: 0.6904 - val_accuracy: 0.5827\n",
      "Epoch 11/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5080 - val_loss: 0.6904 - val_accuracy: 0.5827\n",
      "Epoch 12/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6932 - accuracy: 0.5080 - val_loss: 0.6904 - val_accuracy: 0.5827\n",
      "Epoch 13/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6932 - accuracy: 0.5080 - val_loss: 0.6904 - val_accuracy: 0.5827\n",
      "Epoch 14/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5080 - val_loss: 0.6904 - val_accuracy: 0.5827\n",
      "Epoch 15/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5080 - val_loss: 0.6904 - val_accuracy: 0.5827\n",
      "Epoch 16/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5080 - val_loss: 0.6904 - val_accuracy: 0.5827\n",
      "Epoch 17/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5080 - val_loss: 0.6904 - val_accuracy: 0.5827\n",
      "Epoch 18/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5080 - val_loss: 0.6904 - val_accuracy: 0.5827\n",
      "Epoch 19/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5080 - val_loss: 0.6904 - val_accuracy: 0.5827\n",
      "Epoch 20/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5080 - val_loss: 0.6904 - val_accuracy: 0.5827\n",
      "Epoch 21/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5080 - val_loss: 0.6904 - val_accuracy: 0.5827\n",
      "Epoch 22/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5080 - val_loss: 0.6904 - val_accuracy: 0.5827\n",
      "Epoch 23/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5080 - val_loss: 0.6904 - val_accuracy: 0.5827\n",
      "Epoch 24/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5080 - val_loss: 0.6904 - val_accuracy: 0.5827\n",
      "Epoch 25/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5080 - val_loss: 0.6904 - val_accuracy: 0.5827\n",
      "Epoch 26/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5080 - val_loss: 0.6904 - val_accuracy: 0.5827\n",
      "Epoch 27/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5080 - val_loss: 0.6904 - val_accuracy: 0.5827\n",
      "Epoch 28/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5080 - val_loss: 0.6904 - val_accuracy: 0.5827\n",
      "Epoch 29/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5080 - val_loss: 0.6904 - val_accuracy: 0.5827\n",
      "Epoch 30/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5080 - val_loss: 0.6904 - val_accuracy: 0.5827\n",
      "Epoch 31/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5080 - val_loss: 0.6904 - val_accuracy: 0.5827\n",
      "Epoch 32/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5080 - val_loss: 0.6904 - val_accuracy: 0.5827\n",
      "Epoch 33/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5080 - val_loss: 0.6904 - val_accuracy: 0.5827\n",
      "Epoch 34/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5080 - val_loss: 0.6904 - val_accuracy: 0.5827\n",
      "Epoch 35/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5080 - val_loss: 0.6904 - val_accuracy: 0.5827\n",
      "Epoch 36/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5080 - val_loss: 0.6904 - val_accuracy: 0.5827\n",
      "Epoch 37/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5080 - val_loss: 0.6904 - val_accuracy: 0.5827\n",
      "Epoch 38/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5080 - val_loss: 0.6904 - val_accuracy: 0.5827\n",
      "Epoch 39/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5080 - val_loss: 0.6904 - val_accuracy: 0.5827\n",
      "Epoch 40/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5080 - val_loss: 0.6904 - val_accuracy: 0.5827\n",
      "Epoch 41/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5072 - val_loss: 0.6904 - val_accuracy: 0.5827\n",
      "Epoch 42/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5072 - val_loss: 0.6904 - val_accuracy: 0.5827\n",
      "Epoch 43/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5088 - val_loss: 0.6904 - val_accuracy: 0.5827\n",
      "Epoch 44/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5088 - val_loss: 0.6904 - val_accuracy: 0.5827\n",
      "Epoch 45/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5064 - val_loss: 0.6904 - val_accuracy: 0.5827\n",
      "Epoch 46/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5064 - val_loss: 0.6904 - val_accuracy: 0.5827\n",
      "Epoch 47/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5040 - val_loss: 0.6904 - val_accuracy: 0.5827\n",
      "Epoch 48/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5080 - val_loss: 0.6904 - val_accuracy: 0.5827\n",
      "Epoch 49/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5096 - val_loss: 0.6904 - val_accuracy: 0.5827\n",
      "Epoch 50/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5088 - val_loss: 0.6904 - val_accuracy: 0.5827\n",
      "Epoch 51/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5080 - val_loss: 0.6904 - val_accuracy: 0.5827\n",
      "Epoch 52/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5096 - val_loss: 0.6904 - val_accuracy: 0.5827\n",
      "Epoch 53/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5088 - val_loss: 0.6904 - val_accuracy: 0.5827\n",
      "Epoch 54/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5048 - val_loss: 0.6904 - val_accuracy: 0.5827\n",
      "Epoch 55/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5064 - val_loss: 0.6904 - val_accuracy: 0.5827\n",
      "Epoch 56/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5056 - val_loss: 0.6904 - val_accuracy: 0.5827\n",
      "Epoch 57/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5064 - val_loss: 0.6904 - val_accuracy: 0.5827\n",
      "Epoch 58/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5048 - val_loss: 0.6904 - val_accuracy: 0.5827\n",
      "Epoch 59/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5072 - val_loss: 0.6904 - val_accuracy: 0.5827\n",
      "Epoch 60/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5072 - val_loss: 0.6904 - val_accuracy: 0.5827\n",
      "Epoch 61/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5072 - val_loss: 0.6904 - val_accuracy: 0.5827\n",
      "Epoch 62/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5104 - val_loss: 0.6904 - val_accuracy: 0.6043\n",
      "Epoch 63/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5080 - val_loss: 0.6904 - val_accuracy: 0.6043\n",
      "Epoch 64/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5088 - val_loss: 0.6904 - val_accuracy: 0.6043\n",
      "Epoch 65/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5088 - val_loss: 0.6904 - val_accuracy: 0.6043\n",
      "Epoch 66/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5088 - val_loss: 0.6904 - val_accuracy: 0.6043\n",
      "Epoch 67/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5080 - val_loss: 0.6904 - val_accuracy: 0.6043\n",
      "Epoch 68/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5080 - val_loss: 0.6904 - val_accuracy: 0.6043\n",
      "Epoch 69/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5080 - val_loss: 0.6904 - val_accuracy: 0.6043\n",
      "Epoch 70/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6932 - accuracy: 0.5096 - val_loss: 0.6904 - val_accuracy: 0.6043\n",
      "Epoch 71/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6932 - accuracy: 0.5104 - val_loss: 0.6904 - val_accuracy: 0.6043\n",
      "Epoch 72/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6932 - accuracy: 0.5112 - val_loss: 0.6904 - val_accuracy: 0.6043\n",
      "Epoch 73/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5104 - val_loss: 0.6904 - val_accuracy: 0.6043\n",
      "Epoch 74/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5104 - val_loss: 0.6904 - val_accuracy: 0.6043\n",
      "Epoch 75/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5088 - val_loss: 0.6904 - val_accuracy: 0.6043\n",
      "Epoch 76/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5088 - val_loss: 0.6904 - val_accuracy: 0.6043\n",
      "Epoch 77/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5088 - val_loss: 0.6904 - val_accuracy: 0.6043\n",
      "Epoch 78/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5088 - val_loss: 0.6904 - val_accuracy: 0.6043\n",
      "Epoch 79/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5088 - val_loss: 0.6904 - val_accuracy: 0.6043\n",
      "Epoch 80/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5088 - val_loss: 0.6904 - val_accuracy: 0.6043\n",
      "Epoch 81/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5064 - val_loss: 0.6904 - val_accuracy: 0.6043\n",
      "Epoch 82/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5064 - val_loss: 0.6904 - val_accuracy: 0.6043\n",
      "Epoch 83/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5064 - val_loss: 0.6904 - val_accuracy: 0.6043\n",
      "Epoch 84/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5064 - val_loss: 0.6904 - val_accuracy: 0.6043\n",
      "Epoch 85/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5064 - val_loss: 0.6904 - val_accuracy: 0.6043\n",
      "Epoch 86/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5064 - val_loss: 0.6904 - val_accuracy: 0.6043\n",
      "Epoch 87/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5080 - val_loss: 0.6904 - val_accuracy: 0.6043\n",
      "Epoch 88/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5080 - val_loss: 0.6904 - val_accuracy: 0.6043\n",
      "Epoch 89/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5080 - val_loss: 0.6904 - val_accuracy: 0.6043\n",
      "Epoch 90/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5080 - val_loss: 0.6904 - val_accuracy: 0.6043\n",
      "Epoch 91/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5080 - val_loss: 0.6904 - val_accuracy: 0.6043\n",
      "Epoch 92/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5080 - val_loss: 0.6904 - val_accuracy: 0.6043\n",
      "Epoch 93/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5080 - val_loss: 0.6904 - val_accuracy: 0.6043\n",
      "Epoch 94/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5080 - val_loss: 0.6904 - val_accuracy: 0.6043\n",
      "Epoch 95/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5080 - val_loss: 0.6904 - val_accuracy: 0.6043\n",
      "Epoch 96/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5080 - val_loss: 0.6904 - val_accuracy: 0.6043\n",
      "Epoch 97/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5080 - val_loss: 0.6904 - val_accuracy: 0.6043\n",
      "Epoch 98/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5080 - val_loss: 0.6904 - val_accuracy: 0.6043\n",
      "Epoch 99/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5080 - val_loss: 0.6904 - val_accuracy: 0.6043\n",
      "Epoch 100/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5080 - val_loss: 0.6904 - val_accuracy: 0.6043\n",
      "Epoch 101/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6932 - accuracy: 0.5080 - val_loss: 0.6904 - val_accuracy: 0.6043\n",
      "Epoch 102/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6932 - accuracy: 0.5080 - val_loss: 0.6904 - val_accuracy: 0.6043\n",
      "Epoch 103/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6932 - accuracy: 0.5080 - val_loss: 0.6904 - val_accuracy: 0.6043\n",
      "Epoch 104/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6932 - accuracy: 0.5080 - val_loss: 0.6904 - val_accuracy: 0.6043\n",
      "Epoch 105/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6932 - accuracy: 0.5080 - val_loss: 0.6904 - val_accuracy: 0.6043\n",
      "Epoch 106/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6932 - accuracy: 0.5080 - val_loss: 0.6904 - val_accuracy: 0.6043\n",
      "Epoch 107/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6932 - accuracy: 0.5080 - val_loss: 0.6904 - val_accuracy: 0.6043\n",
      "Epoch 108/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6932 - accuracy: 0.5080 - val_loss: 0.6904 - val_accuracy: 0.6043\n",
      "Epoch 109/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6932 - accuracy: 0.5080 - val_loss: 0.6904 - val_accuracy: 0.6043\n",
      "Epoch 110/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5080 - val_loss: 0.6904 - val_accuracy: 0.6043\n",
      "Epoch 111/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5080 - val_loss: 0.6904 - val_accuracy: 0.6043\n",
      "Epoch 112/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5080 - val_loss: 0.6905 - val_accuracy: 0.6043\n",
      "Epoch 113/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5080 - val_loss: 0.6905 - val_accuracy: 0.6043\n",
      "Epoch 114/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5080 - val_loss: 0.6905 - val_accuracy: 0.6043\n",
      "Epoch 115/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5080 - val_loss: 0.6905 - val_accuracy: 0.6043\n",
      "Epoch 116/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5080 - val_loss: 0.6905 - val_accuracy: 0.6043\n",
      "Epoch 117/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5080 - val_loss: 0.6905 - val_accuracy: 0.6043\n",
      "Epoch 118/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5080 - val_loss: 0.6905 - val_accuracy: 0.6043\n",
      "Epoch 119/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5080 - val_loss: 0.6905 - val_accuracy: 0.6043\n",
      "Epoch 120/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5080 - val_loss: 0.6905 - val_accuracy: 0.6043\n",
      "Epoch 121/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6932 - accuracy: 0.5080 - val_loss: 0.6905 - val_accuracy: 0.6043\n",
      "Epoch 122/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6932 - accuracy: 0.5080 - val_loss: 0.6905 - val_accuracy: 0.6043\n",
      "Epoch 123/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6932 - accuracy: 0.5080 - val_loss: 0.6905 - val_accuracy: 0.6043\n",
      "Epoch 124/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5080 - val_loss: 0.6905 - val_accuracy: 0.6043\n",
      "Epoch 125/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5080 - val_loss: 0.6905 - val_accuracy: 0.6043\n",
      "Epoch 126/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6932 - accuracy: 0.5080 - val_loss: 0.6905 - val_accuracy: 0.6043\n",
      "Epoch 127/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6932 - accuracy: 0.5080 - val_loss: 0.6905 - val_accuracy: 0.6043\n",
      "Epoch 128/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6932 - accuracy: 0.5080 - val_loss: 0.6905 - val_accuracy: 0.6043\n",
      "Epoch 129/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6932 - accuracy: 0.5080 - val_loss: 0.6905 - val_accuracy: 0.6043\n",
      "Epoch 130/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6932 - accuracy: 0.5080 - val_loss: 0.6905 - val_accuracy: 0.6043\n",
      "Epoch 131/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6932 - accuracy: 0.5080 - val_loss: 0.6905 - val_accuracy: 0.6043\n",
      "Epoch 132/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6932 - accuracy: 0.5080 - val_loss: 0.6905 - val_accuracy: 0.6043\n",
      "Epoch 133/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6932 - accuracy: 0.5080 - val_loss: 0.6905 - val_accuracy: 0.6043\n",
      "Epoch 134/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6932 - accuracy: 0.5080 - val_loss: 0.6905 - val_accuracy: 0.6043\n",
      "Epoch 135/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5080 - val_loss: 0.6905 - val_accuracy: 0.6043\n",
      "Epoch 136/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5080 - val_loss: 0.6905 - val_accuracy: 0.6043\n",
      "Epoch 137/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6932 - accuracy: 0.5080 - val_loss: 0.6905 - val_accuracy: 0.6043\n",
      "Epoch 138/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5080 - val_loss: 0.6905 - val_accuracy: 0.6043\n",
      "Epoch 139/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5080 - val_loss: 0.6905 - val_accuracy: 0.6043\n",
      "Epoch 140/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5080 - val_loss: 0.6905 - val_accuracy: 0.6043\n",
      "Epoch 141/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5080 - val_loss: 0.6905 - val_accuracy: 0.6043\n",
      "Epoch 142/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5080 - val_loss: 0.6905 - val_accuracy: 0.6043\n",
      "Epoch 143/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5080 - val_loss: 0.6905 - val_accuracy: 0.6043\n",
      "Epoch 144/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5080 - val_loss: 0.6905 - val_accuracy: 0.6043\n",
      "Epoch 145/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5080 - val_loss: 0.6905 - val_accuracy: 0.6043\n",
      "Epoch 146/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5080 - val_loss: 0.6905 - val_accuracy: 0.6043\n",
      "Epoch 147/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5080 - val_loss: 0.6905 - val_accuracy: 0.6043\n",
      "Epoch 148/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5080 - val_loss: 0.6905 - val_accuracy: 0.6043\n",
      "Epoch 149/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5080 - val_loss: 0.6905 - val_accuracy: 0.6043\n",
      "Epoch 150/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5080 - val_loss: 0.6905 - val_accuracy: 0.6043\n",
      "Epoch 151/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5080 - val_loss: 0.6905 - val_accuracy: 0.6043\n",
      "Epoch 152/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5080 - val_loss: 0.6905 - val_accuracy: 0.6043\n",
      "Epoch 153/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5080 - val_loss: 0.6905 - val_accuracy: 0.6043\n",
      "Epoch 154/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5080 - val_loss: 0.6905 - val_accuracy: 0.6043\n",
      "Epoch 155/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5080 - val_loss: 0.6905 - val_accuracy: 0.6043\n",
      "Epoch 156/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5080 - val_loss: 0.6905 - val_accuracy: 0.6043\n",
      "Epoch 157/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5080 - val_loss: 0.6905 - val_accuracy: 0.6043\n",
      "Epoch 158/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5080 - val_loss: 0.6906 - val_accuracy: 0.6043\n",
      "Epoch 159/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5080 - val_loss: 0.6906 - val_accuracy: 0.6043\n",
      "Epoch 160/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5080 - val_loss: 0.6906 - val_accuracy: 0.6043\n",
      "Epoch 161/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5080 - val_loss: 0.6906 - val_accuracy: 0.6043\n",
      "Epoch 162/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5080 - val_loss: 0.6906 - val_accuracy: 0.6043\n",
      "Epoch 163/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5080 - val_loss: 0.6906 - val_accuracy: 0.6043\n",
      "Epoch 164/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5080 - val_loss: 0.6906 - val_accuracy: 0.6043\n",
      "Epoch 165/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5080 - val_loss: 0.6906 - val_accuracy: 0.6043\n",
      "Epoch 166/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5080 - val_loss: 0.6906 - val_accuracy: 0.6043\n",
      "Epoch 167/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5080 - val_loss: 0.6906 - val_accuracy: 0.6043\n",
      "Epoch 168/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5080 - val_loss: 0.6906 - val_accuracy: 0.6043\n",
      "Epoch 169/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6932 - accuracy: 0.5080 - val_loss: 0.6906 - val_accuracy: 0.6043\n",
      "Epoch 170/1000\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.6932 - accuracy: 0.5080 - val_loss: 0.6906 - val_accuracy: 0.6043\n",
      "Epoch 171/1000\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.6932 - accuracy: 0.5080 - val_loss: 0.6906 - val_accuracy: 0.6043\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 172/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6932 - accuracy: 0.5080 - val_loss: 0.6906 - val_accuracy: 0.6043\n",
      "Epoch 173/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6932 - accuracy: 0.5080 - val_loss: 0.6906 - val_accuracy: 0.6043\n",
      "Epoch 174/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6932 - accuracy: 0.5080 - val_loss: 0.6906 - val_accuracy: 0.6043\n",
      "Epoch 175/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6932 - accuracy: 0.5080 - val_loss: 0.6906 - val_accuracy: 0.6043\n",
      "Epoch 176/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6932 - accuracy: 0.5080 - val_loss: 0.6906 - val_accuracy: 0.6043\n",
      "Epoch 177/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6932 - accuracy: 0.5080 - val_loss: 0.6906 - val_accuracy: 0.6043\n",
      "Epoch 178/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5080 - val_loss: 0.6906 - val_accuracy: 0.6043\n",
      "Epoch 179/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5080 - val_loss: 0.6906 - val_accuracy: 0.6043\n",
      "Epoch 180/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5080 - val_loss: 0.6906 - val_accuracy: 0.6043\n",
      "Epoch 181/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5080 - val_loss: 0.6906 - val_accuracy: 0.6043\n",
      "Epoch 182/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5080 - val_loss: 0.6906 - val_accuracy: 0.6043\n",
      "Epoch 183/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5080 - val_loss: 0.6906 - val_accuracy: 0.6043\n",
      "Epoch 184/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5080 - val_loss: 0.6906 - val_accuracy: 0.6043\n",
      "Epoch 185/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5080 - val_loss: 0.6906 - val_accuracy: 0.6043\n",
      "Epoch 186/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5080 - val_loss: 0.6906 - val_accuracy: 0.6043\n",
      "Epoch 187/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5080 - val_loss: 0.6906 - val_accuracy: 0.6043\n",
      "Epoch 188/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5080 - val_loss: 0.6906 - val_accuracy: 0.6043\n",
      "Epoch 189/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5080 - val_loss: 0.6906 - val_accuracy: 0.6043\n",
      "Epoch 190/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5080 - val_loss: 0.6906 - val_accuracy: 0.6043\n",
      "Epoch 191/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5080 - val_loss: 0.6906 - val_accuracy: 0.6043\n",
      "Epoch 192/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5080 - val_loss: 0.6906 - val_accuracy: 0.6043\n",
      "Epoch 193/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5080 - val_loss: 0.6906 - val_accuracy: 0.5971\n",
      "Epoch 194/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6932 - accuracy: 0.5080 - val_loss: 0.6906 - val_accuracy: 0.5971\n",
      "Epoch 195/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6906 - val_accuracy: 0.5971\n",
      "Epoch 196/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6906 - val_accuracy: 0.5971\n",
      "Epoch 197/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6906 - val_accuracy: 0.5971\n",
      "Epoch 198/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6906 - val_accuracy: 0.5971\n",
      "Epoch 199/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6906 - val_accuracy: 0.5971\n",
      "Epoch 200/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6906 - val_accuracy: 0.5971\n",
      "Epoch 201/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6906 - val_accuracy: 0.5971\n",
      "Epoch 202/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6906 - val_accuracy: 0.5971\n",
      "Epoch 203/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6907 - val_accuracy: 0.5971\n",
      "Epoch 204/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6907 - val_accuracy: 0.5971\n",
      "Epoch 205/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6907 - val_accuracy: 0.5971\n",
      "Epoch 206/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6907 - val_accuracy: 0.5971\n",
      "Epoch 207/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6907 - val_accuracy: 0.5971\n",
      "Epoch 208/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6907 - val_accuracy: 0.5971\n",
      "Epoch 209/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6907 - val_accuracy: 0.5971\n",
      "Epoch 210/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6907 - val_accuracy: 0.5971\n",
      "Epoch 211/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6907 - val_accuracy: 0.5971\n",
      "Epoch 212/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6907 - val_accuracy: 0.5971\n",
      "Epoch 213/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6907 - val_accuracy: 0.5971\n",
      "Epoch 214/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6907 - val_accuracy: 0.5971\n",
      "Epoch 215/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6907 - val_accuracy: 0.5971\n",
      "Epoch 216/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6907 - val_accuracy: 0.5971\n",
      "Epoch 217/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6907 - val_accuracy: 0.5971\n",
      "Epoch 218/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6907 - val_accuracy: 0.5971\n",
      "Epoch 219/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6907 - val_accuracy: 0.5971\n",
      "Epoch 220/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6907 - val_accuracy: 0.5971\n",
      "Epoch 221/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6907 - val_accuracy: 0.5971\n",
      "Epoch 222/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6907 - val_accuracy: 0.5971\n",
      "Epoch 223/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6907 - val_accuracy: 0.5971\n",
      "Epoch 224/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6907 - val_accuracy: 0.5971\n",
      "Epoch 225/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6907 - val_accuracy: 0.5971\n",
      "Epoch 226/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6907 - val_accuracy: 0.5971\n",
      "Epoch 227/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6907 - val_accuracy: 0.5971\n",
      "Epoch 228/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6907 - val_accuracy: 0.5971\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 229/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6907 - val_accuracy: 0.5971\n",
      "Epoch 230/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6907 - val_accuracy: 0.5971\n",
      "Epoch 231/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6907 - val_accuracy: 0.5971\n",
      "Epoch 232/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6907 - val_accuracy: 0.5971\n",
      "Epoch 233/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6907 - val_accuracy: 0.5971\n",
      "Epoch 234/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6907 - val_accuracy: 0.5971\n",
      "Epoch 235/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6907 - val_accuracy: 0.5971\n",
      "Epoch 236/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6907 - val_accuracy: 0.5971\n",
      "Epoch 237/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6907 - val_accuracy: 0.5971\n",
      "Epoch 238/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6907 - val_accuracy: 0.5971\n",
      "Epoch 239/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6907 - val_accuracy: 0.5971\n",
      "Epoch 240/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6907 - val_accuracy: 0.5971\n",
      "Epoch 241/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6907 - val_accuracy: 0.5971\n",
      "Epoch 242/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6907 - val_accuracy: 0.5971\n",
      "Epoch 243/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6907 - val_accuracy: 0.5971\n",
      "Epoch 244/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6907 - val_accuracy: 0.5971\n",
      "Epoch 245/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6907 - val_accuracy: 0.5971\n",
      "Epoch 246/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6907 - val_accuracy: 0.5971\n",
      "Epoch 247/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6907 - val_accuracy: 0.5971\n",
      "Epoch 248/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6907 - val_accuracy: 0.5971\n",
      "Epoch 249/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6907 - val_accuracy: 0.5971\n",
      "Epoch 250/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6907 - val_accuracy: 0.5971\n",
      "Epoch 251/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6908 - val_accuracy: 0.5971\n",
      "Epoch 252/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6908 - val_accuracy: 0.5971\n",
      "Epoch 253/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6908 - val_accuracy: 0.5971\n",
      "Epoch 254/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6908 - val_accuracy: 0.5971\n",
      "Epoch 255/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6908 - val_accuracy: 0.5971\n",
      "Epoch 256/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6908 - val_accuracy: 0.5971\n",
      "Epoch 257/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6908 - val_accuracy: 0.5971\n",
      "Epoch 258/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6908 - val_accuracy: 0.5971\n",
      "Epoch 259/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6908 - val_accuracy: 0.5971\n",
      "Epoch 260/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6908 - val_accuracy: 0.5971\n",
      "Epoch 261/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6908 - val_accuracy: 0.5971\n",
      "Epoch 262/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6908 - val_accuracy: 0.5971\n",
      "Epoch 263/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6908 - val_accuracy: 0.5971\n",
      "Epoch 264/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6908 - val_accuracy: 0.5971\n",
      "Epoch 265/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6908 - val_accuracy: 0.5971\n",
      "Epoch 266/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6908 - val_accuracy: 0.5971\n",
      "Epoch 267/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6908 - val_accuracy: 0.5971\n",
      "Epoch 268/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6908 - val_accuracy: 0.5971\n",
      "Epoch 269/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6908 - val_accuracy: 0.5971\n",
      "Epoch 270/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6908 - val_accuracy: 0.5971\n",
      "Epoch 271/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6908 - val_accuracy: 0.5971\n",
      "Epoch 272/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6908 - val_accuracy: 0.5971\n",
      "Epoch 273/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6908 - val_accuracy: 0.5971\n",
      "Epoch 274/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6908 - val_accuracy: 0.5971\n",
      "Epoch 275/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6908 - val_accuracy: 0.5971\n",
      "Epoch 276/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6908 - val_accuracy: 0.5971\n",
      "Epoch 277/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6908 - val_accuracy: 0.5971\n",
      "Epoch 278/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6908 - val_accuracy: 0.5971\n",
      "Epoch 279/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6908 - val_accuracy: 0.5971\n",
      "Epoch 280/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6908 - val_accuracy: 0.5971\n",
      "Epoch 281/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6908 - val_accuracy: 0.5971\n",
      "Epoch 282/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6908 - val_accuracy: 0.5971\n",
      "Epoch 283/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6908 - val_accuracy: 0.5971\n",
      "Epoch 284/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6908 - val_accuracy: 0.5971\n",
      "Epoch 285/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6908 - val_accuracy: 0.5971\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 286/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6908 - val_accuracy: 0.5971\n",
      "Epoch 287/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6908 - val_accuracy: 0.5971\n",
      "Epoch 288/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6908 - val_accuracy: 0.5971\n",
      "Epoch 289/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6908 - val_accuracy: 0.5971\n",
      "Epoch 290/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6908 - val_accuracy: 0.5971\n",
      "Epoch 291/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6908 - val_accuracy: 0.5971\n",
      "Epoch 292/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6908 - val_accuracy: 0.5971\n",
      "Epoch 293/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6908 - val_accuracy: 0.5971\n",
      "Epoch 294/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6908 - val_accuracy: 0.5971\n",
      "Epoch 295/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6908 - val_accuracy: 0.5971\n",
      "Epoch 296/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6908 - val_accuracy: 0.5971\n",
      "Epoch 297/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6908 - val_accuracy: 0.5971\n",
      "Epoch 298/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6908 - val_accuracy: 0.5971\n",
      "Epoch 299/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6908 - val_accuracy: 0.5971\n",
      "Epoch 300/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6908 - val_accuracy: 0.5971\n",
      "Epoch 301/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6908 - val_accuracy: 0.5971\n",
      "Epoch 302/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6908 - val_accuracy: 0.5971\n",
      "Epoch 303/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6908 - val_accuracy: 0.5971\n",
      "Epoch 304/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6908 - val_accuracy: 0.5971\n",
      "Epoch 305/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6909 - val_accuracy: 0.5971\n",
      "Epoch 306/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6909 - val_accuracy: 0.5971\n",
      "Epoch 307/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6909 - val_accuracy: 0.5971\n",
      "Epoch 308/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6909 - val_accuracy: 0.5971\n",
      "Epoch 309/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6909 - val_accuracy: 0.5971\n",
      "Epoch 310/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6909 - val_accuracy: 0.5971\n",
      "Epoch 311/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6909 - val_accuracy: 0.5971\n",
      "Epoch 312/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6909 - val_accuracy: 0.5971\n",
      "Epoch 313/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6909 - val_accuracy: 0.5971\n",
      "Epoch 314/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6909 - val_accuracy: 0.5971\n",
      "Epoch 315/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6909 - val_accuracy: 0.5971\n",
      "Epoch 316/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6909 - val_accuracy: 0.5971\n",
      "Epoch 317/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6909 - val_accuracy: 0.5971\n",
      "Epoch 318/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6909 - val_accuracy: 0.5971\n",
      "Epoch 319/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6909 - val_accuracy: 0.5971\n",
      "Epoch 320/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6909 - val_accuracy: 0.5971\n",
      "Epoch 321/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6909 - val_accuracy: 0.5971\n",
      "Epoch 322/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6909 - val_accuracy: 0.5971\n",
      "Epoch 323/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6909 - val_accuracy: 0.5971\n",
      "Epoch 324/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6909 - val_accuracy: 0.5971\n",
      "Epoch 325/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6909 - val_accuracy: 0.5971\n",
      "Epoch 326/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6909 - val_accuracy: 0.5971\n",
      "Epoch 327/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6909 - val_accuracy: 0.5971\n",
      "Epoch 328/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6909 - val_accuracy: 0.5971\n",
      "Epoch 329/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6909 - val_accuracy: 0.5971\n",
      "Epoch 330/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6909 - val_accuracy: 0.5971\n",
      "Epoch 331/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6909 - val_accuracy: 0.5971\n",
      "Epoch 332/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6909 - val_accuracy: 0.5971\n",
      "Epoch 333/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6909 - val_accuracy: 0.5971\n",
      "Epoch 334/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6909 - val_accuracy: 0.5971\n",
      "Epoch 335/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6909 - val_accuracy: 0.5971\n",
      "Epoch 336/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6909 - val_accuracy: 0.5971\n",
      "Epoch 337/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6909 - val_accuracy: 0.5971\n",
      "Epoch 338/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6909 - val_accuracy: 0.5971\n",
      "Epoch 339/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6909 - val_accuracy: 0.5971\n",
      "Epoch 340/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6909 - val_accuracy: 0.5971\n",
      "Epoch 341/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6909 - val_accuracy: 0.5971\n",
      "Epoch 342/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6909 - val_accuracy: 0.5971\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 343/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6909 - val_accuracy: 0.5971\n",
      "Epoch 344/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6909 - val_accuracy: 0.5971\n",
      "Epoch 345/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6909 - val_accuracy: 0.5971\n",
      "Epoch 346/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6909 - val_accuracy: 0.5971\n",
      "Epoch 347/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6909 - val_accuracy: 0.5971\n",
      "Epoch 348/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6909 - val_accuracy: 0.5971\n",
      "Epoch 349/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6909 - val_accuracy: 0.5971\n",
      "Epoch 350/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6909 - val_accuracy: 0.5971\n",
      "Epoch 351/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6909 - val_accuracy: 0.5971\n",
      "Epoch 352/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6909 - val_accuracy: 0.5971\n",
      "Epoch 353/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6909 - val_accuracy: 0.5971\n",
      "Epoch 354/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6909 - val_accuracy: 0.5971\n",
      "Epoch 355/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6909 - val_accuracy: 0.5971\n",
      "Epoch 356/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6909 - val_accuracy: 0.5971\n",
      "Epoch 357/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6909 - val_accuracy: 0.5971\n",
      "Epoch 358/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6909 - val_accuracy: 0.5971\n",
      "Epoch 359/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6909 - val_accuracy: 0.5971\n",
      "Epoch 360/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6909 - val_accuracy: 0.5971\n",
      "Epoch 361/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6909 - val_accuracy: 0.5971\n",
      "Epoch 362/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6909 - val_accuracy: 0.5971\n",
      "Epoch 363/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6909 - val_accuracy: 0.5971\n",
      "Epoch 364/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6909 - val_accuracy: 0.5971\n",
      "Epoch 365/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6909 - val_accuracy: 0.5971\n",
      "Epoch 366/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6910 - val_accuracy: 0.5971\n",
      "Epoch 367/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6910 - val_accuracy: 0.5971\n",
      "Epoch 368/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6910 - val_accuracy: 0.5971\n",
      "Epoch 369/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6910 - val_accuracy: 0.5971\n",
      "Epoch 370/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6910 - val_accuracy: 0.5971\n",
      "Epoch 371/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6910 - val_accuracy: 0.5971\n",
      "Epoch 372/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6910 - val_accuracy: 0.5971\n",
      "Epoch 373/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6910 - val_accuracy: 0.5971\n",
      "Epoch 374/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6910 - val_accuracy: 0.5971\n",
      "Epoch 375/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6910 - val_accuracy: 0.5971\n",
      "Epoch 376/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6910 - val_accuracy: 0.5971\n",
      "Epoch 377/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6910 - val_accuracy: 0.5971\n",
      "Epoch 378/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6910 - val_accuracy: 0.5971\n",
      "Epoch 379/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6910 - val_accuracy: 0.5971\n",
      "Epoch 380/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6910 - val_accuracy: 0.5971\n",
      "Epoch 381/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6910 - val_accuracy: 0.5971\n",
      "Epoch 382/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6910 - val_accuracy: 0.5971\n",
      "Epoch 383/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6910 - val_accuracy: 0.5971\n",
      "Epoch 384/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6910 - val_accuracy: 0.5971\n",
      "Epoch 385/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6910 - val_accuracy: 0.5971\n",
      "Epoch 386/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6910 - val_accuracy: 0.5971\n",
      "Epoch 387/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6910 - val_accuracy: 0.5971\n",
      "Epoch 388/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6910 - val_accuracy: 0.5971\n",
      "Epoch 389/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6910 - val_accuracy: 0.5971\n",
      "Epoch 390/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6910 - val_accuracy: 0.5971\n",
      "Epoch 391/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6910 - val_accuracy: 0.5971\n",
      "Epoch 392/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6910 - val_accuracy: 0.5971\n",
      "Epoch 393/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6910 - val_accuracy: 0.5971\n",
      "Epoch 394/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6910 - val_accuracy: 0.5971\n",
      "Epoch 395/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6910 - val_accuracy: 0.5971\n",
      "Epoch 396/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6910 - val_accuracy: 0.5971\n",
      "Epoch 397/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6910 - val_accuracy: 0.5971\n",
      "Epoch 398/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6910 - val_accuracy: 0.5971\n",
      "Epoch 399/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6910 - val_accuracy: 0.5971\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 400/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6910 - val_accuracy: 0.5971\n",
      "Epoch 401/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6910 - val_accuracy: 0.5971\n",
      "Epoch 402/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6910 - val_accuracy: 0.5971\n",
      "Epoch 403/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5064 - val_loss: 0.6910 - val_accuracy: 0.5971\n",
      "Epoch 404/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5064 - val_loss: 0.6910 - val_accuracy: 0.5971\n",
      "Epoch 405/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5064 - val_loss: 0.6910 - val_accuracy: 0.5971\n",
      "Epoch 406/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5064 - val_loss: 0.6910 - val_accuracy: 0.5971\n",
      "Epoch 407/1000\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.6931 - accuracy: 0.5064 - val_loss: 0.6910 - val_accuracy: 0.5971\n",
      "Epoch 408/1000\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.6931 - accuracy: 0.5064 - val_loss: 0.6910 - val_accuracy: 0.5971\n",
      "Epoch 409/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5064 - val_loss: 0.6910 - val_accuracy: 0.5971\n",
      "Epoch 410/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5064 - val_loss: 0.6910 - val_accuracy: 0.5971\n",
      "Epoch 411/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5064 - val_loss: 0.6910 - val_accuracy: 0.5971\n",
      "Epoch 412/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5064 - val_loss: 0.6910 - val_accuracy: 0.5971\n",
      "Epoch 413/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5064 - val_loss: 0.6910 - val_accuracy: 0.5971\n",
      "Epoch 414/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5064 - val_loss: 0.6910 - val_accuracy: 0.5971\n",
      "Epoch 415/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5064 - val_loss: 0.6910 - val_accuracy: 0.5971\n",
      "Epoch 416/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5064 - val_loss: 0.6910 - val_accuracy: 0.5971\n",
      "Epoch 417/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5064 - val_loss: 0.6910 - val_accuracy: 0.5971\n",
      "Epoch 418/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5064 - val_loss: 0.6910 - val_accuracy: 0.5971\n",
      "Epoch 419/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5064 - val_loss: 0.6910 - val_accuracy: 0.5971\n",
      "Epoch 420/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5064 - val_loss: 0.6910 - val_accuracy: 0.5971\n",
      "Epoch 421/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5064 - val_loss: 0.6910 - val_accuracy: 0.5971\n",
      "Epoch 422/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5064 - val_loss: 0.6910 - val_accuracy: 0.5971\n",
      "Epoch 423/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5064 - val_loss: 0.6910 - val_accuracy: 0.5971\n",
      "Epoch 424/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5064 - val_loss: 0.6910 - val_accuracy: 0.5971\n",
      "Epoch 425/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5064 - val_loss: 0.6910 - val_accuracy: 0.5971\n",
      "Epoch 426/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5064 - val_loss: 0.6910 - val_accuracy: 0.5971\n",
      "Epoch 427/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5064 - val_loss: 0.6910 - val_accuracy: 0.5971\n",
      "Epoch 428/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5064 - val_loss: 0.6910 - val_accuracy: 0.5971\n",
      "Epoch 429/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5064 - val_loss: 0.6910 - val_accuracy: 0.5971\n",
      "Epoch 430/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5064 - val_loss: 0.6910 - val_accuracy: 0.5971\n",
      "Epoch 431/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5064 - val_loss: 0.6910 - val_accuracy: 0.5971\n",
      "Epoch 432/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5064 - val_loss: 0.6910 - val_accuracy: 0.5971\n",
      "Epoch 433/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5064 - val_loss: 0.6910 - val_accuracy: 0.5971\n",
      "Epoch 434/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5064 - val_loss: 0.6910 - val_accuracy: 0.5971\n",
      "Epoch 435/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5064 - val_loss: 0.6910 - val_accuracy: 0.5971\n",
      "Epoch 436/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5064 - val_loss: 0.6910 - val_accuracy: 0.5971\n",
      "Epoch 437/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5064 - val_loss: 0.6910 - val_accuracy: 0.5971\n",
      "Epoch 438/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5064 - val_loss: 0.6910 - val_accuracy: 0.5971\n",
      "Epoch 439/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5064 - val_loss: 0.6910 - val_accuracy: 0.5971\n",
      "Epoch 440/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5064 - val_loss: 0.6911 - val_accuracy: 0.5971\n",
      "Epoch 441/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5064 - val_loss: 0.6911 - val_accuracy: 0.5971\n",
      "Epoch 442/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5064 - val_loss: 0.6911 - val_accuracy: 0.5971\n",
      "Epoch 443/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5064 - val_loss: 0.6911 - val_accuracy: 0.5971\n",
      "Epoch 444/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5064 - val_loss: 0.6911 - val_accuracy: 0.5971\n",
      "Epoch 445/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5064 - val_loss: 0.6911 - val_accuracy: 0.5971\n",
      "Epoch 446/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5064 - val_loss: 0.6911 - val_accuracy: 0.5971\n",
      "Epoch 447/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5064 - val_loss: 0.6911 - val_accuracy: 0.5971\n",
      "Epoch 448/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5064 - val_loss: 0.6911 - val_accuracy: 0.5971\n",
      "Epoch 449/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5064 - val_loss: 0.6911 - val_accuracy: 0.5971\n",
      "Epoch 450/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5064 - val_loss: 0.6911 - val_accuracy: 0.5971\n",
      "Epoch 451/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5088 - val_loss: 0.6911 - val_accuracy: 0.5971\n",
      "Epoch 452/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5088 - val_loss: 0.6911 - val_accuracy: 0.5971\n",
      "Epoch 453/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5088 - val_loss: 0.6911 - val_accuracy: 0.5971\n",
      "Epoch 454/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5088 - val_loss: 0.6911 - val_accuracy: 0.5971\n",
      "Epoch 455/1000\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.6931 - accuracy: 0.5088 - val_loss: 0.6911 - val_accuracy: 0.5971\n",
      "Epoch 456/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5088 - val_loss: 0.6911 - val_accuracy: 0.5971\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 457/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5088 - val_loss: 0.6911 - val_accuracy: 0.5971\n",
      "Epoch 458/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5088 - val_loss: 0.6911 - val_accuracy: 0.5971\n",
      "Epoch 459/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5088 - val_loss: 0.6911 - val_accuracy: 0.5971\n",
      "Epoch 460/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5088 - val_loss: 0.6911 - val_accuracy: 0.5971\n",
      "Epoch 461/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5088 - val_loss: 0.6911 - val_accuracy: 0.5971\n",
      "Epoch 462/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5088 - val_loss: 0.6911 - val_accuracy: 0.5971\n",
      "Epoch 463/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5088 - val_loss: 0.6911 - val_accuracy: 0.5971\n",
      "Epoch 464/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5088 - val_loss: 0.6911 - val_accuracy: 0.5971\n",
      "Epoch 465/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5088 - val_loss: 0.6911 - val_accuracy: 0.5971\n",
      "Epoch 466/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5088 - val_loss: 0.6911 - val_accuracy: 0.5971\n",
      "Epoch 467/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5088 - val_loss: 0.6911 - val_accuracy: 0.5971\n",
      "Epoch 468/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5088 - val_loss: 0.6911 - val_accuracy: 0.5971\n",
      "Epoch 469/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5088 - val_loss: 0.6911 - val_accuracy: 0.5971\n",
      "Epoch 470/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5088 - val_loss: 0.6911 - val_accuracy: 0.5971\n",
      "Epoch 471/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5088 - val_loss: 0.6911 - val_accuracy: 0.5971\n",
      "Epoch 472/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5088 - val_loss: 0.6911 - val_accuracy: 0.5971\n",
      "Epoch 473/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5088 - val_loss: 0.6911 - val_accuracy: 0.5971\n",
      "Epoch 474/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5088 - val_loss: 0.6911 - val_accuracy: 0.5971\n",
      "Epoch 475/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5088 - val_loss: 0.6911 - val_accuracy: 0.5971\n",
      "Epoch 476/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5088 - val_loss: 0.6911 - val_accuracy: 0.5971\n",
      "Epoch 477/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5088 - val_loss: 0.6911 - val_accuracy: 0.5971\n",
      "Epoch 478/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5088 - val_loss: 0.6911 - val_accuracy: 0.5971\n",
      "Epoch 479/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5088 - val_loss: 0.6911 - val_accuracy: 0.5971\n",
      "Epoch 480/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5088 - val_loss: 0.6911 - val_accuracy: 0.5971\n",
      "Epoch 481/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5088 - val_loss: 0.6911 - val_accuracy: 0.5971\n",
      "Epoch 482/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5088 - val_loss: 0.6911 - val_accuracy: 0.5971\n",
      "Epoch 483/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5088 - val_loss: 0.6911 - val_accuracy: 0.5971\n",
      "Epoch 484/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5088 - val_loss: 0.6911 - val_accuracy: 0.5971\n",
      "Epoch 485/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5088 - val_loss: 0.6911 - val_accuracy: 0.5971\n",
      "Epoch 486/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5088 - val_loss: 0.6911 - val_accuracy: 0.5971\n",
      "Epoch 487/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5088 - val_loss: 0.6911 - val_accuracy: 0.5971\n",
      "Epoch 488/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5088 - val_loss: 0.6911 - val_accuracy: 0.5971\n",
      "Epoch 489/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5088 - val_loss: 0.6911 - val_accuracy: 0.5971\n",
      "Epoch 490/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5088 - val_loss: 0.6911 - val_accuracy: 0.5971\n",
      "Epoch 491/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5088 - val_loss: 0.6911 - val_accuracy: 0.5971\n",
      "Epoch 492/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5088 - val_loss: 0.6911 - val_accuracy: 0.5971\n",
      "Epoch 493/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5088 - val_loss: 0.6911 - val_accuracy: 0.5971\n",
      "Epoch 494/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5088 - val_loss: 0.6911 - val_accuracy: 0.5971\n",
      "Epoch 495/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5088 - val_loss: 0.6911 - val_accuracy: 0.5971\n",
      "Epoch 496/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5088 - val_loss: 0.6911 - val_accuracy: 0.5971\n",
      "Epoch 497/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5088 - val_loss: 0.6911 - val_accuracy: 0.5971\n",
      "Epoch 498/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5088 - val_loss: 0.6911 - val_accuracy: 0.5971\n",
      "Epoch 499/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5088 - val_loss: 0.6911 - val_accuracy: 0.5971\n",
      "Epoch 500/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5088 - val_loss: 0.6911 - val_accuracy: 0.5971\n",
      "Epoch 501/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5088 - val_loss: 0.6911 - val_accuracy: 0.5971\n",
      "Epoch 502/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5088 - val_loss: 0.6911 - val_accuracy: 0.5971\n",
      "Epoch 503/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5088 - val_loss: 0.6911 - val_accuracy: 0.5971\n",
      "Epoch 504/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5088 - val_loss: 0.6911 - val_accuracy: 0.5971\n",
      "Epoch 505/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5088 - val_loss: 0.6911 - val_accuracy: 0.5971\n",
      "Epoch 506/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5088 - val_loss: 0.6911 - val_accuracy: 0.5971\n",
      "Epoch 507/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5088 - val_loss: 0.6911 - val_accuracy: 0.5971\n",
      "Epoch 508/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5096 - val_loss: 0.6911 - val_accuracy: 0.5971\n",
      "Epoch 509/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5096 - val_loss: 0.6911 - val_accuracy: 0.5971\n",
      "Epoch 510/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5096 - val_loss: 0.6911 - val_accuracy: 0.5971\n",
      "Epoch 511/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5096 - val_loss: 0.6911 - val_accuracy: 0.5971\n",
      "Epoch 512/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5096 - val_loss: 0.6911 - val_accuracy: 0.5971\n",
      "Epoch 513/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5096 - val_loss: 0.6911 - val_accuracy: 0.5971\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 514/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5088 - val_loss: 0.6911 - val_accuracy: 0.5971\n",
      "Epoch 515/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5088 - val_loss: 0.6911 - val_accuracy: 0.5971\n",
      "Epoch 516/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5088 - val_loss: 0.6911 - val_accuracy: 0.5971\n",
      "Epoch 517/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5088 - val_loss: 0.6911 - val_accuracy: 0.5971\n",
      "Epoch 518/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5088 - val_loss: 0.6911 - val_accuracy: 0.5971\n",
      "Epoch 519/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5088 - val_loss: 0.6911 - val_accuracy: 0.5971\n",
      "Epoch 520/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5088 - val_loss: 0.6911 - val_accuracy: 0.5971\n",
      "Epoch 521/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5088 - val_loss: 0.6911 - val_accuracy: 0.5971\n",
      "Epoch 522/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5088 - val_loss: 0.6911 - val_accuracy: 0.5971\n",
      "Epoch 523/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5088 - val_loss: 0.6911 - val_accuracy: 0.5971\n",
      "Epoch 524/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5088 - val_loss: 0.6911 - val_accuracy: 0.5971\n",
      "Epoch 525/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5088 - val_loss: 0.6911 - val_accuracy: 0.5971\n",
      "Epoch 526/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5088 - val_loss: 0.6911 - val_accuracy: 0.5971\n",
      "Epoch 527/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5088 - val_loss: 0.6911 - val_accuracy: 0.5971\n",
      "Epoch 528/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5088 - val_loss: 0.6911 - val_accuracy: 0.5971\n",
      "Epoch 529/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5088 - val_loss: 0.6911 - val_accuracy: 0.5971\n",
      "Epoch 530/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5104 - val_loss: 0.6911 - val_accuracy: 0.5971\n",
      "Epoch 531/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5104 - val_loss: 0.6911 - val_accuracy: 0.5971\n",
      "Epoch 532/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5104 - val_loss: 0.6911 - val_accuracy: 0.5971\n",
      "Epoch 533/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5104 - val_loss: 0.6911 - val_accuracy: 0.5971\n",
      "Epoch 534/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5104 - val_loss: 0.6911 - val_accuracy: 0.5971\n",
      "Epoch 535/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5104 - val_loss: 0.6912 - val_accuracy: 0.5971\n",
      "Epoch 536/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5104 - val_loss: 0.6912 - val_accuracy: 0.5971\n",
      "Epoch 537/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5104 - val_loss: 0.6912 - val_accuracy: 0.5971\n",
      "Epoch 538/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5104 - val_loss: 0.6912 - val_accuracy: 0.5971\n",
      "Epoch 539/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5104 - val_loss: 0.6912 - val_accuracy: 0.5971\n",
      "Epoch 540/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5104 - val_loss: 0.6912 - val_accuracy: 0.5971\n",
      "Epoch 541/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5104 - val_loss: 0.6912 - val_accuracy: 0.5971\n",
      "Epoch 542/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5104 - val_loss: 0.6912 - val_accuracy: 0.5971\n",
      "Epoch 543/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5104 - val_loss: 0.6912 - val_accuracy: 0.5971\n",
      "Epoch 544/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5104 - val_loss: 0.6912 - val_accuracy: 0.5971\n",
      "Epoch 545/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5104 - val_loss: 0.6912 - val_accuracy: 0.5971\n",
      "Epoch 546/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5104 - val_loss: 0.6912 - val_accuracy: 0.5971\n",
      "Epoch 547/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5104 - val_loss: 0.6912 - val_accuracy: 0.5971\n",
      "Epoch 548/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5104 - val_loss: 0.6912 - val_accuracy: 0.5971\n",
      "Epoch 549/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5112 - val_loss: 0.6912 - val_accuracy: 0.5971\n",
      "Epoch 550/1000\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.6931 - accuracy: 0.5112 - val_loss: 0.6912 - val_accuracy: 0.5971\n",
      "Epoch 551/1000\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.6931 - accuracy: 0.5112 - val_loss: 0.6912 - val_accuracy: 0.5971\n",
      "Epoch 552/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5112 - val_loss: 0.6912 - val_accuracy: 0.5971\n",
      "Epoch 553/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5112 - val_loss: 0.6912 - val_accuracy: 0.5971\n",
      "Epoch 554/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5112 - val_loss: 0.6912 - val_accuracy: 0.5971\n",
      "Epoch 555/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5112 - val_loss: 0.6912 - val_accuracy: 0.5971\n",
      "Epoch 556/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5112 - val_loss: 0.6912 - val_accuracy: 0.5971\n",
      "Epoch 557/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5112 - val_loss: 0.6912 - val_accuracy: 0.5971\n",
      "Epoch 558/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5112 - val_loss: 0.6912 - val_accuracy: 0.5971\n",
      "Epoch 559/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5112 - val_loss: 0.6912 - val_accuracy: 0.5971\n",
      "Epoch 560/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5112 - val_loss: 0.6912 - val_accuracy: 0.5971\n",
      "Epoch 561/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5112 - val_loss: 0.6912 - val_accuracy: 0.5971\n",
      "Epoch 562/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5112 - val_loss: 0.6912 - val_accuracy: 0.5971\n",
      "Epoch 563/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5112 - val_loss: 0.6912 - val_accuracy: 0.5971\n",
      "Epoch 564/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5112 - val_loss: 0.6912 - val_accuracy: 0.5971\n",
      "Epoch 565/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5104 - val_loss: 0.6912 - val_accuracy: 0.5971\n",
      "Epoch 566/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5096 - val_loss: 0.6912 - val_accuracy: 0.5971\n",
      "Epoch 567/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5096 - val_loss: 0.6912 - val_accuracy: 0.5971\n",
      "Epoch 568/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5096 - val_loss: 0.6912 - val_accuracy: 0.5971\n",
      "Epoch 569/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5096 - val_loss: 0.6912 - val_accuracy: 0.5971\n",
      "Epoch 570/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5096 - val_loss: 0.6912 - val_accuracy: 0.5971\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 571/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5096 - val_loss: 0.6912 - val_accuracy: 0.5971\n",
      "Epoch 572/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5096 - val_loss: 0.6912 - val_accuracy: 0.5971\n",
      "Epoch 573/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5096 - val_loss: 0.6912 - val_accuracy: 0.5971\n",
      "Epoch 574/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5096 - val_loss: 0.6912 - val_accuracy: 0.5971\n",
      "Epoch 575/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5096 - val_loss: 0.6912 - val_accuracy: 0.5971\n",
      "Epoch 576/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5096 - val_loss: 0.6912 - val_accuracy: 0.5971\n",
      "Epoch 577/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5096 - val_loss: 0.6912 - val_accuracy: 0.5971\n",
      "Epoch 578/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5096 - val_loss: 0.6912 - val_accuracy: 0.5971\n",
      "Epoch 579/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5096 - val_loss: 0.6912 - val_accuracy: 0.5971\n",
      "Epoch 580/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5096 - val_loss: 0.6912 - val_accuracy: 0.5971\n",
      "Epoch 581/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5096 - val_loss: 0.6912 - val_accuracy: 0.5971\n",
      "Epoch 582/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5096 - val_loss: 0.6912 - val_accuracy: 0.5971\n",
      "Epoch 583/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5096 - val_loss: 0.6912 - val_accuracy: 0.5971\n",
      "Epoch 584/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5096 - val_loss: 0.6912 - val_accuracy: 0.5971\n",
      "Epoch 585/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5096 - val_loss: 0.6912 - val_accuracy: 0.5971\n",
      "Epoch 586/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5096 - val_loss: 0.6912 - val_accuracy: 0.5971\n",
      "Epoch 587/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5096 - val_loss: 0.6912 - val_accuracy: 0.5971\n",
      "Epoch 588/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5096 - val_loss: 0.6912 - val_accuracy: 0.5971\n",
      "Epoch 589/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5096 - val_loss: 0.6912 - val_accuracy: 0.5971\n",
      "Epoch 590/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5096 - val_loss: 0.6912 - val_accuracy: 0.5971\n",
      "Epoch 591/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5096 - val_loss: 0.6912 - val_accuracy: 0.5971\n",
      "Epoch 592/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5096 - val_loss: 0.6912 - val_accuracy: 0.5971\n",
      "Epoch 593/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5096 - val_loss: 0.6912 - val_accuracy: 0.5971\n",
      "Epoch 594/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5096 - val_loss: 0.6912 - val_accuracy: 0.5971\n",
      "Epoch 595/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5096 - val_loss: 0.6912 - val_accuracy: 0.5971\n",
      "Epoch 596/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5096 - val_loss: 0.6912 - val_accuracy: 0.5971\n",
      "Epoch 597/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5096 - val_loss: 0.6912 - val_accuracy: 0.5971\n",
      "Epoch 598/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5096 - val_loss: 0.6912 - val_accuracy: 0.5971\n",
      "Epoch 599/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5096 - val_loss: 0.6912 - val_accuracy: 0.5971\n",
      "Epoch 600/1000\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.6931 - accuracy: 0.5096 - val_loss: 0.6912 - val_accuracy: 0.5971\n",
      "Epoch 601/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5096 - val_loss: 0.6912 - val_accuracy: 0.5971\n",
      "Epoch 602/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5096 - val_loss: 0.6912 - val_accuracy: 0.5971\n",
      "Epoch 603/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6912 - val_accuracy: 0.5971\n",
      "Epoch 604/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6912 - val_accuracy: 0.5971\n",
      "Epoch 605/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6912 - val_accuracy: 0.5971\n",
      "Epoch 606/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6912 - val_accuracy: 0.5971\n",
      "Epoch 607/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6912 - val_accuracy: 0.5971\n",
      "Epoch 608/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6912 - val_accuracy: 0.5971\n",
      "Epoch 609/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6912 - val_accuracy: 0.5971\n",
      "Epoch 610/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6912 - val_accuracy: 0.5971\n",
      "Epoch 611/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6912 - val_accuracy: 0.5971\n",
      "Epoch 612/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6912 - val_accuracy: 0.5971\n",
      "Epoch 613/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6912 - val_accuracy: 0.5971\n",
      "Epoch 614/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6912 - val_accuracy: 0.5971\n",
      "Epoch 615/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6912 - val_accuracy: 0.5971\n",
      "Epoch 616/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6912 - val_accuracy: 0.5971\n",
      "Epoch 617/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6912 - val_accuracy: 0.5971\n",
      "Epoch 618/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6912 - val_accuracy: 0.5971\n",
      "Epoch 619/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6912 - val_accuracy: 0.5971\n",
      "Epoch 620/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6912 - val_accuracy: 0.5971\n",
      "Epoch 621/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6912 - val_accuracy: 0.5971\n",
      "Epoch 622/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6912 - val_accuracy: 0.5971\n",
      "Epoch 623/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6912 - val_accuracy: 0.5971\n",
      "Epoch 624/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6912 - val_accuracy: 0.5971\n",
      "Epoch 625/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6912 - val_accuracy: 0.5971\n",
      "Epoch 626/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6912 - val_accuracy: 0.5971\n",
      "Epoch 627/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6912 - val_accuracy: 0.5971\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 628/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6912 - val_accuracy: 0.5971\n",
      "Epoch 629/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6912 - val_accuracy: 0.5971\n",
      "Epoch 630/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6912 - val_accuracy: 0.5971\n",
      "Epoch 631/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6912 - val_accuracy: 0.5971\n",
      "Epoch 632/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6912 - val_accuracy: 0.5971\n",
      "Epoch 633/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6912 - val_accuracy: 0.5971\n",
      "Epoch 634/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6912 - val_accuracy: 0.5971\n",
      "Epoch 635/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6912 - val_accuracy: 0.5971\n",
      "Epoch 636/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6912 - val_accuracy: 0.5971\n",
      "Epoch 637/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6912 - val_accuracy: 0.5971\n",
      "Epoch 638/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6912 - val_accuracy: 0.5971\n",
      "Epoch 639/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6912 - val_accuracy: 0.5971\n",
      "Epoch 640/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6912 - val_accuracy: 0.5971\n",
      "Epoch 641/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6912 - val_accuracy: 0.5971\n",
      "Epoch 642/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6912 - val_accuracy: 0.5971\n",
      "Epoch 643/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6912 - val_accuracy: 0.5971\n",
      "Epoch 644/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6912 - val_accuracy: 0.5971\n",
      "Epoch 645/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6912 - val_accuracy: 0.5971\n",
      "Epoch 646/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6912 - val_accuracy: 0.5971\n",
      "Epoch 647/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6912 - val_accuracy: 0.5971\n",
      "Epoch 648/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6912 - val_accuracy: 0.5971\n",
      "Epoch 649/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6912 - val_accuracy: 0.5971\n",
      "Epoch 650/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6912 - val_accuracy: 0.5971\n",
      "Epoch 651/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6912 - val_accuracy: 0.5971\n",
      "Epoch 652/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6912 - val_accuracy: 0.5971\n",
      "Epoch 653/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6912 - val_accuracy: 0.5971\n",
      "Epoch 654/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6912 - val_accuracy: 0.5971\n",
      "Epoch 655/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6912 - val_accuracy: 0.5971\n",
      "Epoch 656/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6912 - val_accuracy: 0.5971\n",
      "Epoch 657/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6912 - val_accuracy: 0.5971\n",
      "Epoch 658/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6912 - val_accuracy: 0.5971\n",
      "Epoch 659/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6912 - val_accuracy: 0.5971\n",
      "Epoch 660/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6912 - val_accuracy: 0.5971\n",
      "Epoch 661/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6912 - val_accuracy: 0.5971\n",
      "Epoch 662/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6912 - val_accuracy: 0.5971\n",
      "Epoch 663/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6912 - val_accuracy: 0.5971\n",
      "Epoch 664/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6912 - val_accuracy: 0.5971\n",
      "Epoch 665/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6912 - val_accuracy: 0.5971\n",
      "Epoch 666/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6912 - val_accuracy: 0.5971\n",
      "Epoch 667/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6912 - val_accuracy: 0.5971\n",
      "Epoch 668/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6912 - val_accuracy: 0.5971\n",
      "Epoch 669/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6912 - val_accuracy: 0.5971\n",
      "Epoch 670/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6912 - val_accuracy: 0.5971\n",
      "Epoch 671/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6912 - val_accuracy: 0.5971\n",
      "Epoch 672/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6912 - val_accuracy: 0.5971\n",
      "Epoch 673/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6913 - val_accuracy: 0.5971\n",
      "Epoch 674/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6913 - val_accuracy: 0.5971\n",
      "Epoch 675/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6913 - val_accuracy: 0.5971\n",
      "Epoch 676/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6913 - val_accuracy: 0.5971\n",
      "Epoch 677/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6913 - val_accuracy: 0.5971\n",
      "Epoch 678/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6913 - val_accuracy: 0.5971\n",
      "Epoch 679/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6913 - val_accuracy: 0.5971\n",
      "Epoch 680/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6913 - val_accuracy: 0.5971\n",
      "Epoch 681/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6913 - val_accuracy: 0.5971\n",
      "Epoch 682/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6913 - val_accuracy: 0.5971\n",
      "Epoch 683/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6913 - val_accuracy: 0.5971\n",
      "Epoch 684/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6913 - val_accuracy: 0.5971\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 685/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6913 - val_accuracy: 0.5971\n",
      "Epoch 686/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6913 - val_accuracy: 0.5971\n",
      "Epoch 687/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6913 - val_accuracy: 0.5971\n",
      "Epoch 688/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6913 - val_accuracy: 0.5971\n",
      "Epoch 689/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6913 - val_accuracy: 0.5971\n",
      "Epoch 690/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5088 - val_loss: 0.6913 - val_accuracy: 0.5971\n",
      "Epoch 691/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5088 - val_loss: 0.6913 - val_accuracy: 0.5971\n",
      "Epoch 692/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5088 - val_loss: 0.6913 - val_accuracy: 0.5971\n",
      "Epoch 693/1000\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.6931 - accuracy: 0.5088 - val_loss: 0.6913 - val_accuracy: 0.5971\n",
      "Epoch 694/1000\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.6931 - accuracy: 0.5088 - val_loss: 0.6913 - val_accuracy: 0.5971\n",
      "Epoch 695/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5088 - val_loss: 0.6913 - val_accuracy: 0.5971\n",
      "Epoch 696/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5088 - val_loss: 0.6913 - val_accuracy: 0.5971\n",
      "Epoch 697/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5088 - val_loss: 0.6913 - val_accuracy: 0.5971\n",
      "Epoch 698/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5088 - val_loss: 0.6913 - val_accuracy: 0.5971\n",
      "Epoch 699/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5088 - val_loss: 0.6913 - val_accuracy: 0.5971\n",
      "Epoch 700/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5088 - val_loss: 0.6913 - val_accuracy: 0.5971\n",
      "Epoch 701/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5088 - val_loss: 0.6913 - val_accuracy: 0.5971\n",
      "Epoch 702/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5088 - val_loss: 0.6913 - val_accuracy: 0.5971\n",
      "Epoch 703/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5088 - val_loss: 0.6913 - val_accuracy: 0.5971\n",
      "Epoch 704/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5088 - val_loss: 0.6913 - val_accuracy: 0.5971\n",
      "Epoch 705/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5088 - val_loss: 0.6913 - val_accuracy: 0.5971\n",
      "Epoch 706/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5088 - val_loss: 0.6913 - val_accuracy: 0.5971\n",
      "Epoch 707/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5088 - val_loss: 0.6913 - val_accuracy: 0.5971\n",
      "Epoch 708/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5088 - val_loss: 0.6913 - val_accuracy: 0.5971\n",
      "Epoch 709/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5088 - val_loss: 0.6913 - val_accuracy: 0.5971\n",
      "Epoch 710/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5088 - val_loss: 0.6913 - val_accuracy: 0.5971\n",
      "Epoch 711/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5088 - val_loss: 0.6913 - val_accuracy: 0.5971\n",
      "Epoch 712/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5088 - val_loss: 0.6913 - val_accuracy: 0.5971\n",
      "Epoch 713/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5088 - val_loss: 0.6913 - val_accuracy: 0.5971\n",
      "Epoch 714/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5088 - val_loss: 0.6913 - val_accuracy: 0.5971\n",
      "Epoch 715/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5088 - val_loss: 0.6913 - val_accuracy: 0.5971\n",
      "Epoch 716/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5088 - val_loss: 0.6913 - val_accuracy: 0.5971\n",
      "Epoch 717/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5088 - val_loss: 0.6913 - val_accuracy: 0.5971\n",
      "Epoch 718/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5088 - val_loss: 0.6913 - val_accuracy: 0.5971\n",
      "Epoch 719/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5088 - val_loss: 0.6913 - val_accuracy: 0.5971\n",
      "Epoch 720/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5088 - val_loss: 0.6913 - val_accuracy: 0.5971\n",
      "Epoch 721/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5088 - val_loss: 0.6913 - val_accuracy: 0.5971\n",
      "Epoch 722/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5088 - val_loss: 0.6913 - val_accuracy: 0.5971\n",
      "Epoch 723/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5088 - val_loss: 0.6913 - val_accuracy: 0.5971\n",
      "Epoch 724/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5088 - val_loss: 0.6913 - val_accuracy: 0.5971\n",
      "Epoch 725/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5088 - val_loss: 0.6913 - val_accuracy: 0.5971\n",
      "Epoch 726/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5088 - val_loss: 0.6913 - val_accuracy: 0.5971\n",
      "Epoch 727/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5088 - val_loss: 0.6913 - val_accuracy: 0.5971\n",
      "Epoch 728/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5088 - val_loss: 0.6913 - val_accuracy: 0.5971\n",
      "Epoch 729/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5088 - val_loss: 0.6913 - val_accuracy: 0.5971\n",
      "Epoch 730/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5088 - val_loss: 0.6913 - val_accuracy: 0.5971\n",
      "Epoch 731/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5088 - val_loss: 0.6913 - val_accuracy: 0.5971\n",
      "Epoch 732/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5088 - val_loss: 0.6913 - val_accuracy: 0.5971\n",
      "Epoch 733/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5088 - val_loss: 0.6913 - val_accuracy: 0.5971\n",
      "Epoch 734/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5088 - val_loss: 0.6913 - val_accuracy: 0.5971\n",
      "Epoch 735/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5088 - val_loss: 0.6913 - val_accuracy: 0.5971\n",
      "Epoch 736/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5088 - val_loss: 0.6913 - val_accuracy: 0.5971\n",
      "Epoch 737/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5088 - val_loss: 0.6913 - val_accuracy: 0.5971\n",
      "Epoch 738/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5088 - val_loss: 0.6913 - val_accuracy: 0.5971\n",
      "Epoch 739/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5088 - val_loss: 0.6913 - val_accuracy: 0.5971\n",
      "Epoch 740/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5088 - val_loss: 0.6913 - val_accuracy: 0.5971\n",
      "Epoch 741/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5088 - val_loss: 0.6913 - val_accuracy: 0.5971\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 742/1000\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.6931 - accuracy: 0.5088 - val_loss: 0.6913 - val_accuracy: 0.5971\n",
      "Epoch 743/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5088 - val_loss: 0.6913 - val_accuracy: 0.5971\n",
      "Epoch 744/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5088 - val_loss: 0.6913 - val_accuracy: 0.5971\n",
      "Epoch 745/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5088 - val_loss: 0.6913 - val_accuracy: 0.5971\n",
      "Epoch 746/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5088 - val_loss: 0.6913 - val_accuracy: 0.5971\n",
      "Epoch 747/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5088 - val_loss: 0.6913 - val_accuracy: 0.5971\n",
      "Epoch 748/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5088 - val_loss: 0.6913 - val_accuracy: 0.5971\n",
      "Epoch 749/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5088 - val_loss: 0.6913 - val_accuracy: 0.5971\n",
      "Epoch 750/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5088 - val_loss: 0.6913 - val_accuracy: 0.5971\n",
      "Epoch 751/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5088 - val_loss: 0.6913 - val_accuracy: 0.5971\n",
      "Epoch 752/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5088 - val_loss: 0.6913 - val_accuracy: 0.5971\n",
      "Epoch 753/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5088 - val_loss: 0.6913 - val_accuracy: 0.5971\n",
      "Epoch 754/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5088 - val_loss: 0.6913 - val_accuracy: 0.5971\n",
      "Epoch 755/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5088 - val_loss: 0.6913 - val_accuracy: 0.5971\n",
      "Epoch 756/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5088 - val_loss: 0.6913 - val_accuracy: 0.5971\n",
      "Epoch 757/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5088 - val_loss: 0.6913 - val_accuracy: 0.5971\n",
      "Epoch 758/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5088 - val_loss: 0.6913 - val_accuracy: 0.5971\n",
      "Epoch 759/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6913 - val_accuracy: 0.5971\n",
      "Epoch 760/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6913 - val_accuracy: 0.5971\n",
      "Epoch 761/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6913 - val_accuracy: 0.5971\n",
      "Epoch 762/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6913 - val_accuracy: 0.5971\n",
      "Epoch 763/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6913 - val_accuracy: 0.5971\n",
      "Epoch 764/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6913 - val_accuracy: 0.5971\n",
      "Epoch 765/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6913 - val_accuracy: 0.5971\n",
      "Epoch 766/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6913 - val_accuracy: 0.5971\n",
      "Epoch 767/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6913 - val_accuracy: 0.5971\n",
      "Epoch 768/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6913 - val_accuracy: 0.5971\n",
      "Epoch 769/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6913 - val_accuracy: 0.5971\n",
      "Epoch 770/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6913 - val_accuracy: 0.5971\n",
      "Epoch 771/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6913 - val_accuracy: 0.5971\n",
      "Epoch 772/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6913 - val_accuracy: 0.5971\n",
      "Epoch 773/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6913 - val_accuracy: 0.5971\n",
      "Epoch 774/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6913 - val_accuracy: 0.5971\n",
      "Epoch 775/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6913 - val_accuracy: 0.5971\n",
      "Epoch 776/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6913 - val_accuracy: 0.5971\n",
      "Epoch 777/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6913 - val_accuracy: 0.5971\n",
      "Epoch 778/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6913 - val_accuracy: 0.5971\n",
      "Epoch 779/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6913 - val_accuracy: 0.5971\n",
      "Epoch 780/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6913 - val_accuracy: 0.5971\n",
      "Epoch 781/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6913 - val_accuracy: 0.5971\n",
      "Epoch 782/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6913 - val_accuracy: 0.5971\n",
      "Epoch 783/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6913 - val_accuracy: 0.5971\n",
      "Epoch 784/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6913 - val_accuracy: 0.5971\n",
      "Epoch 785/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6913 - val_accuracy: 0.5971\n",
      "Epoch 786/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6913 - val_accuracy: 0.5971\n",
      "Epoch 787/1000\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6913 - val_accuracy: 0.5971\n",
      "Epoch 788/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6913 - val_accuracy: 0.5971\n",
      "Epoch 789/1000\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6913 - val_accuracy: 0.5971\n",
      "Epoch 790/1000\n",
      " 1/63 [..............................] - ETA: 0s - loss: 0.6917 - accuracy: 0.4500"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-107-9f1f7934ad06>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvalidation_split\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1206\u001b[0m         \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_epoch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1207\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcatch_stop_iteration\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1208\u001b[1;33m           \u001b[1;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1209\u001b[0m             with tf.profiler.experimental.Trace(\n\u001b[0;32m   1210\u001b[0m                 \u001b[1;34m'train'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\keras\\engine\\data_adapter.py\u001b[0m in \u001b[0;36msteps\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1248\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_insufficient_data\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# Set by `catch_stop_iteration`.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1249\u001b[0m         \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1250\u001b[1;33m       \u001b[0moriginal_spe\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_steps_per_execution\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1251\u001b[0m       can_run_full_execution = (\n\u001b[0;32m   1252\u001b[0m           \u001b[0moriginal_spe\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32mor\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    643\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    644\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 645\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    646\u001b[0m     raise NotImplementedError(\n\u001b[0;32m    647\u001b[0m         \"numpy() is only available when eager execution is enabled.\")\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1147\u001b[0m     \"\"\"\n\u001b[0;32m   1148\u001b[0m     \u001b[1;31m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1149\u001b[1;33m     \u001b[0mmaybe_arr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1150\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmaybe_arr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1151\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1113\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1114\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1115\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1116\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1117\u001b[0m       \u001b[1;32mraise\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history = classifier.fit(X,y, epochs=1000,batch_size=20,verbose=1,validation_split=0.1,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "580f3595",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train Loss', 'Validation Loss'], loc=\"upper right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1634eb8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
